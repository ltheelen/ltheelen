RsInstrument.logger?.
classScpiLogger[source]?   Base class for SCPI logging
mode?   Sets the logging ON or OFF. Additionally, you can set the logging ON only for errors. Possible values:
   LoggingMode.Off - logging is switched OFF
   LoggingMode.On - logging is switched ON
   LoggingMode.Errors - logging is switched ON, but only for error entries
   LoggingMode.Default - sets the logging to default - the value you have set with logger.default_mode
default_mode?    Sets/Returns the default logging mode. You can recall the default mode by calling the logger.mode= LoggingMode.Default  Data Type:LoggingMode
device_name: str?   Use this property to change the resource name in the log from the default Resource Name (e.g. TCPIP::192.168.2.101::INSTR) to another name e.g. ‘MySigGen1’.
set_logging_target(target, console_log: bool=None, udp_log: bool=None)? None[source]?   Sets logging target - the target must implement write() and flush(). You can optionally set the console and UDP logging ON or OFF. This method switches the logging target global OFF.
get_logging_target()[source]?   Based on the global_mode, it returns the logging target: either the local or the global one.
set_logging_target_global(console_log: bool=None, udp_log: bool=None)? None[source]?   Sets logging target to global. The global target must be defined. You can optionally set the console and UDP logging ON or OFF.
log_to_console?   Returns logging to console status.
log_to_udp?   Returns logging to UDP status.
log_to_console_and_udp?   Returns true, if both logging to UDP and console in are True.
info_raw(log_entry: str, add_new_line: bool=True)? None[source]?   Method for logging the raw string without any formatting.
info(start_time: datetime, end_time: datetime, log_string_info: str, log_string: str)? None[source]?   Method for logging one info entry. For binary log_string, use the info_bin()
error(start_time: datetime, end_time: datetime, log_string_info: str, log_string: str)? None[source]?   Method for logging one error entry.
set_relative_timestamp(timestamp: datetime)? None[source]?   If set, the further timestamps will be relative to the entered time.
set_relative_timestamp_now()? None[source]?   Sets the relative timestamp to the current time.
get_relative_timestamp()? datetime[source]?   Based on the global_mode, it returns the relative timestamp: either the local or the global one.
clear_relative_timestamp()? None[source]?   Clears the reference time, and the further logging continues with absolute times.
flush()? None[source]?   Flush all the entries.
log_status_check_ok?   Sets/returns the current status of status checking OK. If True (default), the log contains logging of the status checking ‘Status check: OK’. If False, the ‘Status check: OK’ is skipped - the log is more compact. Errors will still be logged.
clear_cached_entries()? None[source]?   Clears potential cached log entries. Cached log entries are generated when the Logging is ON, but no target has been defined yet.
set_format_string(value: str, line_divider: str='\n')? None[source]?   Sets new format string and line divider. If you just want to set the line divider, set the format string value=None The original format string is: PAD_LEFT12(%START_TIME%) PAD_LEFT25(%DEVICE_NAME%) PAD_LEFT12(%DURATION%)  %LOG_STRING_INFO%: %LOG_STRING%
restore_format_string()? None[source]?   Restores the original format string and the line divider to LF
abbreviated_max_len_ascii: int?   Defines the maximum length of one ASCII log entry. Default value is 200 characters.
abbreviated_max_len_bin: int?   Defines the maximum length of one Binary log entry. Default value is 2048 bytes.
abbreviated_max_len_list: int?   Defines the maximum length of one list entry. Default value is 100 elements.
bin_line_block_size: int?   Defines number of bytes to display in one line. Default value is 16 bytes.
udp_port?   Returns udp logging port.
target_auto_flushing?   Returns status of the auto-flushing for the logging target.

"""setup.py Setup file for creating the RsInstrument package."""
import pathlib
from setuptools import setup, find_packages
#The directory containing this file
HERE=pathlib.Path(__file__).parent
ext of the README file
README=(HERE/"README.rst").read_text()
#This call to setup() does all the work
setup(name="RsInstrument",
	version="1.55.0",
	description="VISA or Socket Communication Module for Rohde & Schwarz Instruments",
	long_description=README,
	long_description_content_type="text/x-rst",
	author="Rohde & Schwarz GmbH & Co. KG",
	copyright="Copyright © Rohde & Schwarz GmbH & Co. KG 2023",
	url="https://github.com/Rohde-Schwarz/RsInstrument",
	license="MIT",
    classifiers=['License::OSI Approved::MIT License',
                 'Intended Audience::Developers',
                 'Operating System::Microsoft::Windows',
                 'Operating System::POSIX::Linux',
                 'Operating System::MacOS::MacOS X',
                 'Programming Language::Python',
                 'Programming Language::Python::3',
                 'Programming Language::Python::3.6',
                 'Programming Language::Python::3.7',
                 'Programming Language::Python::3.8',
                 'Programming Language::Python::3.9',
                 'Programming Language::Python::3.10',
                 'Programming Language::Python::3.11'],
	packages=(find_packages(include=['RsInstrument','RsInstrument.*'])),
    install_requires=['PyVisa>=1.11.3'],
    python_requires='>=3.6')

"""Events.py"""
from typing import Callable
from ..Internal import Core
class Events:
"""Common Events class.
Event-related methods and properties. Here you can set all the event handlers."""
	def __init__(self, core: Core):
		self._core=core
	@property
	def io_events_include_data(self) -> bool:
"""Returns the current state of the io_events_include_data See the setter for more details."""
		return self._core.io.io_events_include_data
	@io_events_include_data.setter
	def io_events_include_data(self, value: bool) -> None:
"""If True, the on_write and on_read events include also the transferred data.
		Default value is False, to avoid handling potentially big data."""
		self._core.io.io_events_include_data=value
	@property
	def before_write_handler(self) -> Callable:
"""Returns the handler of before_write events. \n
		:return: current ``before_write_handler``"""
		return self._core.io.before_write_handler
	@before_write_handler.setter
	def before_write_handler(self, handler: Callable) -> None:
"""Sets handler for before_write events.
The before_write event is invoked before each write operation (only once, not for every chunk)
Event prototype: handler(io: Instrument, cmd: str)
:param handler: new handler"""
		self._core.io.before_write_handler=handler
	@property
	def on_write_handler(self) -> Callable:
"""Returns the handler of on_write events. \n
:return: current ``on_write_handler``"""
		return self._core.io.on_write_handler
	@on_write_handler.setter
	def on_write_handler(self, handler: Callable) -> None:
"""Sets handler for on_write events.
The on_write event is invoked every time the driver performs a write operation to the instrument (for each write chunk)
Event arguments type: IoTransferEventArgs. By default, the event_args do not contain the actual data sent. If you wish to receive them, set the driver.Events.io_events_include_data to True \n
:param handler: new handler for all write operations"""
		self._core.io.on_write_handler=handler
	@property
	def on_read_handler(self) -> Callable:
"""Returns the handler of on_read events. \n
:return: current ``on_read_handler``"""
		return self._core.io.on_read_handler
	@on_read_handler.setter
	def on_read_handler(self, handler: Callable) -> None:
"""Sets handler for on_read events. The on_read event is invoked every time the driver performs a read operation to the instrument.
Event arguments type: IoTransferEventArgs
By default, the event_args do not contain the actual data sent. If you wish to receive them, set the driver.Events.io_events_include_data to True \n
:param handler: new handler for all read operations"""
		self._core.io.on_read_handler=handler
	@property
	def before_query_handler(self) -> Callable:
"""Returns the handler of before_query events. \n
		:return: current ``before_query_handler``"""
		return self._core.io.before_query_handler
	@before_query_handler.setter
	def before_query_handler(self, handler: Callable) -> None:
"""Sets handler for before_query events.
The before_query event is invoked before each query operation (only once, not for every chunk)
Event prototype: handler(io: Instrument, query: str)
:param handler: new handler"""
		self._core.io.before_query_handler=handler
	def sync_from(self, source: 'Events') -> None:
"""Synchronises these Events with the source."""
		self.before_query_handler=source.before_query_handler
		self.before_write_handler=source.before_write_handler
		self.io_events_include_data=source.io_events_include_data
		self.on_read_handler=source.on_read_handler
		self.on_write_handler=source.on_write_handler


Software for the pgfs-project
2. Installation
RsInstrument is hosted on `pypi.org <https://pypi.org/search/?q=RsInstrument>`_. You can install it with pip (for example ``pip.exe`` for Windows), or if you are using Pycharm (and you should be :-) direct in the Pycharm packet management GUI.

Option 1-Installing with pip.exe under Windows
- Start the command console: ``WinKey+R``, type ``cmd`` and hit ENTER
- Change the working directory to the Python installation of your choice (adjust the user name and python version in the path): ``cd c:\Users\John\AppData\Local\Programs\Python\Python310\Scripts``
- install RsInstrument with the command: ``pip install RsInstrument``

Option 2-Installing in Pycharm
- In Pycharm Menu ``File->Settings->Project->Python Interpreter`` click on the **'+'** button on the top left. Newer Pycharm versions have ``Python Packages`` Tool Window, you can perform the same operation there.
- Type ``RsInstrument`` in the search box
- Install the version 1.22.0 or newer
- If you are behind a Proxy server, configure it in the Menu: 
``File->Settings->Appearance->System Settings->HTTP Proxy``
For more information about Rohde & Schwarz instrument remote control, check out our Instrument remote control series: 
`Rohde&Schwarz remote control Web series https://www.rohde-schwarz.com/driver-pages/remote-control/drivers-remote-control_110753.html 

Option 3-Offline installation
If you are reading this, it is probably because none of the above worked for you-proxy problems, your boss saw the internet bill...
Here are 5 easy steps for installing RsInstrument offline: 
- Download this python script (**Save target as**): `RsInstrument_offline_install.py <https://cdn.rohde-schwarz.com/pws/service_support/driver_pagedq/files_1/helloworld/RsInstrument_offline_install.py>`_
- Execute the script in your offline computer (supported is python 3.6 or newer)

3. Finding available instruments
Similar to the pyvisa's ResourceManager, RsInstrument can search for available instruments: 
.. include::Example_FindInstrument.py
If you have more VISAs installed, the one actually used by default is defined by a secret widget called VISA Conflict Manager. You can force your program to use a VISA of your choice:
.. include::Example_FindInstrument_SelectVisa.py

4. Initiating instrument session
RsInstrument offers four different types of starting your remote-control session. We begin with the most typical case, and progress with more special ones.

Standard Session Initialization
Initiating new instrument session happens, when you instantiate the RsInstrument object. Below, is a Hello World example. Different resource names are examples for different physical interfaces.
.. include::Example_HelloWorld.py
Do not care about specialty of each session kind; RsInstrument handles all the necessary session settings for you. You have immediately access to many identification properties. Here are same of them:
.. code-block::python
    idn_string:str
    driver_version:str
    visa_manufacturer:str
    full_instrument_model_name:str
    instrument_serial_number:str
    instrument_firmware_version:str
    instrument_options:List[str]
The constructor also contains optional boolean arguments ``id_query`` and ``reset``:
.. code-block::python
    instr=RsInstrument('TCPIP::192.168.56.101::hislip0',id_query=True,reset=True)
- Setting ``id_query`` to True (default is True) checks, whether your instrument can be used with the RsInstrument module.
- Setting  ``reset`` to True (default is False) resets your instrument. It is equivalent to calling the ``reset()`` method.
Using context-manager prevents you from forgetting closing the session in case of an error:
.. include::Example_HelloWorldWithContextManager.py
Selecting specific VISA
Same as for the ``list_resources()`` function, RsInstrument allows you to choose which VISA to use:
.. include::Example_DifferentVisas.py

No VISA Session
We recommend using VISA whenever possible, preferably with HiSLIP session because of its low latency.
However, if you are a strict VISA-denier, RsInstrument has something for you too:
**No VISA raw LAN socket**:
.. include::Example_HelloWorld_SocketIO.py
.. warning::Not using VISA can cause problems by debugging when you want to use the communication Trace Tool. The good news is, you can easily switch to use VISA and back just by changing the constructor arguments. The rest of your code stays unchanged.

Simulating Session
If a colleague is currently occupying your instrument, leave him in peace, and open a simulating session:
.. code-block::python
    instr=RsInstrument('TCPIP::192.168.56.101::hislip0',True,True,"Simulate=True")
More ``option_string`` tokens are separated by comma:
.. code-block::python
    instr=RsInstrument('TCPIP::192.168.56.101::hislip0',True,True,"SelectVisa='rs',Simulate=True")
.. note::Simulating session works as a database - when you write a command **SENSe:FREQ 10MHz**, the query **SENSe:FREQ?** returns **10MHz** back. For queries not preceded by set commands, the RsInstrument returns default values:
   -**'Simulating'** for string queries.
   -**0** for integer queries.
   -**0.0** for float queries.
   -**False** for boolean queries.

Shared Session
In some scenarios, you want to have two independent objects talking to the same instrument. Rather than opening a second VISA connection, share the same one between two or more RsInstrument objects:
.. include::Example_SessionSharing.py
.. note::The ``instr1`` is the object holding the 'master' session. If you call the ``instr1.close()``, the ``instr2`` loses its instrument session as well, and becomes pretty much useless.

5. Basic I/O communication
Now we have opened the session, it's time to do some work. RsInstrument provides two basic methods for communication:
write_str()-writing a command without an answer e.g.:*RST
query_str()-querying your instrument, for example with the *IDN? query
One additional feature we need to mention here: VISA timeout. To simplify, VISA timeout plays a role in each query_xxx(), where the controller (your PC) has to prevent waiting forever for an answer from your instrument. VISA timeout defines that maximum waiting time. You can set/read it with the visa_timeout property:
#Timeout in milliseconds
instr.visa_timeout=3000
#After this time, RsInstrument raises an exception. Speaking of exceptions, an important feature of the RsInstrument is Instrument Status Checking. Check out the next chapter that describes the error checking in details. For completion, we mention other string-based write_xxx() and query_xxx() methods, all in one example. They are convenient extensions providing type-safe float/boolean/integer setting/querying features:
Lastly, a method providing basic synchronization:query_opc(). It sends *OPC? to your instrument. The instrument waits with the answer until all the tasks it currently has in the execution queue are finished. This way your program waits too, and it is synchronized with actions in the instrument. Remember to have the VISA timeout set to an appropriate value to prevent the timeout exception. Here's a snippet:
instr.visa_timeout=3000
instr.write_str("INIT")
instr.query_opc()
#The results are ready now to fetch
results=instr.query_str('FETCH:MEASUREMENT?')
#You can define the VISA timeout directly in the query_opc, which is valid only for that call. Afterwards, the VISA timeout is set to the previous value:
instr.write_str("INIT")
instr.query_opc(3000)

6. Error Checking
RsInstrument has a built-in mechanism that after each command/query checks the instrument's status subsystem, and raises an exception if it detects an error. For those who are already screaming: Speed Performance Penalty!, don't worry, you can disable it.
Instrument status checking is very useful since in case your command/query caused an error, you are immediately informed about it. Status checking has in most cases no practical effect on the speed performance of your program. However, if for example, you do many repetitions of short write/query sequences, it might make a difference to switch it off:
#Default value after init is True
instr.instrument_status_checking=False
#To clear the instrument status subsystem of all errors, call this method:
instr.clear_status()
#Instrument's status system error queue is clear-on-read. It means, if you query its content, you clear it at the same time. To query and clear list of all the current errors, use the following:
errors_list=instr.query_all_errors()

7. Exception Handling
The base class for all the exceptions raised by the RsInstrument is RsInstrException. 
Inherited exception classes:
ResourceError raised in the constructor by problems with initiating the instrument, for example wrong or non-existing resource name
StatusException raised if a command or a query generated error in the instrument's error queue
TimeoutException raised if a VISA timeout or an opc timeout is reached

8. OPC-synchronized I/O Communication
OPC-synchronized communication. OPC stands for OPeration Completed. The idea is: use one method (write or query), which sends the command, and polls the instrument's status subsystem until it indicates: "I'm finished". The main advantage is, you can use this mechanism for commands that take several seconds, or minutes to complete, and you are still able to interrupt the process if needed. You can also perform other operations with the instrument in a parallel thread.
All the write/query methods we learned in the previous chapter have their _with_opc siblings. For example: write_str() has write_str_with_opc(). You can use them just like the normal write/query with one difference:They all have an optional parameter timeout, where you define the maximum time to wait. If you omit it, it uses a value from opc_timeout property. Important difference between the meaning of visa_timeout and opc_timeout:
visa_timeout is a VISA IO communication timeout. It does not play any role in the _with_opc() methods. It only defines timeout for the standard query_xxx() methods. We recommend to keep it to maximum of 10000 ms.
opc_timeout is a RsInstrument internal timeout, that serves as a default value to all the _with_opc() methods. If you explicitly define it in the method API, it is valid only for that one method call.

9. Querying Arrays
Often you need to query an array of numbers from your instrument, for example a spectrum analyzer trace or an oscilloscope waveform. Many programmers stick to transferring such arrays in ASCII format, because of the simplicity. Although simple, it is quite inefficient:one float 32-bit number can take up to 12 characters (bytes), compared to 4 bytes in a binary form. Well, with RsInstrument do not worry about the complexity:we have one method for binary or ascii array transfer.

Querying Float Arrays
Let us look at the example below. The method doing all the magic is query_bin_or_ascii_float_list(). In the 'waveform' variable, we get back a list of float numbers:
You might say: I would do this with a simple 'query-string-and-split-on-commas'... and you are right. The magic happens when we want the same waveform in binary form. One additional setting we need though-the binary data from the instrument does not contain information about its encoding. Is it 4 bytes float, or 8 bytes float? Low Endian or Big Endian? This, we specify with the property bin_float_numbers_format:
Tip  To find out in which format your instrument sends the binary data, check out the format settings:FORM REAL,32 means floats, 4 bytes per number. It might be tricky to find out whether to swap the endianness. We recommend you simply try it out-there are only two options. If you see too many NaN values returned, you probably chose the wrong one:
BinFloatFormat.Single_4bytes means the instrument and the control PC use the same endianness
BinFloatFormat.Single_4bytes_swapped means they use opposite endianness
The same is valid for double arrays:settings FORM REAL,64 corresponds to either BinFloatFormat.Double_8bytes or BinFloatFormat.Double_8bytes_swapped

Querying Integer Arrays
For performance reasons, we split querying float and integer arrays into two separate methods. The following example shows both ascii and binary array query. Here, the magic method is query_bin_or_ascii_int_list() returning list of integers.

10. Querying Binary Data
A common question from customers: How do I read binary data to a byte stream, or a file?
If you want to transfer files between PC and your instrument, check out the following chapter::doc:`12_Transferring_Files <Chapter_12_TransferringFiles>`.

Querying to bytes
Let us say you want to get raw (bytes) RTO waveform data. Call this method:
data=rto.query_bin_block('FORM REAL,32;:CHAN1:DATA?')
Querying to PC files
Modern instrument can acquire gigabytes of data, which is often more than your program can hold in memory. The solution may be to save this data to a file. RsInstrument is smart enough to read big data in chunks, which it immediately writes into a file stream. This way, at any given moment your program only holds one chunk of data in memory. You can set the chunk size with the property data_chunk_size. The initial value is 100 000 bytes.
We are going to read the RTO waveform into a PC file c:\temp\rto_waveform_data.bin:
rto.data_chunk_size=10000
rto.query_bin_block_to_file('FORM REAL,32;:CHAN1:DATA?',r'c:\temp\rto_waveform_data.bin',append=False)

11. Writing Binary Data
Writing from bytes data
We take an example for a Signal generator waveform data file. First, we construct a wform_data as bytes, and then send it with write_bin_block():
#MyWaveform.wv is an instrument file name under which this data is stored
smw.write_bin_block("SOUR:BB:ARB:WAV:DATA 'MyWaveform.wv',",wform_data)
Note Notice the write_bin_block() has two parameters:
string parameter cmd for the SCPI command
bytes parameter payload for the actual data to send
Writing from PC files
Similar to querying binary data to a file, you can write binary data from a file. The second parameter is the source PC file path with content which you want to send:
smw.write_bin_block_from_file("SOUR:BB:ARB:WAV:DATA 'MyWaveform.wv',",r"c:\temp\wform_data.wv")

12. Transferring Files
Instrument->PC
You just did a perfect measurement, saved the results as a screenshot to the instrument's storage drive. Now you want to transfer it to your PC. With RsInstrument, no problem, just figure out where the screenshot was stored on the instrument. In our case, it is var/user/instr_screenshot.png:
instr.read_file_from_instrument_to_pc(r'/var/user/instr_screenshot.png',r'c:\temp\pc_screenshot.png')
PC->Instrument
Another common scenario: Your cool test program contains a setup file you want to transfer to your instrument:Here is the RsInstrument one-liner split into 3 lines:
instr.send_file_from_pc_to_instrument('c:\MyCoolTestProgram\instr_setup.sav',r'/var/appdata/instr_setup.sav')
Tip  You want to delete a file on the instrument, and get an error, because it does not exist?
Or you want to write a file and get an error that the file exists and can not be overwritten?
Not anymore, use the file detection methods:
#Let's see if you exist...
i_exist=instr.file_exist(r'/var/appdata/instr_setup.sav')
#Give me your size or give me nothing...
my_size=instr.get_file_size(r'/var/appdata/instr_setup.sav')

13. Transferring Big Data with Progress
We can agree that it can be annoying using an application that shows no progress for long-lasting operations. The same is true for remote-control programs. Luckily, RsInstrument has this covered. And, this feature is quite universal-not just for big files transfer, but for any data in both directions.
RsInstrument allows you to register a function (programmers fancy name is handler or callback), which is then periodically invoked after transfer of one data chunk. You can define that chunk size, which gives you control over the callback invoke frequency. You can even slow down the transfer speed, if you want to process the data as they arrive (direction instrument->PC).
To show this in praxis, we are going to use another University-Professor-Example:querying the *IDN? with chunk size of 2 bytes and delay of 200ms between each chunk read:
If you start it, you might wonder (or maybe not):why is the args.total_size=None? The reason is, in this particular case the RsInstrument does not know the size of the complete response up-front. However, if you use the same mechanism for transfer of a known data size (for example, a file transfer), you get the information about the total size too, and hence you can calculate the progress as:
progress [pct]=100*args.transferred_size/args.total_size
Snippet of transferring file from PC to instrument, the rest of the code is the same as in the previous example:
instr.events.on_write_handler=my_transfer_handler
instr.events.io_events_include_data=True
instr.data_chunk_size=1000
instr.send_file_from_pc_to_instrument(r'c:\MyCoolTestProgram\my_big_file.bin',r'/var/user/my_big_file.bin')
#Unregister the event handler
instr.events.on_write_handler=None

14. Multithreading
You are at the party, many people talking over each other. Not every person can deal with such crosstalk, neither can measurement instruments. For this reason, RsInstrument has a feature of scheduling the access to your instrument by using so-called Locks. Locks make sure that there can be just one client at a time 'talking' to your instrument. Talking in this context means completing one communication step-one command write or write/read or write/read/error check.
To describe how it works, and where it matters, we take three typical multithread scenarios:

One instrument session, accessed from multiple threads
You are all set-the lock is a part of your instrument session. Check out the following example-it will execute properly, although the instrument gets 10 queries at the same time.

Shared instrument session, accessed from multiple threads
Same as in the previous case, you are all set. The session carries the lock with it. You have two objects, talking to the same instrument from multiple threads. Since the instrument session is shared, the same lock applies to both objects causing the exclusive access to the instrument.
As you see, everything works fine. If you want to simulate some party crosstalk, uncomment the line instr2.clear_lock(). This causes the instr2 session lock to break away from the instr1 session lock. Although the instr1 still tries to schedule its instrument access, the instr2 tries to do the same at the same time, which leads to all the fun stuff happening.

Multiple instrument sessions accessed from multiple threads
Here, there are two possible scenarios depending on the instrument's VISA interface:
You are lucky, because you instrument handles each remote session completely separately. 
Your instrument handles all sessions with one set of in/out buffers. You need to lock the session for the duration of a talk. And you are lucky again, because the RsInstrument takes care of it for you. The text below describes this scenario.
Run the following example:
You have two completely independent sessions that want to talk to the same instrument at the same time. This will not go well, unless they share the same session lock. The key command to achieve this is instr2.assign_lock(instr1.get_lock()) Comment that line, and see how it goes. If despite commenting the line the example runs without issues, you are lucky to have an instrument similar to the SMW200A.

15. Logging
Yes, the logging again. This one is tailored for instrument communication. You will appreciate such handy feature when you troubleshoot your program, or just want to protocol the SCPI communication for your test reports.
What can you do with the logger?
Write SCPI communication to a stream-like object, for example console or file, or both simultaneously
Log only errors and skip problem-free parts; this way you avoid going through thousands lines of texts
Investigate duration of certain operations to optimize your program's performance
Log custom messages from your program
The logged information can be sent to these targets (one or more):

Console: this is the most straight-forward target, but it mixes up with other program outputs...
Stream: the most universal one, see the examples below.
UDP Port: if you wish to send it to another program, or a universal UDP listener. This option is used for example by our Instrument Control Pycharm Plugin.
Logging to console
Console output:
10:29:10.819     TCPIP::192.168.1.101::INSTR     0.976 ms  Write:*RST
10:29:10.819     TCPIP::192.168.1.101::INSTR  1884.985 ms  Status check:OK
10:29:12.704     TCPIP::192.168.1.101::INSTR     0.983 ms  Query OPC:1
10:29:12.705     TCPIP::192.168.1.101::INSTR     2.892 ms  Clear status:OK
10:29:12.708     TCPIP::192.168.1.101::INSTR     3.905 ms  Status check:OK
10:29:12.712     TCPIP::192.168.1.101::INSTR     1.952 ms  Close:Closing session
The columns of the log are aligned for better reading. Columns meaning:
Start time of the operation
Device resource name (you can set an alias)
Duration of the operation
Log entry
Tip  You can customize the logging format with set_format_string(), and set the maximum log entry length with the properties:
abbreviated_max_len_ascii
abbreviated_max_len_bin
abbreviated_max_len_list
See the full logger help :ref:`here <Logger>`.
Notice the SCPI communication starts from the line instr.reset(). If you want to log the initialization of the session as well, you have to switch the logging ON already in the constructor:
instr=RsInstrument('TCPIP::192.168.56.101::hislip0', options='LoggingMode=On')

Logging to files
Parallel to the console logging, you can log to a general stream. Do not fear the programmer's jargon'... under the term stream you can just imagine a file. To be a little more technical, a stream in Python is any object that has two methods:write() and flush(). This example opens a file and sets it as logging target:

Integration with Python's logging module
Commonly used Python's logging can be used with RsInstrument too:

Logging from multiple sessions
We hope you are a happy Rohde & Schwarz customer, and hence you use more than one of our instruments. In such case, you probably want to log from all the instruments into a single target (file). Therefore, you open one log file for writing (or appending) and the set is as the logging target for all your sessions:
Console output:
11:43:42.657            SMW    10.712 ms  Session init:Device 'TCPIP::192.168.1.101::INSTR' IDN:Rohde&Schwarz,SMW200A,1412.0000K02/0,4.70.026 beta
11:43:42.668            SMW     2.928 ms  Status check:OK
11:43:42.686           SMCV     1.952 ms  Session init:Device 'TCPIP::192.168.1.102::INSTR' IDN:Rohde&Schwarz,SMCV100B,1432.7000K02/0,4.70.060.41 beta
11:43:42.688           SMCV     1.981 ms  Status check:OK
> Custom log from SMW session
11:43:42.690            SMW     0.973 ms  Write:*RST
11:43:42.690            SMW  1874.658 ms  Status check:OK
11:43:44.565            SMW     0.976 ms  Query OPC:1
11:43:44.566            SMW     1.952 ms  Clear status:OK
11:43:44.568            SMW     2.928 ms  Status check:OK
> Custom log from SMCV session
11:43:44.571           SMCV     0.975 ms  Query string:*IDN? Rohde&Schwarz,SMCV100B,1432.7000K02/0,4.70.060.41 beta
11:43:44.571           SMCV     1.951 ms  Status check:OK
11:43:44.573            SMW     0.977 ms  Close:Closing session
11:43:44.574           SMCV     0.976 ms  Close:Closing session
Tip  To make the log more compact, you can skip all the lines with Status check:OK:
smw.logger.log_status_check_ok=False

Logging to UDP
For logging to a UDP port in addition to other log targets, use one of the lines:
smw.logger.log_to_udp=True
smw.logger.log_to_console_and_udp=True
You can select the UDP port to log to, the default is 49200:
smw.logger.udp_port=49200

Logging from all instances
In Python everything is an object. Even class definition is an object that can have attributes. Starting with RsInstrument version 1.40.0, we take advantage of that. We introduce the logging target as a class variable (class attribute). The interesting effect of a class variable is, that it has immediate effect for all its instances. Let us rewrite the example above for multiple sessions and use the class variable not only for the log target, but also a relative timestamp, which gives us the log output starting from relative time 00:00:00:000. The created log file will have the same name as the script, but with the extension .ptc (dedicated to those who still worship R&S Forum :-)
Console output and the file content:
00:00:00.000                  SMW  1107.736 ms  Session init:Device 'TCPIP::192.168.1.101::hislip0' IDN:Rohde&Schwarz,SMW200A,1412.0000K02/0,4.70.026 beta
00:00:01.107                  SMW    82.962 ms  Status check:OK
00:00:01.190                 SMCV   960.414 ms  Session init:Device 'TCPIP::192.168.1.102::hislip0' IDN:Rohde&Schwarz,SMCV100B,1432.7000K02/0,5.00.122.24
00:00:02.151                 SMCV    81.994 ms  Status check:OK
> Custom log entry from SMW session
00:00:02.233                  SMW    40.989 ms  Write:*RST
00:00:02.233                  SMW  1910.007 ms  Status check:OK
00:00:04.143                  SMW    82.013 ms  Query OPC:1
00:00:04.225                  SMW   124.933 ms  Clear status:OK
00:00:04.350                  SMW    81.984 ms  Status check:OK
> Custom log entry from SMCV session
00:00:04.432                 SMCV    81.978 ms  Query string:*IDN? Rohde&Schwarz,SMCV100B,1432.7000K02/0,5.00.122.24
00:00:04.432                 SMCV   163.935 ms  Status check:OK
00:00:04.595                  SMW   144.479 ms  Close:Closing session
00:00:04.740                 SMCV   144.457 ms  Close:Closing session
> SMW execution time:0:00:03.451152
> SMCV execution time:0:00:01.268806
For the completion, here are all the global time functions:
RsInstrument.set_global_logging_relative_timestamp(timestamp:datetime)
RsInstrument.get_global_logging_relative_timestamp()->datetime
RsInstrument.set_global_logging_relative_timestamp_now()
RsInstrument.clear_global_logging_relative_timestamp()
and the session-specific time and statistic methods:
smw.logger.set_relative_timestamp(timestamp:datetime)
smw.logger.set_relative_timestamp_now()
smw.logger.get_relative_timestamp()->datetime
smw.logger.clear_relative_timestamp()
smw.get_total_execution_time()->timedelta
smw.get_total_time()->timedelta
smw.get_total_time_startpoint()->datetime
smw.reset_time_statistics()

Logging only errors
Another cool feature is logging only errors. To make this mode useful for troubleshooting, you also want to see the circumstances which lead to the errors. Each RsInstrument elementary operation, for example, write_str(), can generate a group of log entries-let us call them Segment. In the logging mode Errors, a whole segment is logged only if at least one entry of the segment is an error.
The script below demonstrates this feature. We deliberately misspelled a SCPI command *CLS, which leads to instrument status error:
Console output:
12:11:02.879 TCPIP::192.168.1.101::INSTR     0.976 ms  Write string:*CLaS
12:11:02.879 TCPIP::192.168.1.101::INSTR     6.833 ms  Status check:StatusException:
                                             Instrument error detected: Undefined header;*CLaS
Notice the following: Although the operation Write string:*CLaS finished without an error, it is still logged, because it provides the context for the actual error which occurred during the status checking right after.
No other log entries are present, including the session initialization and close, because they went error-free.

Example programs from Rohde-Schwarz

.. code-block::python
"""Example_DifferentVisas.py   Choosing VISA implementation"""
    from RsInstrument import *
#Force use of the Rs Visa. For e.g.: NI Visa, use the "SelectVisa='ni'"
    instr=RsInstrument('TCPIP::192.168.56.101::INSTR',True,True,"SelectVisa='rs'")
    idn=instr.query_str('*IDN?')
    print(f"\nHello, I am:'{idn}'")
    print(f"\nI am using the VISA from:{instr.visa_manufacturer}")
    instr.close()

.. code-block::python
"""Example_Exceptions.py  How to deal with RsInstrument exceptions.""" 
    from RsInstrument import *
    instr=None
#Try-catch for initialization. If an error occurs, the ResourceError is raised
    try:
        instr=RsInstrument('TCPIP::10.112.1.179::HISLIP',True,True)
    except ResourceError as e:
        print(e.args[0])
        print('Your instrument is probably OFF...')
#Exit now, no point of continuing
        exit(1)   
#Dealing with commands that potentially generate errors OPTION 1:  #Switching the status checking OFF temporarily
    instr.instrument_status_checking=False
    instr.write_str('MY:MISSpelled:COMMand')
#Clear the error queue
    instr.clear_status()
#Status checking ON again
    instr.instrument_status_checking=True
#Dealing with queries that potentially generate errors OPTION 2:
    try:
#You might want to reduce the VISA timeout to avoid long waiting
        instr.visa_timeout=1000
        instr.query_str('MY:OTHEr:WRONg:QUERy?')
    except StatusException as e:
#Instrument status error
        print(e.args[0])
        print('Nothing to see here, moving on...')
    except TimeoutException as e:
#Timeout error
        print(e.args[0])
        print('That took a long time...')
    except RsInstrException as e:
#RsInstrException is a base class for all the RsInstrument exceptions
        print(e.args[0])
        print('Some other RsInstrument error...')
    finally:
        instr.visa_timeout=5000
#Close the session in any case
        instr.close()

.. code-block::python
"""Example_FindInstrument.py  Find the instruments in your environment"""
    from RsInstrument import *
#Use the instr_list string items as resource names in the RsInstrument constructor
    instr_list=RsInstrument.list_resources("?*")
    print(instr_list)

.. code-block::python
"""Example_FindInstrument_SelectVisa.py Find the instruments in your environment with the VISA implementation"""
    from RsInstrument import *
#In the optional parameter visa_select you can use e.g.:'rs' or 'ni'  #Rs Visa also finds any NRP-Zxx USB sensors
    instr_list=RsInstrument.list_resources('?*', 'rs')
    print(instr_list)

.. code-block::python
"""Example_HelloWorld.py  Basic example on how to use the module for remote-controlling your VISA instrument. 
Preconditions:
-Installed RsInstrument Python module Version 1.50.0 or newer from pypi.org
-Installed VISA e.g. R&S Visa 5.12 or newer"""
    from RsInstrument import *
    resource_string_1='TCPIP::192.168.2.101::INSTR' #Standard LAN connection (also called VXI-11)
    resource_string_2='TCPIP::192.168.2.101::hislip0' #Hi-Speed LAN connection-see 1MA208
    resource_string_3='GPIB::20::INSTR'  #GPIB Connection
    resource_string_4='USB::0x0AAD::0x0119::022019943::INSTR' #USB-TMC (Test and Measurement Class)
    resource_string_5='RSNRP::0x0095::104015::INSTR' #R&S Powersensor NRP-Z86
#Initializing the session
    instr=RsInstrument(resource_string_1)
    idn=instr.query_str('*IDN?')
    print(f"\nHello, I am:'{idn}'")
    print(f'RsInstrument driver version:{instr.driver_version}')
    print(f'Visa manufacturer:{instr.visa_manufacturer}')
    print(f'Instrument full name:{instr.full_instrument_model_name}')
    print(f'Instrument installed options:{",".join(instr.instrument_options)}')
    instr.close()

.. code-block::python
"""Example_HelloWorldWithContextManager.py   Using Context-Manager for you RsInstrument session. 
No matter what happens inside of the 'with' section, your session is always closed properly."""
    from RsInstrument import *
    with RsInstrument('TCPIP::192.168.2.101::hislip0') as instr:
        idn=instr.query_str('*IDN?')
        print(f"\nHello, I am:'{idn}'")

.. code-block::python
"""Example_HelloWorld_SocketIO.py  Using RsInstrument without VISA for LAN Raw socket communication"""
    from RsInstrument import *
    instr=RsInstrument('TCPIP::192.168.56.101::5025::SOCKET',True,True,"SelectVisa='socket'")
    print(f'Visa manufacturer:{instr.visa_manufacturer}')
    print(f"\nHello, I am:'{instr.idn_string}'")
    print(f"\nNo VISA has been harmed or even used in this example.")
    instr.close()

.. code-block::python
"""Example_LoggingBasic.py  Basic logging example to the console"""
    from RsInstrument import *
    instr=RsInstrument('TCPIP::192.168.1.101::INSTR')
#Switch ON logging to the console.
    instr.logger.log_to_console=True
    instr.logger.mode=LoggingMode.On
    instr.reset()
    instr.close()

.. code-block::python
"""Example_LoggingError.py   Logging example to the console with only errors logged"""
    from RsInstrument import *
    instr=RsInstrument('TCPIP::192.168.1.101::INSTR',options='LoggingMode=Errors')
#Switch ON logging to the console.
    instr.logger.log_to_console=True
#Reset will not be logged, since no error occurred there
    instr.reset()
#Now a misspelled command.
    instr.write('*CLaS')
#A good command again, no logging here
    idn=instr.query('*IDN?')
    instr.close()

.. code-block:: python
"""Example of logging to a file. Example_LoggingFile.py""" 
    from RsInstrument import *
#Make sure you have the RsInstrument version 1.50.0 and newer
    RsInstrument.assert_minimum_version('1.50.0')
    instr=RsInstrument('TCPIP::192.168.1.101::INSTR')
#We also want to log to the console.
    instr.logger.log_to_console=True
#Logging target is our file
    file=open(r'c:\temp\my_file.txt', 'w')
    instr.logger.set_logging_target(file)
    instr.logger.mode=LoggingMode.On
#Instead of the 'TCPIP::192.168.1.101::INSTR', show 'MyDevice'
    instr.logger.device_name='MyDevice'
#Custom user entry
    instr.logger.info_raw('----- This is my custom log entry. ---- ')
    instr.reset() 
#Close the session
    instr.close()
#Close the log file
    file.close()

.. code-block::python
"""Example_LoggingMultipleSessions.py  Example of logging to a file shared by multiple sessions."""
    from RsInstrument import *
#Log file common for all the instruments, #previous content is discarded.
    file=open(r'c:\temp\my_file.txt','w')
#Setting of the SMW smw=RsInstrument('TCPIP::192.168.1.101::INSTR',options='LoggingMode=On,LoggingName=SMW')
    smw.logger.set_logging_target(file,console_log=True)  #Log to file and the console
#Setting of the SMCV smcv=RsInstrument('TCPIP::192.168.1.102::INSTR',options='LoggingMode=On,LoggingName=SMCV')
    smcv.logger.set_logging_target(file,console_log=True)  #Log to file and the console
    smw.logger.info_raw("> Custom log from SMW session")
    smw.reset()
    smcv.logger.info_raw("> Custom log from SMCV session")
    idn=smcv.query('*IDN?')
    smw.close()
    smcv.close()  
#Close the log file
    file.close()

.. code-block::python
"""Example_LoggingMultipleSessionsGlobal.py  Example of logging to a file shared by multiple sessions. 
The log file and the reference timestamp is set to the RsInstrument class variable, which makes it available to all the instances immediately. Each instance must set the LogToGlobalTarget=True in the constructor, or later io.logger.set_logging_target_global()"""
    from RsInstrument import *
    import os
    from pathlib import Path
    from datetime import datetime
#Log file common for all the RsInstrument instances, saved in the same folder as this #script, with the same name as this script, just with the suffix .ptc #The previous file content is discarded.
    log_file=open(Path(os.path.realpath(__file__)).stem+".ptc",'w')
    RsInstrument.set_global_logging_target(log_file)
#Here you can set relative timestamp if you do now worry about the absolute times.
    RsInstrument.set_global_logging_relative_timestamp(datetime.now())
#Setting of the SMW:log to the global target and to the console
    smw=RsInstrument(
        resource_name='TCPIP::192.168.1.101::HISLIP',          	options=f'LoggingMode=On,LoggingToConsole=True,LoggingName=SMW,LogToGlobalTarget=On')
#Setting of the SMCV:log to the global target and to the console
    smcv=RsInstrument(
        resource_name='TCPIP::192.168.1.101::HISLIP',
    options='LoggingMode=On,LoggingToConsole=True,LoggingName=SMCV,LogToGlobalTarget=On')
    smw.logger.info_raw("> Custom log entry from SMW session")
    smw.reset()
    smcv.logger.info_raw("> Custom log entry from SMCV session")
    idn=smcv.query('*IDN?')
#Close the sessions
    smw.close()
    smcv.close()
#Show how much time each instrument needed for its operations.
    smw.logger.info_raw("> SMW execution time:"+str(smw.get_total_execution_time()))
    smcv.logger.info_raw("> SMCV execution time:"+str(smcv.get_total_execution_time()))
#Close the log file
    log_file.close()

.. code-block::python
"""Example_LoggingPythonLogger.py  Example of logging to a python standard logger object."""
    import logging
    from RsInstrument import *
class LoggerStream:
"""Class to wrap the python's logging into a stream interface."""
        @staticmethod
        def write(log_entry:str)->None:
"""Method called by the RsInstrument to add the log_entry. Use it to do your custom operation, in our case calling python's logging function."""
            logging.info('RsInstrument:'+log_entry.rstrip())
        def flush(self)->None:
"""Do the operations at the end. In our case, we do nothing."""
            pass
#Setting of the SMW
    smw=RsInstrument('TCPIP::10.99.2.10::hislip0',options='LoggingMode=On,LoggingName=SMW')
#Create a logger stream object
    target=LoggerStream()
    logging.getLogger().setLevel(logging.INFO)
#Adjust the log string to not show the start time
    smw.logger.set_format_string('PAD_LEFT25(%DEVICE_NAME%) PAD_LEFT12(%DURATION%)  %LOG_STRING_INFO%:%LOG_STRING%')
    smw.logger.set_logging_target(target)  #Log to my target
    smw.logger.info_raw("> Custom log from SMW session")
    smw.reset()
#Close the sessions

.. code-block::python
"""Example_MethodsWithOpc.py Write/Query with OPC The SCPI commands syntax is for demonstration only"""
    from RsInstrument import *
    instr=RsInstrument('TCPIP::192.168.56.101::INSTR',True,True)
    instr.visa_timeout=3000
#opc_timeout default value is 10000 ms
    instr.opc_timeout=20000
#Send Reset command and wait for it to finish
    instr.write_str_with_opc('*RST')
#Initiate the measurement and wait for it to finish, define the timeout 50 secs  #Notice no changing of the VISA timeout
    instr.write_str_with_opc('INIT',50000)
#The results are ready, simple fetch returns the results  #Waiting here is not necessary
    result1=instr.query_str('FETCH:MEASUREMENT?')
#READ command starts the measurement, we use query_with_opc to wait for the measurement to finish
    result2=instr.query_str_with_opc('READ:MEASUREMENT?',50000)  
    instr.close()

.. code-block::python
"""Example_MultithreadMultipleSessions.py Multiple threads are accessing two RsInstrument objects with two separate sessions."""
    import threading
    from RsInstrument import *
    def execute(session:RsInstrument,session_ix,index)->None:
"""Executed in a separate thread."""
        print(f'{index} session {session_ix} query start...')
        session.query_str('*IDN?')
        print(f'{index} session {session_ix} query end') 
    instr1=RsInstrument('TCPIP::192.168.56.101::INSTR')
    instr2=RsInstrument('TCPIP::192.168.56.101::INSTR')
    instr1.visa_timeout=200
    instr2.visa_timeout=200
#Synchronise the sessions by sharing the same lock
    instr2.assign_lock(instr1.get_lock())  #To see the effect of crosstalk, comment this line 
    threads=[]
    for i in range(10):
        t=threading.Thread(target=execute,args=(instr1,1,i,))
        t.start()
        threads.append(t)
        t=threading.Thread(target=execute,args=(instr2,2,i,))
        t.start()
        threads.append(t)
    print('All threads started')
#Wait for all threads to join this main thread
    for t in threads:
        t.join()
    print('All threads ended')
    instr2.close()
    instr1.close()
    smw.close()
#Close the sessions
    smw.close()
    smcv.close() 
#Close the log file
    file.close()

.. code-block::python
"""Example_MultithreadOneSession.py  Multiple threads are accessing one RsInstrument object"""
    import threading
    from RsInstrument import *
    def execute(session:RsInstrument)->None:
"""Executed in a separate thread."""
        session.query_str('*IDN?')
    instr=RsInstrument('TCPIP::192.168.56.101::INSTR')
    threads=[]
    for i in range(10):
        t=threading.Thread(target=execute,args=(instr,))
        t.start()
        threads.append(t)
    print('All threads started')
#Wait for all threads to join this main thread
    for t in threads:
        t.join()
    print('All threads ended')
    instr.close()

.. code-block::python
"""Example_MultithreadSharedSession.py. Multiple threads are accessing two RsInstrument objects with shared session"""
    import threading
    from RsInstrument import *
    def execute(session:RsInstrument,session_ix,index)->None:
"""Executed in a separate thread."""
        print(f'{index} session {session_ix} query start...')
        session.query_str('*IDN?')
        print(f'{index} session {session_ix} query end')
    instr1=RsInstrument('TCPIP::192.168.56.101::INSTR')
    instr2=RsInstrument.from_existing_session(instr1)
    instr1.visa_timeout=200
    instr2.visa_timeout=200
#To see the effect of crosstalk, uncomment this line
#instr2.clear_lock()
    threads=[]
    for i in range(10):
        t=threading.Thread(target=execute,args=(instr1,1,i,))
        t.start()
        threads.append(t)
        t=threading.Thread(target=execute,args=(instr2,2,i,))
        t.start()
        threads.append(t)
    print('All threads started')
#Wait for all threads to join this main thread
    for t in threads:
        t.join()
    print('All threads ended')
    instr2.close()
    instr1.close()

.. code-block::python
"""Example_QueryFloatArray_ASCII.py  Querying ASCII float arrays."""
    from time import time
    from RsInstrument import *
    rto=RsInstrument('TCPIP::192.168.56.101::INSTR',True,True)
#Initiate a single acquisition and wait for it to finish
    rto.write_str_with_opc("SINGle",20000)
#Query array of floats in ASCII format
    t=time()
    waveform=rto.query_bin_or_ascii_float_list('FORM ASC;:CHAN1:DATA?')
    print(f'Instrument returned {len(waveform)} points, query duration {time()-t:.3f} secs')
#Close the RTO session
    rto.close()

.. code-block::python
"""Example_QueryFloatArray_Bin.py  Querying binary float arrays."""
    from RsInstrument import *
    from time import time
    rto=RsInstrument('TCPIP::192.168.56.101::INSTR',True,True)
#Initiate a single acquisition and wait for it to finish
    rto.write_str_with_opc("SINGle",20000)
#Query array of floats in Binary format
    t=time()
#This tells the RsInstrument in which format to expect the binary float data
    rto.bin_float_numbers_format=BinFloatFormat.Single_4bytes
#If your instrument sends the data with the swapped endianness, use the following 
#format:rto.bin_float_numbers_format=BinFloatFormat.Single_4bytes_swapped
    waveform=rto.query_bin_or_ascii_float_list('FORM REAL,32;:CHAN1:DATA?')
    print(f'Instrument returned {len(waveform)} points,query duration {time()-t:.3f} secs')
#Close the RTO session
    rto.close()

.. code-block::python
"""Example_QueryIntArray_AsciiBin.py  Querying ASCII and binary integer arrays."""
    from RsInstrument import *
    from time import time
    rto=RsInstrument('TCPIP::192.168.56.101::INSTR',True,True)
#Initiate a single acquisition and wait for it to finish
    rto.write_str_with_opc("SINGle",20000)
#Query array of integers in ASCII format
    t=time()
    waveform=rto.query_bin_or_ascii_int_list('FORM ASC;:CHAN1:DATA?')
    print(f'Instrument returned {len(waveform)} points in ASCII format,query duration {time()-t:.3f} secs')
#Query array of integers in Binary format
    t=time()
#This tells the RsInstrument in which format to expect the binary integer data
    rto.bin_int_numbers_format=BinIntFormat.Integer32_4bytes
#If your instrument sends the data with the swapped endianness, use the following 
#format: #rto.bin_int_numbers_format=BinIntFormat.Integer32_4bytes_swapped
    waveform=rto.query_bin_or_ascii_int_list('FORM INT,32;:CHAN1:DATA?')
    print(f'Instrument returned {len(waveform)} points in binary format, query duration {time()-t:.3f} secs')
#Close the rto session
    rto.close()

.. code-block::python
"""Example_QueryWithProgress.py  Event handlers by reading"""
    from RsInstrument import *
    import time
    def my_transfer_handler(args):
"""Function called each time a chunk of data is transferred""" #Total size is not always known at the beginning of the transfer
        total_size=args.total_size if args.total_size is not None else "unknown"
        print(f"Context:'{args.context}{'with opc' if args.opc_sync else ''}', "
                f"chunk {args.chunk_ix}, "
                f"transferred {args.transferred_size} bytes, "
                f"total size {total_size}, "
                f"direction {'reading' if args.reading else 'writing'}, "
                f"data '{args.data}'")
        if args.end_of_transfer:
            print('End of Transfer')
        time.sleep(0.2)
    instr=RsInstrument('TCPIP::192.168.56.101::INSTR',True,True)
    instr.events.on_read_handler=my_transfer_handler
#Switch on the data to be included in the event arguments  #The event arguments args.data will be updated
    instr.events.io_events_include_data=True
#Set data chunk size to 2 bytes
    instr.data_chunk_size=2
    instr.query_str('*IDN?')
#Unregister the event handler
    instr.events.on_read_handler=None
    instr.close()

.. code-block::python
"""Example_SessionSharing.py  Sharing the same physical VISA session by two different objects."""
    from RsInstrument import *
    instr1=RsInstrument('TCPIP::192.168.56.101::INSTR',True,True)
    instr2=RsInstrument.from_existing_session(instr1)
    print(f'instr1:{instr1.idn_string}')
    print(f'instr2:{instr2.idn_string}')
#Closing the instr2 session does not close the instr1 session-instr1 is the 'session master'
    instr2.close()
    print(f'instr2:I am closed now')
    print(f'instr1:I am still opened and working:{instr1.idn_string}')
    instr1.close()
    print(f'instr1:Only now I am closed.')

.. code-block::python
"""Example_SimpleStringIo.py  Basic string write_str/query_str"""
    from RsInstrument import *
    instr=RsInstrument('TCPIP::192.168.56.101::INSTR',True,True)
    instr.reset()
    print(instr.idn_string)
    instr.close()

.. code-block::python
"""Example_SimpleStringIoOtherTypes.py  Basic string write_xxx/query_xxx"""
    from RsInstrument import *
    instr=RsInstrument('TCPIP::192.168.56.101::INSTR',True,True)
    instr.visa_timeout=5000
    instr.instrument_status_checking=True
    instr.write_int('SWEEP:COUNT ',10)               #sending 'SWEEP:COUNT 10'
    instr.write_bool('SOURCE:RF:OUTPUT:STATE ',True) #sending 'SOURCE:RF:OUTPUT:STATE ON'
    instr.write_float('SOURCE:RF:FREQUENCY ',1E9)    #sending 'SOURCE:RF:FREQUENCY 1000000000'
    sc=instr.query_int('SWEEP:COUNT?')               #returning integer number sc=10
    out=instr.query_bool('SOURCE:RF:OUTPUT:STATE?')  #returning boolean out=True
    freq=instr.query_float('SOURCE:RF:FREQUENCY?')   #returning float number freq=1E9
    instr.close()

.. code-block::python
"""Example_SimpleStringIoUniversity.py  Basic string write_str/query_str"""
    from RsInstrument import *
    instr=RsInstrument('TCPIP::192.168.56.101::INSTR',True,True)
    instr.write_str('*RST')
    response=instr.query_str('*IDN?')
    print(response)
    instr.close()
.. autoclass::ScpiLogger()
   .. autoattribute::mode
   .. autoattribute::default_mode
   .. autoattribute::device_name
   .. automethod::set_logging_target
   .. automethod::get_logging_target
   .. automethod::set_logging_target_global
   .. autoattribute::log_to_console
   .. autoattribute::log_to_udp
   .. autoattribute::log_to_console_and_udp
   .. automethod::info_raw
   .. automethod::info
   .. automethod::error
   .. automethod::set_relative_timestamp
   .. automethod::set_relative_timestamp_now
   .. automethod::get_relative_timestamp
   .. automethod::clear_relative_timestamp
   .. automethod::flush
   .. autoattribute::log_status_check_ok
   .. automethod::clear_cached_entries
   .. automethod::set_format_string
   .. automethod::restore_format_string
   .. autoattribute::abbreviated_max_len_ascii
   .. autoattribute::abbreviated_max_len_bin
   .. autoattribute::abbreviated_max_len_list
   .. autoattribute::bin_line_block_size
   .. autoattribute::udp_port
   .. autoattribute::target_auto_flushing
.. automodule::RsInstrument.RsInstrument
   :members:
   :undoc-members:
   :show-inheritance:
.. automodule::RsInstrument
   :members:
   :undoc-members:
   :show-inheritance:

"""Event-related methods and properties. Here you can set all the event handlers."""
from typing import Callable
from ..Internal import Core
class Events:
"""Common Events class. Event-related methods and properties. Here you can set all the event handlers."""
	def __init__(self,core:Core):
		self._core=core
	@property
	def io_events_include_data(self)->bool:
"""Returns the current state of the io_events_include_data. See the setter for more details."""
		return self._core.io.io_events_include_data
	@io_events_include_data.setter
	def io_events_include_data(self,value:bool)->None:
"""If True, the on_write and on_read events include also the transferred data. Default value is False, to avoid handling potentially big data."""
		self._core.io.io_events_include_data=value
	@property
	def before_write_handler(self)->Callable:
"""Returns the handler of before_write events. \n  :return:current ``before_write_handler``"""
		return self._core.io.before_write_handler
	@before_write_handler.setter
	def before_write_handler(self,handler:Callable)->None:
"""Sets handler for before_write events. The before_write event is invoked before each write operation (only once, not for every chunk)  Event prototype:handler(io:Instrument,cmd:str)  :param handler:new handler"""
		self._core.io.before_write_handler=handler
	@property
	def on_write_handler(self)->Callable:
"""Returns the handler of on_write events. \n  :return:current ``on_write_handler``"""
		return self._core.io.on_write_handler
	@on_write_handler.setter
	def on_write_handler(self,handler:Callable)->None:
"""Sets handler for on_write events. The on_write event is invoked every time the driver performs a write operation to the instrument (for each write chunk)  Event arguments type:IoTransferEventArgs
By default, the event_args do not contain the actual data sent. If you wish to receive them, set the driver. Events.io_events_include_data to True \n  :param handler:new handler for all write operations."""
		self._core.io.on_write_handler=handler
	@property
	def on_read_handler(self)->Callable:
"""Returns the handler of on_read events. \n  :return:current ``on_read_handler``"""
		return self._core.io.on_read_handler
	@on_read_handler.setter
	def on_read_handler(self,handler:Callable)->None:
"""Sets handler for on_read events. The on_read event is invoked every time the driver performs a read operation to the instrument. Event arguments type:IoTransferEventArgs  By default, the event_args do not contain the actual data sent. If you wish to receive them, set the driver.Events.io_events_include_data to True \n  :param handler:new handler for all read operations."""
		self._core.io.on_read_handler=handler
	@property
	def before_query_handler(self)->Callable:
"""Returns the handler of before_query events. \n  :return:current ``before_query_handler``"""
		return self._core.io.before_query_handler
	@before_query_handler.setter
	def before_query_handler(self,handler:Callable)->None:
"""Sets handler for before_query events. The before_query event is invoked before each query operation (only once, not for every chunk)  Event prototype:handler(io:Instrument,query:str) :param handler:new handler"""
		self._core.io.before_query_handler=handler
	def sync_from(self,source:'Events')->None:
"""Synchronises these Events with the source."""
		self.before_query_handler=source.before_query_handler
		self.before_write_handler=source.before_write_handler
		self.io_events_include_data=source.io_events_include_data
		self.on_read_handler=source.on_read_handler
		self.on_write_handler=source.on_write_handler

"""Reliability.py"""
import time
from typing import Callable
from ..Internal import ArgLinkedEventArgs
from ..Internal import Core
codes_table={
				0:      'OK',
				1:      'Measurement Timeout',
				2:      'Capture Buffer Overflow',
				3:      'Over-driven',
				4:      'Under-driven',
				6:      'Trigger Timeout',
				7:      'Acquisition Error',
				8:      'Sync Error',
				9:      'Uncalibrated',
				15:     'Reference Frequency Error',
				16:     'RF Not Available',
				17:     'RF Level not Settled',
				18:     'RF Frequency not Settled',
				19:     'Call not Established',
				20:     'Call Type not Usable',
				21:     'Call Lost',
				23:     'Missing Option',
				24:     'Invalid RF Setting',
				26:     'Resource Conflict',
				27:     'No Sensor Connected',
				28:     'Unexpected Parameter Change',
				30:     'File not Found',
				31:     'No DTM reply',
				32:     'ACL Disconnected',
				40:     'ARB File CRC Error',
				42:     'ARB Header Tag Invalid',
				43:     'ARB Segment Overflow',
				44:     'ARB File not Found',
				45:     'ARB Memory Overflow',
				46:     'ARB Sample Rate out of Range',
				47:     'ARB Cycles out of Range',
				50:     'Startup Error',
				51:     'No Reply',
				52:     'Connection Error',
				53:     'Configuration Error',
				54:     'Filesystem Error',
				60:     'Invalid RF-Connector Setting',
				93:     'OCXO Oven Temperature too low',
				101:    'Firmware Error',
				102:    'Unidentified Error',
				103:    'Parameter Error',
				104:    'Not Functional'}
class ReliabilityEventArgs:
"""Arguments for reliability indicator event."""
	def __init__(self,timestamp,code:int,message:str,context:str):
		self.timestamp=timestamp
		self.message=message
		self.code=code
		self.message=message
		self.context=context
class Reliability:
"""Reliability class that handles all the necessary tasks related to reliability indicator."""
	def __init__(self,core:Core):
		self._core:Core=core
		self._last_value:int=0
		self._last_context:str=''
		self._last_timestamp=None
		self._exception_on_error=False
#noinspection PyTypeChecker
		self._on_update_handler:Callable=None
		self._core.set_link_handler('Reliability',self._permanent_on_update_handler)
	@property
	def last_value(self)->int:
"""Returns the last updated Reliability code."""
		return self._last_value
	@property
	def last_context(self)->str:
"""Returns the last updated Context of the reliability code - usually the SCPI query on which the instrument responded with the Reliability code."""
		return self._last_context
	@property
	def last_timestamp(self)->time:
"""Returns the time of the last Reliability update."""
		return self._last_timestamp
	@property
	def last_message(self)->str:
"""Returns the LastValue of the reliability table converted to human-readable string."""
		if self._last_value in codes_table:
			return codes_table[self._last_value]
		else:
			return f'Undefined reliability code {self._last_value}.'
	@property
	def exception_on_error(self)->bool:
"""If True, (default is False) the object throws an exception if the updated reliability is not 0 (non-OK)."""
		return self._exception_on_error
	@exception_on_error.setter
	def exception_on_error(self,value)->None:
"""If True, (default is False) the object throws an exception if the updated reliability is not 0 (non-OK)."""
		self._exception_on_error=value
	def on_update_handler(self,handler:Callable)->None:
"""Register the handler for on_update event. This handler is invoked with each update of the reliability indicator.
Handler API:handler(event_args:ReliabilityEventArgs)"""
		self._on_update_handler=handler
	def _permanent_on_update_handler(self,event_args:ArgLinkedEventArgs)->None:
"""Permanent on_update handler. Takes care of updating all the 'last_xxx' values and calling a user-defined updated_handler."""
		self._last_value=int(str(event_args.value))
		self._last_context=event_args.context
		self._last_timestamp=event_args.timestamp
		if self._on_update_handler:
#Call the additional handler if registered
	rel_events_args=ReliabilityEventArgs(self._last_timestamp,self._last_value,self.last_message,self._last_context)
			self._on_update_handler(rel_events_args)
		if self._exception_on_error and self._last_value!=0:
			raise Exception(
				f'Reliability indicator error. Time:{time.strftime("%H:%M:%S",time.localtime(self._last_timestamp))},'
				f'Context:{self._last_context},Value {self._last_value}:{self.last_message}')
	def sync_from(self,source:'Reliability')->None:
"""Synchronises this Reliability with the source."""
		self.exception_on_error=source.exception_on_error
		self.on_update_handler(source._on_update_handler)

"""Utilities extending the driver for methods provided with RsInstrument."""
from typing import List,Tuple
import threading
from ..Internal import Core
from ..Internal import Conversions as Conv
from ..Internal.ScpiLogger import ScpiLogger
class Utilities:
"""Common utility class. Utility functions common for all types of drivers. \n
Access snippet:``utils=[DRIVER_PREFIX].utilities``"""
	def __init__(self,core:Core):
		self._core=core
	@property
	def logger(self)->ScpiLogger:
"""Scpi Logger interface, see :ref:`here <Logger>` \n
Access snippet:``logger=[DRIVER_PREFIX].utilities.logger``"""
		return self._core.io.logger
	@property
	def driver_version(self)->str:
"""Returns the instrument driver version."""
		return self._core.driver_version
	@property
	def idn_string(self)->str:
"""Returns instrument's identification string-the response on the SCPI command *IDN?"""
		return self._core.io.idn_string
	@property
	def manufacturer(self)->str:
"""Returns manufacturer of the instrument."""
		return self._core.io.manufacturer
	@property
	def full_instrument_model_name(self)->str:
"""Returns the current instrument's full name e.g. 'FSW26'."""
		return self._core.io.full_model_name
	@property
	def instrument_model_name(self)->str:
"""Returns the current instrument's family name e.g. 'FSW'."""
		return self._core.io.model
	@property
	def supported_models(self)->List[str]:
"""Returns a list of the instrument models supported by this instrument driver."""
		return self._core.supported_instr_models
	@property
	def instrument_firmware_version(self)->str:
"""Returns instrument's firmware version."""
		return self._core.io.firmware_version
	@property
	def instrument_serial_number(self)->str:
"""Returns instrument's serial_number."""
		return self._core.io.serial_number
	def query_opc(self,timeout:int=0)->int:
"""SCPI command: *OPC?
Queries the instrument's OPC bit and hence it waits until the instrument reports operation complete.
If you define timeout>0, the VISA timeout is set to that value just for this method call."""
		return self._core.io.query_opc(timeout)
	@property
	def instrument_status_checking(self)->bool:
"""Sets/returns Instrument Status Checking.
When True (default is True), all the driver methods and properties are sending "SYSTem:ERRor?"
at the end to immediately react on error that might have occurred.
We recommend to keep the state checking ON all the time. Switch it OFF only in rare cases when you require maximum speed.
The default state after initializing the session is ON."""
		return self._core.io.query_instr_status
	@instrument_status_checking.setter
	def instrument_status_checking(self,value)->None:
"""Sets/returns Instrument Status Checking. When True (default is True), all the driver methods and properties are sending "SYSTem:ERRor?" at the end to immediately react on error that might have occurred. We recommend to keep the state checking ON all the time. Switch it OFF only in rare cases when you require maximum speed. The default state after initializing the session is ON."""
		self._core.io.query_instr_status=value
	@property
	def encoding(self)->str:
"""Returns string<=>bytes encoding of the session."""
		return self._core.io.encoding
	@encoding.setter
	def encoding(self,value:str)->None:
"""Sets string<=>bytes encoding of the session."""
		self._core.io.encoding=value
	@property
	def opc_query_after_write(self)->bool:
"""Sets/returns Instrument *OPC? query sending after each command write. When True, (default is False) the driver sends *OPC? every time a write command is performed. Use this if you want to make sure your sequence is performed command-after-command."""
		return self._core.io.opc_query_after_write
	@opc_query_after_write.setter
	def opc_query_after_write(self,value)->None:
"""Sets/returns Instrument *OPC? query sending after each command write. When True, (default is False) the driver sends *OPC? every time a write command is performed. Use this if you want to make sure your sequence is performed command-after-command."""
		self._core.io.opc_query_after_write=value
	@property
	def bin_float_numbers_format(self)->Conv.BinFloatFormat:
"""Sets/returns format of float numbers when transferred as binary data."""
		return self._core.io.bin_float_numbers_format
	@bin_float_numbers_format.setter
	def bin_float_numbers_format(self,value:Conv.BinFloatFormat)->None:
"""Sets/returns format of float numbers when transferred as binary data."""
		self._core.io.bin_float_numbers_format=value
	@property
	def bin_int_numbers_format(self)->Conv.BinIntFormat:
"""Sets/returns format of integer numbers when transferred as binary data."""
		return self._core.io.bin_int_numbers_format
	@bin_int_numbers_format.setter
	def bin_int_numbers_format(self,value:Conv.BinIntFormat)->None:
"""Sets/returns format of integer numbers when transferred as binary data."""
		self._core.io.bin_int_numbers_format=value
	def clear_status(self)->None:
"""Clears instrument's status system, the session's I/O buffers and the instrument's error queue."""
		return self._core.io.clear_status()
	def query_all_errors(self)->List[str] or None:
"""Queries and clears all the errors from the instrument's error queue. The method returns list of strings as error messages. If no error is detected, the return value is None. The process is:querying 'SYSTem:ERRor?' in a loop until the error queue is empty. If you want to include the error codes, call the  query_all_errors_with_codes()"""
		return self._core.io.query_all_syst_errors(include_codes=False)
	def query_all_errors_with_codes(self)->List[Tuple[int,str]] or None:
"""Queries and clears all the errors from the instrument's error queue. The method returns list of tuples (code:int,message:str). If no error is detected, the return value is None. The process is:querying 'SYSTem:ERRor?' in a loop until the error queue is empty."""
		return self._core.io.query_all_syst_errors(include_codes=True)
	@property
	def instrument_options(self)->List[str]:
"""Returns all the instrument options. The options are sorted in the ascending order starting with K-options and continuing with B-options."""
		return self._core.io.instr_options.get_all()
	def reset(self)->None:
"""SCPI command:*RST  Sends *RST command+calls the clear_status()."""
		self._core.io.reset()
		self.default_instrument_setup()
	def default_instrument_setup(self)->None:
"""Custom steps performed at the init and at the reset()."""
	def self_test(self,timeout:int=None)->Tuple[int,str]:
"""SCPI command:*TST?  Performs instrument's self-test. Returns tuple (code:int,message:str). Code 0 means the self-test passed. You can define the custom timeout in milliseconds. If you do not define it, the default selftest timeout is used (usually 60 s)."""
		return self._core.io.self_test(timeout)
	def is_connection_active(self)->bool:
"""Returns true, if the VISA connection is active and the communication with the instrument still works."""
		return self._core.io.is_connection_active()
	def reconnect(self,force_close:bool=False)->bool:
"""If the connection is not active, the method tries to reconnect to the device
If the connection is active, and force_close is False, the method does nothing.
If the connection is active, and force_close is True, the method closes, and opens the session again. Returns True, if the reconnection has been performed."""
		return self._core.io.reconnect(force_close)
	@property
	def resource_name(self)->int:
"""Returns the resource name used in the constructor"""
		return self._core.io.resource_name
	@property
	def opc_timeout(self)->int:
"""Sets/returns timeout in milliseconds for all the operations that use OPC synchronization."""
		return self._core.io.opc_timeout
	@opc_timeout.setter
	def opc_timeout(self,value:int)->None:
"""Sets/returns timeout in milliseconds for all the operations that use OPC synchronization."""
		self._core.io.opc_timeout=value
	@property
	def visa_timeout(self)->int:
"""Sets/returns visa IO timeout in milliseconds."""
		return self._core.io.visa_timeout
	@visa_timeout.setter
	def visa_timeout(self,value)->None:
"""Sets/returns visa IO timeout in milliseconds."""
		self._core.io.visa_timeout=value
	@property
	def data_chunk_size(self)->int:
"""Sets/returns the maximum size of one block transferred during write/read operations."""
		return self._core.io.data_chunk_size
	@data_chunk_size.setter
	def data_chunk_size(self,chunk_size:int)->None:
"""Sets/returns the maximum size of one block transferred during write/read operations."""
		self._core.io.data_chunk_size=chunk_size
	@property
	def visa_manufacturer(self)->int:
"""Returns the manufacturer of the current VISA session."""
		return self._core.io.visa_manufacturer
	def process_all_commands(self)->None:
"""SCPI command:*WAI  Stops further commands processing until all commands sent before *WAI have been executed."""
		return self._core.io.write('*WAI')
	def write_str(self,cmd:str)->None:
"""Writes the command to the instrument."""
		self._core.io.write(cmd)
	def write(self,cmd:str)->None:
"""This method is an alias to the write_str(). Writes the command to the instrument as string."""
		self._core.io.write(cmd)
	def write_int(self,cmd:str,param:int)->None:
"""Writes the command to the instrument followed by the integer parameter: e.g.:cmd='SELECT:INPUT' param='2', result command='SELECT:INPUT 2'"""
		self._core.io.write(f'{cmd} {param}')
	def write_int_with_opc(self,cmd:str,param:int,timeout:int=None)->None:
"""Writes the command with OPC to the instrument followed by the integer parameter: e.g.:cmd='SELECT:INPUT' param='2', result command='SELECT:INPUT 2'  If you do not provide timeout, the method uses current opc_timeout."""
		self._core.io.write_with_opc(f'{cmd} {param}',timeout)
	def write_float(self,cmd:str,param:float)->None:
"""Writes the command to the instrument followed by the boolean parameter: e.g.:cmd='CENTER:FREQ' param='10E6',result command='CENTER:FREQ 10E6'"""
		self._core.io.write(f'{cmd} {Conv.float_to_str(param)}')
	def write_float_with_opc(self,cmd:str,param:float,timeout:int=None)->None:
"""Writes the command with OPC to the instrument followed by the boolean parameter: e.g.:cmd='CENTER:FREQ' param='10E6',result command='CENTER:FREQ 10E6'  If you do not provide timeout, the method uses current opc_timeout."""
		self._core.io.write_with_opc(f'{cmd} {Conv.float_to_str(param)}',timeout)
	def write_bool(self,cmd:str,param:bool)->None:
"""Writes the command to the instrument followed by the boolean parameter: e.g.:cmd='OUTPUT' param='True',result command='OUTPUT ON'"""
		self._core.io.write(f'{cmd} {Conv.bool_to_str(param)}')
	def write_bool_with_opc(self,cmd:str,param:bool,timeout:int=None)->None:
"""Writes the command with OPC to the instrument followed by the boolean parameter: e.g.:cmd='OUTPUT' param='True', result command='OUTPUT ON'  If you do not provide timeout, the method uses current opc_timeout."""
		self._core.io.write_with_opc(f'{cmd} {Conv.bool_to_str(param)}',timeout)
	def query_str(self,query:str)->str:
"""Sends the query to the instrument and returns the response as string. The response is trimmed of any trailing LF characters and has no length limit."""
return self._core.io.query_str(query)
	def query(self,query:str)->str:
"""This method is an alias to the query_str(). Sends the query to the instrument and returns the response as string.
The response is trimmed of any trailing LF characters and has no length limit."""
		return self._core.io.query_str(query)
	def query_bool(self,query:str)->bool:
"""Sends the query to the instrument and returns the response as boolean."""
		return self._core.io.query_bool(query)
	def query_int(self,query:str)->int:
"""Sends the query to the instrument and returns the response as integer."""
		return self._core.io.query_int(query)
	def query_float(self,query:str)->float:
"""Sends the query to the instrument and returns the response as float."""
		return self._core.io.query_float(query)
	def write_str_with_opc(self,cmd:str,timeout:int=None)->None:
"""Writes the opc-synced command to the instrument.
If you do not provide timeout, the method uses current opc_timeout."""
		self._core.io.write_with_opc(cmd,timeout)
	def write_with_opc(self,cmd:str,timeout:int=None)->None:
"""This method is an alias to the write_str_with_opc(). Writes the opc-synced command  to the instrument. If you do not provide timeout, the method uses current opc_timeout."""
		self._core.io.write_with_opc(cmd,timeout)
	def query_str_with_opc(self,query:str,timeout:int=None)->str:
"""Sends the opc-synced query to the instrument and returns the response as string.
The response is trimmed of any trailing LF characters and has no length limit.
If you do not provide timeout, the method uses current opc_timeout."""
		return self._core.io.query_str_with_opc(query,timeout)
	def query_with_opc(self,query:str,timeout:int=None)->str:
"""This method is an alias to the query_str_with_opc(). Sends the opc-synced query to the instrument and returns the response as string. The response is trimmed of any trailing LF characters and has no length limit. If you do not provide timeout, the method uses current opc_timeout."""
		return self._core.io.query_str_with_opc(query,timeout)
	def query_bool_with_opc(self,query:str,timeout:int=None)->bool:
"""Sends the opc-synced query to the instrument and returns the response as boolean. If you do not provide timeout, the method uses current opc_timeout."""
		return self._core.io.query_bool_with_opc(query,timeout)
	def query_int_with_opc(self,query:str,timeout:int=None)->int:
"""Sends the opc-synced query to the instrument and returns the response as integer. If you do not provide timeout, the method uses current opc_timeout."""
		return self._core.io.query_int_with_opc(query,timeout)
	def query_float_with_opc(self,query:str,timeout:int=None)->float:
"""Sends the opc-synced query to the instrument and returns the response as float. If you do not provide timeout, the method uses current opc_timeout."""
		return self._core.io.query_float_with_opc(query,timeout)
	def write_bin_block(self,cmd:str,payload:bytes)->None:
"""Writes all the payload as binary data block to the instrument. The binary data header is added at the beginning of the transmission automatically, do not include it in the payload!!!"""
		self._core.io.write_bin_block(cmd,payload)
	def query_bin_block(self,query:str)->bytes:
"""Queries binary data block to bytes. Throws an exception if the returned data was not a binary data. Returns data:bytes."""
		return self._core.io.query_bin_block(query)
	def query_bin_block_with_opc(self,query:str,timeout:int=None)->bytes:
"""Sends a OPC-synced query and returns binary data block to bytes. If you do not provide timeout, the method uses current opc_timeout."""
		return self._core.io.query_bin_block_with_opc(query,timeout)
	def query_bin_or_ascii_float_list(self,query:str)->List[float]:
"""Queries a list of floating-point numbers that can be returned in ASCII format or in binary format.
- For ASCII format, the list numbers are decoded as comma-separated values.
- For Binary Format, the numbers are decoded based on the property BinFloatFormat, usually float 32-bit (FORM REAL,32)."""
		return self._core.io.query_bin_or_ascii_float_list(query)
	def query_bin_or_ascii_float_list_with_opc(self,query:str,timeout:int=None)->List[float]:
"""Sends a OPC-synced query and reads a list of floating-point numbers that can be returned in ASCII format or in binary format.
- For ASCII format, the list numbers are decoded as comma-separated values.
- For Binary Format, the numbers are decoded based on the property BinFloatFormat, usually float 32-bit (FORM REAL,32).
If you do not provide timeout, the method uses current opc_timeout."""
		return self._core.io.query_bin_or_ascii_float_list_with_opc(query,timeout)
	def query_bin_or_ascii_int_list(self,query:str)->List[int]:
"""Queries a list of floating-point numbers that can be returned in ASCII format or in binary format.
- For ASCII format, the list numbers are decoded as comma-separated values.
- For Binary Format, the numbers are decoded based on the property BinFloatFormat, usually float 32-bit (FORM REAL,32)."""
		return self._core.io.query_bin_or_ascii_int_list(query)
	def query_bin_or_ascii_int_list_with_opc(self,query:str,timeout:int=None)->List[int]:
"""Sends a OPC-synced query and reads a list of floating-point numbers that can be returned in ASCII format or in binary format.
- For ASCII format, the list numbers are decoded as comma-separated values.
- For Binary Format, the numbers are decoded based on the property BinFloatFormat, usually float 32-bit (FORM REAL,32).
If you do not provide timeout, the method uses current opc_timeout."""
		return self._core.io.query_bin_or_ascii_int_list_with_opc(query,timeout)
	#Write/Read to file
	def query_bin_block_to_file(self,query:str,file_path:str,append:bool=False)->None:
"""Queries binary data block to the provided file.
If append is False, any existing file content is discarded.
If append is True, the new content is added to the end of the existing file, or if the file does not exit, it is created.
Throws an exception if the returned data was not a binary data.
Example for transferring a file from Instrument->PC:
	query=f"MMEM:DATA? '{INSTR_FILE_PATH}'".
Alternatively, use the dedicated methods for this purpose:
- ``send_file_from_pc_to_instrument()``
- ``read_file_from_instrument_to_pc()``"""
		self._core.io.query_bin_block_to_file(query,file_path,append)
	def query_bin_block_to_file_with_opc(self,query:str,file_path:str,append:bool=False,timeout:int=None)->None:
"""Sends a OPC-synced query and writes the returned data to the provided file.
If append is False, any existing file content is discarded.
If append is True, the new content is added to the end of the existing file, or if the file does not exit, it is created.
Throws an exception if the returned data was not a binary data."""
	self._core.io.query_bin_block_to_file_with_opc(query,file_path,append,timeout)
	def write_bin_block_from_file(self,cmd:str,file_path:str)->None:
"""Writes data from the file as binary data block to the instrument using the provided command. Example for transferring a file from PC->Instrument:
cmd=f"MMEM:DATA '{INSTR_FILE_PATH}',". Alternatively, use the dedicated methods for this purpose:
- ``send_file_from_pc_to_instrument()``
- ``read_file_from_instrument_to_pc()``"""
		self._core.io.write_bin_block_from_file(cmd,file_path)
	def send_file_from_pc_to_instrument(self,source_pc_file:str,target_instr_file:str)->None:
"""SCPI Command:MMEM:DATA \n Sends file from PC to the instrument"""	self._core.io.send_file_from_pc_to_instrument(source_pc_file,target_instr_file)
	def read_file_from_instrument_to_pc(self,source_instr_file:str,target_pc_file:str,append_to_pc_file:bool=False)->None:
"""SCPI Command:MMEM:DATA? \n  Reads file from instrument to the PC. \n
Set the ``append_to_pc_file`` to True if you want to append the read content to the end of the existing PC file"""
self._core.io.read_file_from_instrument_to_pc(source_instr_file,target_pc_file,append_to_pc_file)
	def get_last_sent_cmd(self)->str:
"""Returns the last commands sent to the instrument. Only works in simulation mode"""
		return self._core.get_last_sent_cmd()
	def go_to_local(self)->None:
"""Puts the instrument into local state."""
		self._core.io.go_to_local()
	def go_to_remote(self)->None:
"""Puts the instrument into remote state."""
		self._core.io.go_to_remote()
	def get_lock(self)->threading.RLock:
"""Returns the thread lock for the current session. \n
By default:-If you create standard new [DRIVER_PREFIX] instance with new VISA session, the session gets a new thread lock. You can assign it to other [DRIVER_PREFIX] sessions in order to share one physical instrument with a multi-thread access.
- If you create new [DRIVER_PREFIX] from an existing session, the thread lock is shared automatically making both instances multi-thread safe. You can always assign new thread lock by calling ``driver.utilities.assign_lock()``"""
		return self._core.io.get_lock()
	def assign_lock(self,lock:threading.RLock)->None:
"""Assigns the provided thread lock."""
		self._core.io.assign_lock(lock)
	def clear_lock(self):
"""Clears the existing thread lock, making the current session thread-independent from others that might share the current thread lock."""
		self._core.io.clear_lock()
	def sync_from(self,source:'Utilities')->None:
"""Synchronises these Utils with the source."""
		self.logger.sync_from(source.logger)
		self.assign_lock(source.get_lock())
		self.bin_float_numbers_format=source.bin_float_numbers_format
		self.bin_int_numbers_format=source.bin_int_numbers_format
		self.data_chunk_size=source.data_chunk_size
		self.encoding=source.encoding
		self.instrument_status_checking=source.instrument_status_checking
		self.opc_query_after_write=source.opc_query_after_write
		self.opc_timeout=source.opc_timeout


"""ScpiLogger.py"""
import socket
from enum import Enum
from datetime import datetime
import re
import string
from typing import List
from textwrap import wrap
from .Utilities import get_plural_string,shorten_string_middle,escape_nonprintable_chars,size_to_kb_mb_string,calculate_chunks_count
from .InstrumentErrors import RsInstrException
from .Conversions import list_to_csv_str,convert_ts_to_datetime,get_timedelta_string,get_timestamp_string,get_timedelta_fixed_string
from .GlobalData import GlobalData
class LoggingMode(Enum):
"""Determines the format of the logging message."""
    Off=0      #Don't write messages to log
    On=1       #Write message to log
    Errors=2   #Only log errors. This is like 'Off', with the exception, that VisaIOErrors are logged.
    Default=3  #Default mode
class LogEntry:
"""One entry in the log Defined by content, which has all the variables resolved except the START_TIME and the end_time."""
    _tab_var_re=re.compile(r'PAD_(LEFT|RIGHT)(\d+)\(%(START_TIME|END_TIME|DURATION|DEVICE_NAME|LOG_STRING_INFO|LOG_STRING)%\)')
    _var_re=re.compile(r'%(START_TIME|END_TIME|DURATION|DEVICE_NAME|LOG_STRING_INFO|LOG_STRING)%')
    def __init__(self,start_time:datetime or None or float,end_time:datetime or None or float,device_name:str,log_string_info:str,log_string:str,add_new_line:bool,error:bool,raw:bool,binary:bool):
        self._start_time:datetime=start_time
        self._end_time:datetime=end_time
        self._device_name:str=device_name
        self._log_string_info:str=log_string_info
        self._log_string:str=log_string
        self._raw:bool=raw
        self._binary:bool=binary
        self._timestamp_reference_time:datetime or None=None
#Public properties
        self.add_new_line:bool=add_new_line
        self.error:bool=error
    @classmethod
    def as_raw_content(cls,content:str,add_new_line:bool)->'LogEntry':
"""Create the entry as raw"""
        return cls(start_time=None,end_time=None,device_name='',log_string_info='',log_string=content,add_new_line=add_new_line,error=False,raw=True,binary=False)
    @classmethod
    def as_raw_error_content(cls,content:str,add_new_line:bool)->'LogEntry':
"""Create the entry as raw"""
        return cls(start_time=None,end_time=None,device_name='',log_string_info='',log_string=content,add_new_line=add_new_line,error=True,raw=True,binary=False)
    @classmethod
    def as_info_entry(cls,start_time:datetime or None,end_time:datetime or None,device_name:str,log_string_info:str,log_string:str,add_new_line:bool)->'LogEntry':
"""Create the entry as info entry."""
        return cls(start_time=start_time,end_time=end_time,device_name=device_name,log_string_info=log_string_info,log_string=log_string,add_new_line=add_new_line,error=False,raw=False,binary=False)
    @classmethod
    def as_error_entry(cls,start_time:datetime or None,end_time:datetime or None,device_name:str,log_string_info:str,log_string:str,add_new_line:bool)->'LogEntry':
"""Create the entry as info entry."""
        return cls(start_time=start_time,end_time=end_time,device_name=device_name,log_string_info=log_string_info,log_string=log_string,add_new_line=add_new_line,error=True,raw=False,binary=False)
    @classmethod
    def as_info_bin_entry(cls,start_time:datetime or None,end_time:datetime or None,device_name:str,log_string_info:str,log_string:str,add_new_line:bool)->'LogEntry':
"""Create the entry as info entry."""
        return cls(start_time=start_time,end_time=end_time,device_name=device_name,log_string_info=log_string_info,log_string=log_string,add_new_line=add_new_line,error=False,raw=False,binary=True)
    def set_timestamp_reference_time(self,ref_time:datetime):
"""Sets reference time for the start time. None (default value) means the start time is absolute."""
        self._timestamp_reference_time=ref_time
    def get_resolved_content(self,template:str,encoding:str)->str:
"""Returns the resolved content. For raw entry it means only the log_string."""
        if self._raw is True:
            return self._log_string
        result_str=self._replace_variables(template)
#For non-binary data, trim the end and escape the non-printable chars.
        if self._binary is False:
            result_str=result_str.rstrip(':')
            result_str=escape_nonprintable_chars(result_str,encoding)
        return result_str
    def _replace_variables(self,format_string:str)->str:
"""Replaces all the variables in the entered template string with their actual values."""
        content=format_string
        while True:
            m=self._tab_var_re.search(content)
            if m:
                pos_left=m.group(1)=='LEFT'
                spaces=int(m.group(2).strip())
                var_name=m.group(3).strip().strip('%')
                value=self._get_log_string_variable_values(var_name)
                value=value.rjust(spaces) if pos_left else value.ljust(spaces)
                content=content[:m.start()]+value+content[m.end():]
                continue
            m=self._var_re.search(content)
            if m:
                var_name=m.group(1)
                value=self._get_log_string_variable_values(var_name)
                if not value:
                    print(f'Value:{value} var_name "{var_name}" log_info:{self._log_string_info}')
                content=content[:m.start()]+value+content[m.end():]
                continue
            break
        return content
    def _get_log_string_variable_values(self,name:str)->str:
"""Returns the required variable value. Recognised names:START_TIME, END_TIME, DURATION, DEVICE_NAME, LOG_STRING_INFO, LOG_STRING"""
        if name=='START_TIME':
            if self._start_time is None:
                return ''
            if self._timestamp_reference_time is None:
                return get_timestamp_string(self._start_time)
            else:
                return get_timedelta_fixed_string(self._timestamp_reference_time,self._start_time)
        if name=='END_TIME':
            if self._end_time is None:
                return ''
            return get_timestamp_string(self._end_time)
        if name=='DURATION':
            if self._start_time is None or self._end_time is None:
                return ''
            return get_timedelta_string(self._start_time,self._end_time)
        if name=='DEVICE_NAME':
            if self._device_name is None:
                return ''
            return self._device_name
        if name=='LOG_STRING_INFO':
            if self._log_string_info is None:
                return ''
            return self._log_string_info
        if name=='LOG_STRING':
            return self._log_string
class Segment:
"""Segment of logs."""
    def __init__(self):
        self.error_present=False
        self.entries:List[LogEntry]=[]
    def add_to_segment(self,entry:LogEntry)->None:
"""Adds an entry to the current segment."""
        self.entries.append(entry)
        if entry.error is True:
            self.error_present=True
    def empty(self)->None:
"""Empties the list of entries for the current segment."""
        self.error_present=False
        self.entries=[]
    def __del__(self):
        self.empty()
class CachedEntries:
"""Entries that are cached internally, in case no target is defined, but the logging is ON"""
    def __init__(self):
        self.entries:List[LogEntry]=[]
        self.truncated_count=0
        self.clear()
    def append(self,entry:LogEntry)->None:
"""Appends one entry. If the list is longer than 1000 entries, the oldest one is deleted and truncated_count is increased by 1."""
        self.entries.append(entry)
        if len(self.entries)>1000:
            self.entries.pop(0)
            self.truncated_count+=1
        return
    def clear(self)->None:
"""Clears all the cached entries."""
        self.entries=[]
        self.truncated_count=0
    def __del__(self):
        self.clear()
class ScpiLogger:
"""Base class for SCPI logging"""
    def __init__(self,resource_name:str,encoding:str='charmap'):
        if resource_name is None:
            raise RsInstrException('resource_name cannot be None')
        self._orig_resource_name=resource_name
        self._global_mode:bool=False
        self._default_mode:LoggingMode=LoggingMode.Off
        self._mode:LoggingMode=self._default_mode
        self._log_target_local=None
        self._cached=CachedEntries()
        self._timestamp_reference_time_local:datetime or None=None
        self._format_string:str=''
        self._line_divider:str='\n'
        self._target_auto_flushing=True
        self.restore_format_string()
        self._log_to_console=False
        self._log_to_udp=False
        self._udp_port=49200
#Transients
        self._segment:Segment or None=None
        self._log_status_check_ok:bool=True
        self._socket=None
#Printable chars set
        self._printable_chars=set(bytes(string.printable,'ascii'))
        self._printable_chars.remove(10)
        self._printable_chars.remove(13)
        self._printable_chars.remove(32)
        self._printable_chars.remove(9)
#Public properties
        self.device_name:str=resource_name
"""Use this property to change the resource name in the log from the default Resource Name (e.g. TCPIP::192.168.2.101::INSTR) to another name e.g. 'MySigGen1'."""
        self.abbreviated_max_len_ascii:int=200
"""Defines the maximum length of one ASCII log entry. Default value is 200 characters."""
        self.abbreviated_max_len_list:int=100
"""Defines the maximum length of one list entry. Default value is 100 elements."""
        self.abbreviated_max_len_bin:int=2048
"""Defines the maximum length of one Binary log entry. Default value is 2048 bytes."""
        self.bin_line_block_size:int=16
"""Defines number of bytes to display in one line. Default value is 16 bytes."""
        self.encoding=encoding
"""Defines encoding of the strings into bytes. Default is charmap."""
        self.allow_log_string_adjust=True
"""Specifies whether log string adjustment is allowed. Default is True."""
    def __str__(self):
        value=f"ScpiLogger for '{self.device_name}'"
        if self.mode!=LoggingMode.Off:
            value+=f' mode:{self._mode.name}'
        else:
            value+=f' OFF'
        if self.log_to_console is False and self._log_to_udp is False and self.get_logging_target() is None:
            return value
        value+=',target:'
        if self.log_to_console:
            value+='console+'
        if self.log_to_udp:
            value+='udp+'
        if self._global_mode:
            value+='global stream'
        elif self._log_target_local:
            value+='stream'
        return value.strip('+ ')
    def start_new_segment(self)->None:
"""Only relevant for if the log mode is LoggingMode.Errors. In this mode, all the logging is delayed until you call end_current_segment()  Then, only if an error occurred, the logs are flushed to the output log. In case no error occurred, the logs are deleted."""
        if self._segment:
            self.end_current_segment()
            raise RsInstrException('Segment was not property finished before the new one was started.')
#Logging to segment is only started if the logging mode is set to LoggingMode.Errors
#That causes in mode ON all the entries appear immediately, rather than being delayed until the segment is ended
        self._segment=None
        if self._mode==LoggingMode.Errors:
            self._segment=Segment()
    def end_current_segment(self)->None:
"""Only relevant for if the log mode is LoggingMode.Errors.
Calling this method causes the logger to either flush all the segment logs to the output log or delete them if no error occurred. This causes only the errors to be logged, but also with the appropriate context, so you can troubleshoot more easily."""
        if self._segment:
            curr_segment=self._segment
            self._segment=None
            if self._mode==LoggingMode.Errors and curr_segment.error_present:
#If error mode is on, and the segment contains at least one error entry, write the segment entries to the log for entry in curr_segment.entries:
                    self._write_to_log(entry)
    def set_format_string(self,value:str,line_divider:str='\n')->None:
"""Sets new format string and line divider. If you just want to set the line divider, set the format string value=None
The original format string is:``PAD_LEFT12(%START_TIME%) PAD_LEFT25(%DEVICE_NAME%) PAD_LEFT12(%DURATION%)  %LOG_STRING_INFO%:%LOG_STRING%`` """
        if value is not None:
            self._format_string=value
        self._line_divider=line_divider
    def restore_format_string(self)->None:
"""Restores the original format string and the line divider to LF """
        self._format_string='PAD_LEFT12(%START_TIME%) PAD_LEFT30(%DEVICE_NAME%) PAD_LEFT12(%DURATION%)  %LOG_STRING_INFO%:%LOG_STRING%'
        self._line_divider='\n'
    def clear_cached_entries(self)->None:
"""Clears potential cached log entries. Cached log entries are generated when the Logging is ON, but no target has been defined yet."""
        self._cached.clear()
    def set_logging_target(self,target,console_log:bool or None=None,udp_log:bool or None=None)->None:
"""Sets logging target-the target must implement write() and flush(). You can optionally set the console and UDP logging ON or OFF. This method switches the logging target global OFF."""
        self._log_target_local=target
        self._global_mode=False
        if console_log is not None:
            self._log_to_console=console_log
        if udp_log is not None:
            self._log_to_udp=udp_log
        self._flush_cached_entries()
    def set_logging_target_global(self,console_log:bool or None=None,udp_log:bool or None=None)->None:
"""Sets logging target to global. The global target must be defined. You can optionally set the console and UDP logging ON or OFF."""
        if GlobalData.get_logging_target() is None:
            raise RsInstrException(f"Cannot set the logging to global target, because the global target has not been defined. Device name:'{self.device_name}'")
        self._global_mode=True
        if console_log is not None:
            self._log_to_console=console_log
        if udp_log is not None:
            self._log_to_udp=udp_log
        self._flush_cached_entries()
    def get_logging_target(self):
"""Based on the global_mode, it returns the logging target:either the local or the global one."""
        return self._log_target_local if self._global_mode is False else GlobalData.get_logging_target()
    def get_relative_timestamp(self)->datetime or None:
"""Based on the global_mode, it returns the relative timestamp:either the local or the global one."""
        return self._timestamp_reference_time_local if self._global_mode is False else GlobalData.get_logging_relative_timestamp()
    @property
    def target_auto_flushing(self)->bool:
"""Returns status of the auto-flushing for the logging target."""
        return self._target_auto_flushing
    @target_auto_flushing.setter
    def target_auto_flushing(self,value:bool)->None:
"""Sets auto-flushing for the logging target. If set to True (default value), after each entry the stream is flushed. This makes sure, that even if your e.g. file stream is not closed at the end, it contains all the entries."""
        self._target_auto_flushing=value
    @property
    def mode(self)->LoggingMode:
"""Sets the logging ON or OFF. Additionally, you can set the logging ON only for errors. Possible values:
* LoggingMode.Off -logging is switched OFF
* LoggingMode.On -logging is switched ON
* LoggingMode.Errors -logging is switched ON, but only for error entries
* LoggingMode.Default -sets the logging to default-the value you have set with logger.default_mode"""
        return self._mode
    Off=0      #Don't write messages to log
    On=1       #Write message to log
    Errors=2   #Only log errors. This is like 'Off', with the exception, that VisaIOErrors are logged.
    Default=3  #Default mode
    @mode.setter
    def mode(self,value:LoggingMode)->None:
"""Sets/returns the Logging mode."""
        if self._segment:
            raise RsInstrException(f"Can not change the logging mode when a log segment is active. End the segment with ScpiLogger.end_current_segment(). Device name:'{self.device_name}'")
        value=self._resolve_log_mode(value)
        if self.mode!=LoggingMode.Off:
#logging is ON. Check the internal log entries and flush them to the target
            self._flush_cached_entries()
        self._mode=value
        if self._mode==LoggingMode.Off and self.get_logging_target():
#Logging was switched off, flush the entries on the target
            self.flush()
    @property
    def log_status_check_ok(self)->bool:
"""Sets/returns the current status of status checking OK. If True (default), the log contains logging of the status checking 'Status check:OK'. If False, the 'Status check:OK' is skipped-the log is more compact. Errors will still be logged."""
        return self._log_status_check_ok
    @log_status_check_ok.setter
    def log_status_check_ok(self,value:bool)->None:
"""Sets new logging of status checking OK. If True (default), the log contains logging of the status checking 'Status check:OK'. If False, the 'Status check:OK' is skipped-the log is more compact. Errors will still be logged."""
        self._log_status_check_ok=value
        self.info(datetime.now(),None,'Logging of \'Status Check OK\'','ON' if value is True else 'OFF')
    @property
    def log_to_console(self)->bool:
"""Returns logging to console status."""
        return self._log_to_console
    @log_to_console.setter
    def log_to_console(self,value:bool)->None:
"""Sets logging to console. Default value is False."""
        self._log_to_console=value
        if self._log_to_console is True:
            self._flush_cached_entries()
    @property
    def log_to_udp(self)->bool:
"""Returns logging to UDP status."""
        return self._log_to_udp
    @log_to_udp.setter
    def log_to_udp(self,value:bool)->None:
"""Sets logging to UDP. Default value is False."""
        self._log_to_udp=value
        if self._log_to_udp is True:
            self._flush_cached_entries()
    @property
    def log_to_console_and_udp(self)->bool:
"""Returns true, if both logging to UDP and console in are True."""
        return self.log_to_udp and self.log_to_console
    @log_to_console_and_udp.setter
    def log_to_console_and_udp(self,value:bool)->None:
"""Sets logging to UDP and console in one call. Compare to calling two methods, this one flushes potential cached entries to both targets."""
        self._log_to_console=value
        self._log_to_udp=value
        if self._log_to_console is True:
            self._flush_cached_entries()
    @property
    def udp_port(self)->int:
"""Returns udp logging port."""
        return self._udp_port
    @udp_port.setter
    def udp_port(self,value:int)->None:
"""Sets UDP logging port. Default value is 49200."""
        self._udp_port=value
    def set_relative_timestamp(self,timestamp:datetime)->None:
"""If set, the further timestamps will be relative to the entered time."""
        self._timestamp_reference_time_local=convert_ts_to_datetime(timestamp)
    def set_relative_timestamp_now(self)->None:
"""Sets the relative timestamp to the current time."""
        self.set_relative_timestamp(datetime.now())
    def clear_relative_timestamp(self)->None:
"""Clears the reference time, and the further logging continues with absolute times."""
        self._timestamp_reference_time_local=None
    def _target_exists(self):
"""Returns true, if the target either console or udp, or stream exist."""
        return self.get_logging_target() is not None or self.log_to_console is True or self._log_to_udp is True
    def _flush_cached_entries(self)->bool:
"""Flushes internal log to the log target. Returns true if flushed."""
        if not self._target_exists():
            return False
        if self._cached.truncated_count>0:
            self._write_to_log(LogEntry.as_raw_content(f'-- Missing {self._cached.truncated_count} oldest entries --',True))
        for entry in self._cached.entries:
            entry.set_timestamp_reference_time(self.get_relative_timestamp())
            self._write_to_log(entry)
        self.clear_cached_entries()
        return True
    def _resolve_log_mode(self,value:LoggingMode)->LoggingMode:
"""Resolves the potential default mode."""
        if value==LoggingMode.Default:
            return self._default_mode
        else:
            return value
    @property
    def default_mode(self)->LoggingMode:
"""Sets/returns the default logging mode. You can recall the default mode by calling the logger.mode=LoggingMode. Default:Data Type:LoggingMode"""
        return self._default_mode
    @default_mode.setter
    def default_mode(self,value:LoggingMode)->None:
"""Sets the default logging mode. You can recall the default mode by calling the logger.mode=LoggingMode.Default"""
        if value==LoggingMode.Default:
            raise ValueError('LoggingMode.Default can not be set here. Use a specific value.')
        self._default_mode=value
    def _write_to_log(self,entry:LogEntry)->None:
"""Logs the provided string to the target and optionally to the stdout. Error signals that the entry is an error entry."""
#Check if the segment is active and if so, write the log only to the segment.
        if self._segment:
            self._segment.add_to_segment(entry)
            return
        if not self._target_exists():
#No target is defined yet, cache the entries internally for now
            self._cached.append(entry)
            return
#only now, before writing to the log target, resolve the content.
        entry.set_timestamp_reference_time(self.get_relative_timestamp())
        content=entry.get_resolved_content(self._format_string,self.encoding)
        if self.log_to_console:
            print(content)
        if self.log_to_udp:
            self._send_to_udp(content,entry.error)
        target=self.get_logging_target()
        if target:
            new_line=self._line_divider if entry.add_new_line else ''
            try:
                target.write(content+new_line)
                if self._target_auto_flushing:
                    target.flush()
            except Exception as e:
                msg=f'Error logging to the stream. Message:\'{content}\'. Error:{e.args[0]}'
                raise RsInstrException(msg)
        return
    def _send_to_udp(self,content:str,error:bool):
"""Sends the log string to the defined udp port. Any socket exception is consumed."""
        prefix='[e]' if error else '[i]'
        msg=bytes(prefix+content,"utf-8")
        try:
            if self._socket is None:
                self._socket=socket.socket(socket.AF_INET,socket.SOCK_DGRAM)
            self._socket.sendto(msg,("127.0.0.1",self._udp_port))
        finally:
            return
    def info_raw(self,log_entry:str,add_new_line:bool=True)->None:
"""Method for logging the raw string without any formatting."""
        if self.mode==LoggingMode.Off:
            return
        if self._mode==LoggingMode.Errors:
#For errors logging mode, log the info only if the segment is active.
#That means, it might be logged eventually as a context when the segment ends with an error
            if not self._segment:
                return
        entry=LogEntry.as_raw_content(log_entry,add_new_line)
        self._write_to_log(entry)
    def _info_as_raw_entry(self,log_entry:LogEntry)->None:
"""Method for logging the entry."""
        if self.mode==LoggingMode.Off:
            return
        if self._mode==LoggingMode.Errors:
#For errors logging mode, log the info only if the segment is active.
#That means, it might be logged eventually as a context when the segment ends with an error
            if not self._segment:
                return
        self._write_to_log(log_entry)
    def info(self,start_time:datetime or float or None,end_time:datetime or float or None,log_string_info:str,log_string:str)->None:
"""Method for logging one info entry. For binary log_string, use the info_bin()"""
        if self.mode==LoggingMode.Off:
            return
        entry=self._compose_log_entry(start_time,end_time,log_string_info,log_string,self.abbreviated_max_len_ascii)
        entry.add_new_line=True
        self._info_as_raw_entry(entry)

    def info_bin(self,start_time:datetime or float or None,end_time:datetime or float or None,log_string_info:str,log_data:bytes)->None:
"""Method for logging one info entry where the log_data is binary (bytes)."""
        if self.mode==LoggingMode.Off:
            return
        entry=self._compose_bin_log_entry(start_time,end_time,log_string_info,log_data)
        entry.add_new_line=True
        self._info_as_raw_entry(entry)

    def info_list(self,start_time:datetime or float or None,end_time:datetime or float or None,log_string_info:str,list_data:List)->None:
"""Method for logging one info entry where the list_data is decimal List[]."""
        if self.mode==LoggingMode.Off:
            return
        delimiter=','
        if len(list_data) <=self.abbreviated_max_len_list:
            log_string=f'List size {len(list_data)}:{list_to_csv_str(list_data,delimiter=delimiter)}'
        else:
            chunk=self.abbreviated_max_len_list // 2
            log_string=f'List size {len(list_data)},showing first and last {chunk} elements:'
            log_string+=list_to_csv_str(list_data[:chunk],delimiter=delimiter)
            log_string+=' .... '
            log_string+=list_to_csv_str(list_data[-chunk:],delimiter=delimiter)
        entry=self._compose_log_entry(start_time,end_time,log_string_info,log_string,max_log_string_len=None)
        entry.add_new_line=True
        self._info_as_raw_entry(entry)
    def error_raw(self,log_entry:str,add_new_line:bool=True)->None:
"""Method for logging one error entry without any formatting. Setting the error flag to True."""
        if self.mode==LoggingMode.Off:
            return
        if self._segment:
            self._segment.error_present=True
        entry=LogEntry.as_raw_error_content(log_entry,add_new_line)
        self._write_to_log(entry)
    def _error_as_raw_entry(self,log_entry:LogEntry)->None:
"""Method for logging one error entry."""
        if self.mode==LoggingMode.Off:
            return
        if self._segment:
            self._segment.error_present=True
        log_entry.error=True
        log_entry.add_new_line=True
        self._write_to_log(log_entry)
    def error(self,start_time:datetime or float or None,end_time:datetime or float or None,log_string_info:str,log_string:str)->None:
"""Method for logging one error entry."""
        if self.mode==LoggingMode.Off:
            return
        entry=self._compose_log_entry(start_time,end_time,log_string_info,log_string,self.abbreviated_max_len_ascii)
        self._error_as_raw_entry(entry)
    def _adjust_log_strings(self,value:str)->str:
"""Adjusts the log string to prevent repeating of the information in the fields."""
#Prevent repeating of the device name:
        if self.allow_log_string_adjust and 'DEVICE_NAME' in self._format_string:
            value=value.replace(f"'{self._orig_resource_name}':",'')
            value=value.replace(f"'{self._orig_resource_name}' ",'')
            value=value.replace(f"'{self._orig_resource_name}'",'')
            value=value.replace(self._orig_resource_name,'')
        return value
    def _adjust_for_repeated_log_string_info(self,log_string_info:str,log_string)->str:
#Prevent repeating of the log string info in the log_string
        if 'LOG_STRING_INFO' in self._format_string:
            log_string=log_string.replace(f'{log_string_info}:','')
            log_string=log_string.replace(f'{log_string_info} ','')
            log_string=log_string.replace(f'{log_string_info}','')
            log_string=log_string.replace(log_string_info,'')
        return log_string
    def _compose_log_entry(self,start_time:datetime or float,end_time:datetime or float,log_string_info:str,log_string:str,max_log_string_len:int=None)->LogEntry:
"""Composes the log string with the format defined in the self._format_string"""
        log_string_info=self._adjust_log_strings(log_string_info)
        log_string=self._adjust_log_strings(log_string)
        log_string=self._adjust_for_repeated_log_string_info(log_string_info,log_string)
        orig_len=len(log_string)
#Shorten the long log strings
        if max_log_string_len is not None:
            if orig_len>self.abbreviated_max_len_ascii:
                log_string=shorten_string_middle(log_string,max_log_string_len)     entry=LogEntry(start_time,end_time,self.device_name,log_string_info,log_string,add_new_line=False,error=False,raw=False,binary=False)
        return entry
    def _compose_bin_log_entry(self,start_time:datetime or float,end_time:datetime or float,log_string_info:str,log_data:bytes)->LogEntry:
"""Composes the binary log string with the format defined in the self._format_string"""
        log_string_info=self._adjust_log_strings(log_string_info)
        log_string_info=escape_nonprintable_chars(log_string_info,self.encoding)
        log_string=self._compose_hexdump(log_data,offset_left=20)    entry=LogEntry(start_time,end_time,self.device_name,log_string_info,log_string,add_new_line=False,error=False,raw=False,binary=True)
        return entry
    def _compose_hexdump(self,value:str or bytes,offset_left:int)->str:
"""Composes hexdump string from string or bytes. The hex dump is organised in the groups of 16 bytes per line."""
        if isinstance(value,str):
            value=bytes(value,self.encoding)
        size=len(value)
        line=f'{size_to_kb_mb_string(size,True)}'
        padding=' '*offset_left
        right_padding=self.bin_line_block_size*3-1
        max_lines=calculate_chunks_count(self.abbreviated_max_len_bin,self.bin_line_block_size)
        lines_count=calculate_chunks_count(size,self.bin_line_block_size)
        skipping=False
        skip_start=0
        skip_size=0
        if lines_count>(max_lines+1):
#Skip the lines in the middle
            skip_start=max_lines // 2
            if skip_start==0:
                skip_start=1
            skip_size=lines_count-max_lines
            if skip_start>0 and skip_size>0:
                skipping=True
                line+=f',showing {max_lines} blocks (1 block={self.bin_line_block_size} bytes) out of {lines_count},skipped {get_plural_string("block",skip_size)} in the middle'
                skip_start*=self.bin_line_block_size
                skip_size*=self.bin_line_block_size
        ix=0
        end=0
        line+=self._line_divider
        while end<size:
            if skipping and ix >=skip_start:
                ix+=skip_size
                line+=padding+('...'*self.bin_line_block_size)+self._line_divider
                skipping=False
            end=ix+self.bin_line_block_size
            if end >=size:
                end=size
            chunk=value[ix:end]
            cp=[chr(c) if c in self._printable_chars else '.' for c in chunk]
            line+=padding+' '.join(wrap(chunk.hex(),2)).ljust(right_padding)+'    '+''.join(cp)+self._line_divider
            ix+=self.bin_line_block_size
        return line
    def flush(self)->None:
"""Flush all the entries."""
        target=self.get_logging_target()
        if target:
            try:
#The file might be already closed.
                target.flush()
            except ValueError:
                pass
    def __del__(self):
        self.flush()
    def sync_from(self,source:'ScpiLogger')->None:
"""Synchronises this Logger with the source."""
        self._orig_resource_name=source._orig_resource_name
        self.mode=source.mode
        self.default_mode=source.default_mode
        self.log_status_check_ok=source.log_status_check_ok
        self.log_to_console=source.log_to_console
        self.log_to_udp=source.log_to_udp
        self.udp_port=source.udp_port
        self.set_format_string(source._format_string,source._line_divider)
        self._target_auto_flushing=source._target_auto_flushing
        self._log_target_local=source._log_target_local
        self._timestamp_reference_time_local=source._timestamp_reference_time_local
        if source._global_mode is True:
            self.set_logging_target_global()
#Public properties
        self.device_name=source.device_name
        self.abbreviated_max_len_ascii=source.abbreviated_max_len_ascii
        self.abbreviated_max_len_list=source.abbreviated_max_len_list
        self.abbreviated_max_len_bin=source.abbreviated_max_len_bin
        self.bin_line_block_size=source.bin_line_block_size
        self.encoding=source.encoding
        self.allow_log_string_adjust=source.allow_log_string_adjust

"""ArgLinkedEventArgs.py"""
import time
class ArgLinkedEventArgs(object):
"""Contains event data for suppressed argument."""
	def __init__(self,link_name:str,arg_name:str,value:object=None,context:str='',timestamp:time=None):
		self.link_name=link_name
		self.arg_name=arg_name
		self.value=value
		self.context=context
		self.timestamp=timestamp
	def __str__(self):
		result=f"ArgLinkedEventArgs '{self.link_name}'"
		if self.arg_name:
			result+=f"argument name '{self.arg_name}'"
		result+=f"value:{self.value}"
		return result

"""ArgSingle.py"""
from .ConverterFromScpiString import ConverterFromScpiString
from .ConverterToScpiString import ConverterToScpiString
from .InstrumentErrors import RsInstrException
from .Types import DataType
class ArgSingle(object):
"""Single Argument outside a structure-used for composing query arguments. Contains the argument value as well (self.value)."""
	def __init__(self,name:str,value,data_type:DataType,enum_type=None,is_optional:bool=False,is_open_list:bool=False,repetition:int=1,intern_link:str=None):
		self.name=name if name else ''
		self.argument_ix=None
		self.value=value
		self.data_type=data_type
		self.enum_type=enum_type
		self.is_optional=is_optional
		self.is_open_list=is_open_list
		self.repetition=repetition
		self.intern_link=intern_link
		self.conv_from_scpi_string=None
		self.conv_to_scpi_string=None
		if self.data_type.is_scalar_enum:
#self.assert_mandatory_has_value(self)
			self.conv_from_scpi_string=ConverterFromScpiString(self.data_type,self.enum_type)
			self.conv_to_scpi_string=ConverterToScpiString(self.data_type,self.enum_type)
		elif self.data_type.is_list_enum:
#self.assert_mandatory_has_value(self)
			if self.value is not None:
				self.conv_from_scpi_string=ConverterFromScpiString(self.data_type,self.enum_type)
				self.conv_to_scpi_string=ConverterToScpiString(self.data_type,self.enum_type)
		else:
			self.conv_from_scpi_string=ConverterFromScpiString(self.data_type)
			self.conv_to_scpi_string=ConverterToScpiString(self.data_type)
		self.check_consistency()
	@classmethod
	def as_open_list(cls,name:str,value:object,data_type:DataType,enum_type=None)->'ArgSingle':
"""Creates new ArgSingle of open list type.Use this method for all non-interleaved list types. \n
:param name:name of the argument
:param value:value of the argument
:param data_type:data type of the argument
:param enum_type:enum type if the data_type is Enum or EnumExt (or list of those)
:return:ArgSingle object of an open list type"""
		return cls(name,value,data_type,enum_type,False,True,1,None)
	def __str__(self):
		opt='~' if self.is_optional else ''
		name=f" '{self.name}'" if self.name!='' else ''
		out=f"SingleArg {opt}{self.data_type.name}{name}"
		if self.is_open_list is False and self.repetition>1:
			out+=f' [{self.repetition}]'
		elif self.is_open_list is True:
			out+=f' [{self.repetition}...]'
		if self.intern_link:
			out+=f",Linking:'{self.intern_link}'"
		if self.value:
			out+=f',value:{self.value}'
		else:
			out+=",<no value>"
		if self.intern_link:
			out+=f",Linking:'{self.intern_link}'"
		return out
#noinspection PyUnusedLocal
	def has_value(self,value_obj=None)->bool:
"""Returns true, if the argument has value."""
		return self.value is not None
#noinspection PyUnusedLocal
	def assert_is_optional(self,obj=None)->None:
"""Asserts that the parameter is optional. If not, the method throws an exception."""
		if self.is_optional:
			return
		raise RsInstrException(f'Single argument is not optional:{self}')
#noinspection PyUnusedLocal
	def assert_mandatory_has_value(self,value_obj=None)->None:
"""Asserts that if the parameter is mandatory, it must have value assigned. If not, the method throws an exception."""
		if self.is_optional:
			return
		if self.value is None:
			raise ValueError(f'Mandatory single argument has no value:{self}')
	def set_scalar_value_from_str(self,string:str)->None:
		"""Sets scalar value from input string"""
		self.value=self.conv_from_scpi_string.get_value(string)
	def check_consistency(self)->None:
		"""Checks the consistency of the object"""
		if self.value is None:
			return
		if isinstance(self.value,list):
			if self.data_type.is_scalar:
				raise RsInstrException(f'Argument real data type is list, but it is declared as {self.data_type}. Value:{self.value}')
		else:
			if self.data_type.is_list:
				raise RsInstrException(f'Argument real data type is scalar, but it is declared as {self.data_type}. Value:{self.value}')

"""ArgSingleList.py"""
from .ArgSingle import ArgSingle
from .ArgStringComposer import compose_cmd_string_from_single_args
class ArgSingleList(object):
"""Contains methods for composing cmd string for the list of single arguments. Used in methods with 1+ set or query arguments. The instance does not have a fixed args list, you can use the instance method compose_cmd_string with different arguments."""
	def __init__(self):
		self.args=None
	def compose_cmd_string(self,arg1:ArgSingle,arg2:ArgSingle=None,arg3:ArgSingle=None,arg4:ArgSingle=None,arg5:ArgSingle=None,arg6:ArgSingle=None,arg7:ArgSingle=None,arg8:ArgSingle=None,arg9:ArgSingle=None):
"""Composes the string cmd argument from the arguments list.
		Same treatment as in the ArgStructList.compose_cmd_string().
		The difference is in handling the value of the argument."""
		self.args=dict()
		ix=0
		for arg in [arg1,arg2,arg3,arg4,arg5,arg6,arg7,arg8,arg9]:
			if arg:
				self.args[ix]=arg
				ix+=1
		return compose_cmd_string_from_single_args(self.args)

"""ArgSingleSuppressed.py"""
from .Types import DataType
class ArgSingleSuppressed(object):
"""Single suppressed Argument-used in Query_XxXx_Suppressed() to remove it from the returned value. It does not contain:
- 'value' attribute, since this is discarded or linked internally directly  in the Query_XxXx_Suppressed().
- 'is_optional' attribute, since it is always mandatory."""
	def __init__(self, argument_ix:int, data_type:DataType, is_open_list:bool=False, repetition:int=1, intern_link:str=None):
		self.name=''
		self.argument_ix=argument_ix
		self.data_type=data_type
		self.is_open_list=is_open_list
		self.repetition=repetition
		self.intern_link=intern_link
	def __str__(self):
		out=f"{self.data_type.name} '{self.name}' SuppressedArg"
		if self.is_open_list is False and self.repetition>1:
			out+=f' [{self.repetition}]'
		elif self.is_open_list is True:
			out+=f' [{self.repetition}...]'
		if self.intern_link:
			out+=f", Linking:'{self.intern_link}'"
		return out

"""ArgStringComposer.py"""
"""- class SingleComposer-for composing SCPI string parameters from ArgSingle
- class StructComposer-for composing SCPI string parameters from ArgStruct
- function compose_cmd_string_from_struct_args-takes ArgStruct values and converts it to a SCPI string parameter.
- function compose_cmd_string_from_single_args-takes ArgSingle[] values and converts them to a SCPI string parameter.
The composing of the SCPI parameter string is similar for the ArgStruct and ArgSingle[] objects, therefore they share the same module."""
from typing import Dict
from .ArgSingle import ArgSingle
from .ArgStruct import ArgStruct
from .Utilities import get_plural_string
from .InstrumentErrors import RsInstrException
class SingleComposer:
"""Composes strings for single argument.
Provides Composer interface with 3 functions:
- from_scalar_arg
- from_list_arg
- get_arg_list_size"""
	@staticmethod
	def from_scalar_arg(arg:ArgSingle)->str:
"""Takes argument's scalar value and converts it to a SCPI parameter string."""
		if not arg.is_optional and arg.value is None:
			raise ValueError(f"StructArgComposer.from_scalar_arg()-mandatory argument's '{arg.name}' value is None")
		assert arg.data_type.is_scalar, f"StructArgComposer.from_scalar_arg()-argument '{arg.name}' must be scalar. Data type:'{arg.data_type}'"
		if arg.value is None:
			return ''
		return arg.conv_to_scpi_string.get_value(arg.value)
	@staticmethod
	def from_list_arg(arg:ArgSingle, start_ix=0, items_count=-1)->str:
"""Takes argument's List of elements and converts it to a csv-string of SCPI parameters.
		start_ix defines where to start in the list.
		items_count defines how many items to take. -1 means all of them"""
		if not arg.is_optional and arg.value is None:
			raise ValueError(f"StructArgComposer.from_list_arg()-mandatory argument's '{arg.name}' value is None")
		assert arg.data_type.is_list, f"StructArgComposer.from_list_arg()-argument must be list. Data type:'{arg.data_type}'"
		if not arg.is_optional:
		     assert arg.value is not None, f"StructArgComposer.from_list_arg()-mandatory argument's '{arg.name}' value is None"
		if arg.value is None:
			return ''
		if start_ix==0 and items_count<0:
			return arg.conv_to_scpi_string.get_value(arg.value)
		elif items_count<0:
			return arg.conv_to_scpi_string.get_value(arg.value[start_ix])
		elif items_count==0:
			return ''
		elif items_count>0:
			return arg.conv_to_scpi_string.get_value(arg.value[start_ix:start_ix+items_count])
	@staticmethod
	def get_arg_list_size(arg:ArgSingle)->int:
"""Returns list size of the argument assuming it is a list. If the argument is not a list, the method returns -1."""
		if arg.data_type.is_scalar:
			return -1
		else:
			return len(arg.value)
class StructComposer:
"""Composes strings for structure arguments.
Provides Composer interface with 3 functions:
- from_scalar_arg
- from_list_arg
- get_arg_list_size \n
The StructComposer constructor has the owning struct instance as parameter, because this is needed to access the argument value."""
	def __init__(self, struct):
		self.struct=struct
	def from_scalar_arg(self, arg:ArgStruct)->str:
"""Returns a single argument value converted to string."""
		assert arg.data_type.is_scalar, f"StructArgComposer.from_scalar_arg()-argument must be scalar. Data type:'{arg.data_type}'"
		return arg.conv_to_scpi_string.get_value(getattr(self.struct, arg.name))
	def from_list_arg(self, arg:ArgStruct, start_ix=0, items_count=-1)->str:
"""Returns csv-string with all the elements from the argument value."""
		assert arg.data_type.is_list, f"StructArgComposer.from_list_arg()-argument must be list. Data type:'{arg.data_type}'"
		if start_ix==0 and items_count<0:
			return arg.conv_to_scpi_string.get_value(getattr(self.struct, arg.name))
		elif items_count<0:
			return arg.conv_to_scpi_string.get_value(getattr(self.struct, arg.name)[start_ix])
		elif items_count==0:
			return ''
		elif items_count>0:
			return arg.conv_to_scpi_string.get_value(getattr(self.struct, arg.name)[start_ix:start_ix+items_count])
	def get_arg_list_size(self, arg:ArgStruct)->int:
"""Returns list size of the argument assuming it is a list. If the argument is not a list, the method returns -1."""
		if arg.data_type.is_scalar:
			return -1
		else:
			return len(getattr(self.struct, arg.name))
def compose_cmd_string_from_struct_args(args:Dict[int, ArgStruct], composer:StructComposer, values_obj:object)->str:
"""Returns SCPI-composed string based on the structure args specification."""
	arg_count=len(args)
	string_arg=[]
	arg_ix=0
	opt_null_ix=-1
#Non-repeated arguments-single values or arrays which are not open lists
#Non-open lists or scalars must be at the beginning of the definition
#Once the first open list argument is detected, continue further
	while arg_ix<arg_count and args[arg_ix].is_open_list is False:
		arg=args[arg_ix]
		if arg.has_value(values_obj) is False:
			arg.assert_is_optional(values_obj)
#The optional argument, which has no value. End the entire string_arg composition
			opt_null_ix=arg_ix
			break
		if arg.repetition <=1:
#No list, but scalar value
			string_arg.append(composer.from_scalar_arg(arg))
		else:
			string_arg.append(composer.from_list_arg(arg, 0, arg.repetition))
		arg_ix+=1
#End of non-repeated arguments
#If the optional argument without a value was not found, check if there are some more arguments to go through
	if opt_null_ix<0 and arg_ix<arg_count:
#Still some args to go
		arg=args[arg_ix]
		if arg.is_open_list:
#The previous loop ended because the next argument had is_open_list=True
			if arg_ix==(arg_count-1):
				if arg.has_value(values_obj):
#The last argument, ignore the repetitions and convert the whole list to string
					string_arg.append(composer.from_list_arg(arg))
				else:
#The optional argument, which has no value. End the entire string_arg composition
					arg.assert_is_optional(values_obj)
					opt_null_ix=arg_ix
			else:
#More than one argument remaining. Loop through them interleaving the result strings
#Interleaving arguments must all have values
#Check if each list has at least Repetition number of elements
				cycles_error=False
				alignments_error=False
				cycle=-1
				data={}
				for x in range(arg_ix, arg_count):
					arg=args[x]
					curr_size:int=composer.get_arg_list_size(arg)
					curr_cycle:int=curr_size // arg.repetition
					curr_align:int=curr_size % arg.repetition
					data[x]=(curr_size, curr_cycle, curr_align)
					if curr_size<0:
						raise RsInstrException(f"Argument '{arg.name}' has repetitions, therefore it must be declared as a list. Current Declaration:'{arg.data_type}'")
					if arg.repetition>curr_size:
						raise RsInstrException(f"Argument '{arg.name}' has repetitions {arg.repetition}, but its list size is only {curr_size}")
#noinspection PyChainedComparisons
					if cycle >=0 and curr_cycle!=cycle:
						cycles_error=True
					cycle=curr_cycle
					if curr_align!=0:
						alignments_error=True
				if cycles_error:
					message='Arguments interleaving is not aligned-all the cycles must be the same. Actual cycles:\n'
					for x in range(arg_ix, arg_count):
						message+=f'{args[x].name}[{data[x][0]}] sliced by {get_plural_string("element", args[x].repetition)} ' \
							f'results in {data[x][0]/args[x].repetition} cycles\n'
					raise RsInstrException(message)
				if alignments_error:
					message='At least one argument has a list size not dividable by the defined repetitions:\n'
					for x in range(arg_ix, arg_count):
						message+=f'{args[x].name}[{data[x][0]}] modulo {args[x].repetition}x results in {data[x][0] % args[x].repetition}\n'
					raise RsInstrException(message)
				for x in range(cycle):
					for y in range(arg_ix, arg_count):
						arg=args[y]
						string_arg.append(composer.from_list_arg(arg, arg.repetition*x, arg.repetition))
	if opt_null_ix >=0:
#Check the rest of the optional values, all of them must be without a value
		rest=[]
		for y in range(opt_null_ix, arg_count):
			arg=args[y]
			if arg.has_value(values_obj):
				rest.append(arg.name)
		if len(rest):
			msg=f"Optional Argument '{args[opt_null_ix].name}' has no value, but the further ones do. " \
				f"If you skip an optional argument, you have to skip all the ones following it. " \
				f"Clear the values for the rest of the argument(s):\n{', '.join(rest)}"
			raise RsInstrException(msg)
	return ','.join(string_arg)
def compose_cmd_string_from_single_args(args:Dict[int, ArgSingle])->str:
"""Returns SCPI-composed string based on the single args specification. We can use the same function as for the struct arguments, with the difference of providing a SingleComposer. Parameter value_obj is set to None, since each argument holds the value itself."""
#noinspection PyTypeChecker
	return compose_cmd_string_from_struct_args(args,SingleComposer(),None)

"""ArgStruct.py"""
from .ConverterFromScpiString import ConverterFromScpiString
from .ConverterToScpiString import ConverterToScpiString
from .Types import DataType
from .InstrumentErrors import RsInstrException
class ArgStruct(object):
"""Describes an argument in data structures. This info is used to parse a string query response to the output structure, or to parse the output structure to the string parameter for writing. Contains reference to the value in the owning structure."""
	def __init__(self, name:str, data_type:DataType, enum_type=None, is_optional=False, is_open_list=False, repetition=1, intern_link:str=None):
		self.argument_ix=None
		self.name=name
		self.data_type=data_type
		self.is_optional=is_optional
		self.is_open_list=is_open_list
		self.repetition=repetition
		self.intern_link=intern_link
		self.enum_type=enum_type
		self.conv_from_scpi_string=ConverterFromScpiString(self.data_type, self.enum_type)
		self.conv_to_scpi_string=ConverterToScpiString(self.data_type, self.enum_type)
	@classmethod
	def scalar_int(cls, name:str, intern_link:str=None):
"""Describes mandatory scalar integer argument."""
		return cls(name, DataType.Integer, None, False, False, 1, intern_link)
	@classmethod
	def scalar_int_ext(cls, name:str, intern_link:str=None):
"""Describes mandatory scalar extended integer argument."""
		return cls(name, DataType.IntegerExt, None, False, False, 1, intern_link)
	@classmethod
	def scalar_str(cls, name:str, intern_link:str=None):
"""Describes mandatory scalar string argument."""
		return cls(name, DataType.String, None, False, False, 1, intern_link)
	@classmethod
	def scalar_raw_str(cls, name:str, intern_link:str=None):
"""Describes mandatory scalar raw string argument."""
		return cls(name, DataType.RawString, None, False, False, 1, intern_link)
	@classmethod
	def scalar_bool(cls, name:str, intern_link:str=None):
"""Describes mandatory scalar boolean argument."""
		return cls(name, DataType.Boolean, None, False, False, 1, intern_link)
	@classmethod
	def scalar_float(cls, name:str, intern_link:str=None):
"""Describes mandatory scalar float argument."""
		return cls(name, DataType.Float, None, False, False, 1, intern_link)
	@classmethod
	def scalar_float_ext(cls, name:str, intern_link:str=None):
"""Describes mandatory scalar extended float argument."""
		return cls(name, DataType.FloatExt, None, False, False, 1, intern_link)
	@classmethod
	def scalar_enum(cls, name:str, enum_type, intern_link:str=None):
"""Describes mandatory scalar float argument."""
		return cls(name, DataType.Enum, enum_type, False, False, 1, intern_link)
	@classmethod
	def scalar_str_optional(cls, name:str, intern_link:str=None):
"""Describes optional scalar string argument."""
		return cls(name, DataType.String, None, True, False, 1, intern_link)
	@classmethod
	def scalar_raw_str_optional(cls, name:str, intern_link:str=None):
"""Describes optional scalar raw string argument."""
		return cls(name, DataType.RawString, None, True, False, 1, intern_link)
	@classmethod
	def scalar_bool_optional(cls, name:str, intern_link:str=None):
"""Describes optional scalar boolean argument."""
		return cls(name, DataType.Boolean, None, True, False, 1, intern_link)
	@classmethod
	def scalar_int_optional(cls, name:str, intern_link:str=None):
"""Describes optional scalar integer argument."""
		return cls(name, DataType.Integer, None, True, False, 1, intern_link)
	@classmethod
	def scalar_int_ext_optional(cls, name:str, intern_link:str=None):
"""Describes optional scalar extended integer argument."""
		return cls(name, DataType.IntegerExt, None, True, False, 1, intern_link)
	@classmethod
	def scalar_float_optional(cls, name:str, intern_link:str=None):
"""Describes optional scalar float argument."""
		return cls(name, DataType.Float, None, True, False, 1, intern_link)
	@classmethod
	def scalar_float_ext_optional(cls, name:str, intern_link:str=None):
"""Describes optional scalar extended float argument."""
		return cls(name, DataType.FloatExt, None, True, False, 1, intern_link)
	@classmethod
	def scalar_enum_optional(cls, name:str, enum_type, intern_link:str=None):
"""Describes optional scalar float argument."""
		return cls(name, DataType.Enum, enum_type, True, False, 1, intern_link)
	def __str__(self):
		opt='~' if self.is_optional else ''
		name=f" '{self.name}'" if self.name!='' else ''
		out=f"StructArg {opt}{self.data_type.name}{name}"
		if self.is_open_list is False and self.repetition>1:
			out+=f' [{self.repetition}]'
		elif self.is_open_list is True:
			out+=f' [{self.repetition}...]'
		if self.intern_link:
			out+=f", Linking:'{self.intern_link}'"
		return out
	def has_value(self, obj)->bool:
"""Returns True, if the entered object attribute has value."""
		return getattr(obj, self.name) is not None
	def assert_is_optional(self, obj)->None:
"""Asserts that the parameter is optional. If not, the method throws an exception."""
		if self.is_optional:
			return
		value=getattr(obj, self.name)
		if value is None:
			raise RsInstrException(f"Structure '{obj}', argument without value is not optional:{self}")
		else:
			raise RsInstrException(f"Structure '{obj}', argument is not optional:{self}', value '{value}'")
	def assert_mandatory_has_value(self, obj)->None:
"""Asserts that if the parameter is mandatory, it must have value assigned.
		If not, the method throws an exception."""
		if self.is_optional:
			return
		if getattr(obj, self.name) is None:
			raise ValueError(f"Mandatory structure '{obj}' argument '{self.name}' has no value.")
 
"""ArgStructList.py"""
from .ArgStringComposer import StructComposer, compose_cmd_string_from_struct_args
from .ArgStructStringParser import ArgStructStringParser
from .StructBase import StructBase
from .InstrumentErrors import RsInstrExceptio
class ArgStructList(object):
"""Contains methods for composing cmd string and parsing cmd response to the provided structure instance."""
	RAW_DATA_PROP_NAME='RawReturnData'
	def __init__(self, struct):
		self.__struct=struct
		self.args=self.__get_struct_arg_attrs()
	def __str__(self):
		return f"'{self.__struct.__class__.__name__}', {len(self.args)} args:[ {', '.join([self.args[x].name for x in self.args])} ]"
	def __get_struct_arg_attrs(self):
		"""Fills self.args with the dictionary of ArgStruct list.
		Dictionary key is the argument order (argument_ix)."""
#noinspection PyUnresolvedReferences,PyProtectedMember
		args_list=StructBase._StructBase__get_meta_args_list(None, self.__struct)
#meta_data=getattr(self.__struct, '_{}__meta_args_list'.format(self.__struct.__class__.__name__))
		args=dict()
		for x in args_list:
			args[x.argument_ix]=x
		return args
	def parse_from_cmd_response(self, content:str):
"""Fills the structure from the entered string content (command response)."""
		if hasattr(self.__struct, ArgStructList.RAW_DATA_PROP_NAME):
			setattr(self.__struct, ArgStructList.RAW_DATA_PROP_NAME, content)
		parser=ArgStructStringParser(self.__struct, content)
		arg_count=len(self.args)
		arg_ix=0
#Non-repeated arguments
		while arg_ix<arg_count and self.args[arg_ix].is_open_list is False:
			arg=self.args[arg_ix]
			if arg.repetition <=1:
#No list, but scalar value
				parser.to_scalar_value(arg)
			else:
#List with a fixed size, not repeated
			parser.to_list_value(arg, True, 0, arg.repetition, arg.repetition, 1)
			arg_ix+=1
		if arg_ix<arg_count:
			arg=self.args[arg_ix]
			#Still some args to go
			if arg.is_open_list is True:
#The previous loop ended because the next argument had is_open_list True
				if arg_ix==(arg_count-1):
#This is the last argument, ignore the repetitions and take the whole rest of the elements
					parser.to_list_value(arg, True, 0, parser.remaining, parser.remaining, 1)
				else:
#More than one argument remaining. Loop through them interleaving the result strings
					open_list_args={key:value for key, value in self.args.items() if key >=arg_ix}
#Accumulate the number of repetitions from all the open_list_args
					period:int=sum(open_list_args[ix].repetition for ix in open_list_args)
					reminder:int=parser.remaining % period
					if reminder!=0:
						raise RsInstrException(
							f'Arguments parsing is not aligned-source string elements remaining to parse {parser.remaining}'
							f'is not dividable by the summary Period {period} of all the open list arguments:\n'+'\n'.join(['{}'.format(x) for x in open_list_args]))
#Go through the arguments and accumulate the list content
					offset=0
					for x in open_list_args:
						arg=open_list_args[x]
						parser.to_list_value(arg, False, offset, arg.repetition, period, -1)
						offset+=arg.repetition
	def compose_cmd_string(self):
"""Composes the string argument from the structure for sending to the instrument."""
		return compose_cmd_string_from_struct_args(self.args, StructComposer(self.__struct), self.__struct)

"""ArgStructStringParser.py"""
from . import Utilities
from .ArgStruct import ArgStruct
from .InstrumentErrors import RsInstrException
class ArgStructStringParser:
"""Class for parsing a response from the instrument to an output structure of arguments. It is used by the ArgStructList class for filling structures with return values."""
	def __init__(self, struct, value:str):
		self.struct=struct
		self.elements=value.split(',')
		self.count=len(self.elements)
		self.position=0
	@property
	def remaining(self)->int:
		"""Remaining items to parse."""
		return self.count-self.position
	def to_scalar_value(self, arg:ArgStruct):
"""Parses the current element to a scalar argument."""
		assert arg.data_type.is_scalar, f'to_scalar_value() method only works with scalar values. Data type:{arg.data_type}'
		if self.position >=self.count:
			raise RsInstrException(
				f"Cannot parse a scalar value to structure argument. Response contains only {self.count} elements, "
				f"argument '{arg.name}' has position {self.position+1}.\n"
				f"Response (commas replaced by new lines):\n"+Utilities.truncate_string_from_end('\n'.join(self.elements), 1000))
		string=self.elements[self.position]
		value=arg.conv_from_scpi_string.get_one_element_value(string)
		setattr(self.struct, arg.name, value)
		self.position+=1
	def to_list_value(self, arg:ArgStruct, increase_pos:bool, offset:int, count:int, period:int, cycles:int)->None:
"""Parses more elements to the list argument-slicing."""
		assert arg.data_type.is_list, f'to_list_value method only works with list values. Data type:{arg.data_type}'
		if cycles<0:
			cycles=self.remaining // period
		if self.position >=self.count:
			raise RsInstrException(
				f"Cannot parse an list value to the argument '{arg.name}', "
				f"because the element position {self.position} is over the parsed list length {self.count}")
		if (self.position+offset+count)>self.count:
			raise RsInstrException(
				f"Cannot parse the whole list value to the argument '{arg.name}', because the element position {self.position}"
				f"plus the argument offset {offset} and argument length {count} would be over the parsed list length {self.count}")
		result=[]
		for cycle in range(cycles):
			start_ix=self.position+(cycle*period)+offset
			for i in range(counresult.append(arg.conv_from_scpi_string.get_one_element_value(self.elements[start_ix+i]))
		if increase_pos:
			self.position+=count
		setattr(self.struct, arg.name, result)

"""CommandsGroup.py"""
from enum import Enum
from typing import List
from .Core import Core
from .RepeatedCapability import RepeatedCapability as RepCap
from .InstrumentErrors import DriverValueError
class CommandsGroup:
"""Contains methods dealing with RepCaps and Group object cloning"""
	def __init__(self, group_name:str, core:Core, parent:'CommandsGroup'):
"""Constructor with header name, group property name and the start value"""
		self.group_name=group_name
		self._core=core
		self.parent=parent
		self.io=core.io
		self.existing_children=[]
		self.rep_cap:RepCap or None=None
		self.multi_repcap_types:str=''
		if parent:
			parent.existing_children.append(self)
	def __str__(self):
"""String representation of the CommandsGroup"""
		out=f"SCPI Commands Group {self.group_name}"
		if self.has_repcap():
			out+=f', RepCap {self.rep_cap.name}={self.rep_cap.get_enum_value()}'
		return out
	def has_repcap(self)->bool:
"""Returns True, if the group has a RepCap.
		Returns False for a group with MultiRepCaps."""
		return self.rep_cap is not None
	def has_multi_repcaps(self)->bool:
"""Returns True for a group with MultiRepCaps."""
		return self.multi_repcap_types!=''
	def add_existing_child(self, child:'CommandsGroup')->None:
"""Adds the child to the parent's list of created children. This is used when the group is cloned, where the whole existing tree of groups have to be recreated"""
		self.existing_children.append(child)
	def set_repcap_enum_value(self, enum_value:Enum or int)->None:
"""Sets RepCap value as enum or integer
		Default is not allowed here."""
		try:
			self.rep_cap.set_enum_value(enum_value)
		except ValueError:
			raise DriverValueError(self.io.resource_name, f"Commands group RepCap value '{self.rep_cap.name}.Default' cannot be set. Please select a concrete value.")
	def get_repcap_enum_value(self)->Enum:
"""Returns RepCap value as enum"""
		return self.rep_cap.get_enum_value()
	def get_repcap_cmd_value(self, enum_value:Enum or int, enum_type)->str:
"""Returns the current string of RepCapCmdValue for the entered RepCapEnumName
The enum_value can be a repcap of the current CommandsGroup or any of their parents."""
#Use the static functions of the RepeatedCapability to get the non-default value
#It is faster, since there is no need to use the RepCap instance
		if not RepCap.clsm_is_default_value(enum_value, enum_type):
			return RepCap.clsm_get_cmd_string_value(enum_value, enum_type)
#Default value-get it from the group or the parent groups
		group=self
		while group is not None:
			if group.has_repcap():
				if group.rep_cap.matches_type(enum_type):
					return group.rep_cap.get_cmd_string_value()
			group=group.parent
#repCapEnumName not found in single repcaps. Check the multiRepCaps
		group=self
		while group is not None:
			if group.has_multi_repcaps():
				if str(enum_type.__name__) in group.multi_repcap_types.split(','):
					#Found in the multiple repcaps, create more fitting exception message
					raise DriverValueError(
						self.io.resource_name,
						f"You can not use the RepCap value '{enum_value}', "
						f"because its real value is not defined in any of the parent command groups. Please select a concrete value.")
			group=group.parent
#repCapEnumName not found, create exception message
		group=self
		groups=[]
		while group is not None:
			item=group.group_name
			if group.has_repcap():
				item+=f'=>{group.rep_cap.name}'
			groups.insert(0, item)
			group=group.parent
		groups_chain=str.join("\n", groups)
		raise DriverValueError(
			self.io.resource_name,
			f"Error replacing RepCaps in the SCPI command:"
			f"RepCap '{enum_type}' not found in the group chain:\n{groups_chain}")
	def get_owners_chain(self, stop:'CommandsGroup'=None)->List['CommandsGroup']:
"""Returns the owners chain including itself up to the entered point or up to the root by default."""
		chain=[]
		group=self
		while group!=stop:
			chain.append(group)
			group=group.parent
		return chain
	def get_self_and_desc_existing_children(self)->List['CommandsGroup']:
"""Get all the existing descendant groups recursively"""
		all_descendants=[self]
		for x in self.existing_children:
			all_descendants.extend(x.get_self_and_desc_existing_children())
		return all_descendants
	def synchronize_repcaps(self, new_group)->None:
"""Clones the existing group repeated capabilities to the new one. Because of the lazy group properties, the group clones are created by accessing the repcaps in them."""
		all_existing=filter(lambda grp:grp.has_repcap(),self.get_self_and_desc_existing_children())
		for x in all_existing:
			chain=x.get_owners_chain(self)
			chain.reverse()
			group=new_group
			for item in chain:
				group=getattr(group,item.group_name)
			fnc=getattr(group,x.rep_cap.method_set_name)
			fnc(x.rep_cap.get_enum_value())
	def restore_repcaps(self)->None:
"""Sets RepCaps of the Group and its children groups to their initial values."""
		all_existing=filter(lambda grp:grp.has_repcap(),self.get_self_and_desc_existing_children())
		for x in all_existing:
			x.rep_cap.set_to_start_value()
 
"""Conversions.py"""
import math
import struct
import sys
from enum import Enum
from typing import List,Tuple
from .ScpiEnums import ScpiEnum,enum_spec_prefixes,enum_spec_strings
from datetime import datetime
from . import Utilities
from .InstrumentErrors import RsInstrException
class BinFloatFormat(Enum):
"""Binary format of a float number."""
	Single_4bytes=1
	Single_4bytes_swapped=2
	Double_8bytes=3
	Double_8bytes_swapped=4
class BinIntFormat(Enum):
"""Binary format of an integer number."""
	Integer32_4bytes=1
	Integer32_4bytes_swapped=2
	Integer16_2bytes=3
	Integer16_2bytes_swapped=4
def assert_string_data(value:str)->None:
"""Asserts value is string type."""
	assert isinstance(value,str),f"Input value type must be string. Actual type:{type(value)},value:{value}"
def assert_list_data(value:List)->None:
"""Asserts value is list type."""
	assert isinstance(value,list),f"Input value type must be a list. Actual type:{type(value)},value:{value}"
def _get_endianness_symbol(swap_endianness:bool)->str:
"""Based on the current endianness returns the symbol used in the 'struct' module."""
	if swap_endianness is False:
		return '@'
	elif swap_endianness is True and sys.byteorder=='little':
		return '>'
	else:
		return '<'
def bytes_to_float32_list(data:bytes,swap_endianness=False)->List[float]:
"""Converts bytes to list of floats-one number is represented by 4 bytes."""
	fmt=f'{_get_endianness_symbol(swap_endianness)}{len(data) // 4}f'
	return list(struct.unpack(fmt,data))
def bytes_to_double64_list(data:bytes,swap_endianness=False)->List[float]:
"""Converts bytes to list of doubles-one number is represented by 8 bytes."""
	fmt=f'{_get_endianness_symbol(swap_endianness)}{len(data) // 8}d'
	return list(struct.unpack(fmt,data))
def bytes_to_int32_list(data:bytes,swap_endianness=False)->List[int]:
"""Converts bytes to list of integer32-one number is represented by 4 bytes."""
	fmt=f'{_get_endianness_symbol(swap_endianness)}{len(data) // 4}i'
	return list(struct.unpack(fmt,data))
def bytes_to_int16_list(data:bytes,swap_endianness=False)->List[int]:
"""Converts bytes to list of integer16-one number is represented by 2 bytes."""
	fmt=f'{_get_endianness_symbol(swap_endianness)}{len(data) // 2}h'
	return list(struct.unpack(fmt,data))
def bytes_to_list_of_floats(data:bytes,fmt:BinFloatFormat)->List[float]:
"""Decodes binary data to a list of floating-point numbers based on the entered format."""
	if fmt==BinFloatFormat.Single_4bytes:
		return bytes_to_float32_list(data)
	elif fmt==BinFloatFormat.Single_4bytes_swapped:
		return bytes_to_float32_list(data,True)
	elif fmt==BinFloatFormat.Double_8bytes:
		return bytes_to_double64_list(data)
	elif fmt==BinFloatFormat.Double_8bytes_swapped:
		return bytes_to_double64_list(data,True)
def bytes_to_list_of_integers(data:bytes,fmt:BinIntFormat)->List[int]:
"""Decodes binary data to a list of integer numbers based on the entered format."""
	if fmt==BinIntFormat.Integer32_4bytes:
		return bytes_to_int32_list(data)
	elif fmt==BinIntFormat.Integer32_4bytes_swapped:
		return bytes_to_int32_list(data,True)
	elif fmt==BinIntFormat.Integer16_2bytes:
		return bytes_to_int16_list(data)
	elif fmt==BinIntFormat.Integer16_2bytes_swapped:
		return bytes_to_int16_list(data,True)
def double64_list_to_bytes(data:List[float],swap_endianness=False)->bytes:
"""Converts list of doubles to bytes-one number is converted to 8 bytes."""
	fmt=f'{_get_endianness_symbol(swap_endianness)}{str(len(data))}d'
	return struct.pack(fmt,*data)
def float32_list_to_bytes(data:List[float],swap_endianness=False)->bytes:
"""Converts list of floats to bytes-one number is converted to 4 bytes."""
	fmt=f'{_get_endianness_symbol(swap_endianness)}{str(len(data))}f'
	return struct.pack(fmt,*data)
def int32_list_to_bytes(data:List[int],swap_endianness=False)->bytes:
"""Converts list of integers 32 to bytes-one number is converted to 4 bytes."""
	fmt=f'{_get_endianness_symbol(swap_endianness)}{str(len(data))}i'
	return struct.pack(fmt,*data)
def int16_list_to_bytes(data:List[float],swap_endianness=False)->bytes:
"""Converts list of integers 16 to bytes-one number is converted to 2 bytes."""
	fmt=f'{_get_endianness_symbol(swap_endianness)}{str(len(data))}h'
	return struct.pack(fmt,*data)
def list_of_integers_to_bytes(ints:List[int],fmt:BinIntFormat)->bytes:
"""Encodes list of integers to binary data based on the entered format."""
	if fmt==BinIntFormat.Integer32_4bytes:
		return int32_list_to_bytes(ints)
	elif fmt==BinIntFormat.Integer32_4bytes_swapped:
		return int32_list_to_bytes(ints,True)
	elif fmt==BinIntFormat.Integer16_2bytes:
		return int16_list_to_bytes(ints)
	elif fmt==BinIntFormat.Integfer16_2bytes_swapped:
		return int16_list_to_bytes(ints,True)
def list_of_floats_to_bytes(floats:List[float],fmt:BinFloatFormat)->bytes:
"""Encodes list of floats to binary data based on the entered format."""
	if fmt==BinFloatFormat.Single_4bytes:
		return float32_list_to_bytes(floats)
	elif fmt==BinFloatFormat.Single_4bytes_swapped:
		return float32_list_to_bytes(floats,True)
	elif fmt==BinFloatFormat.Double_8bytes:
		return double64_list_to_bytes(floats)
	elif fmt==BinFloatFormat.Double_8bytes_swapped:
		return double64_list_to_bytes(floats,True)
pure_bool_true_lookup=frozenset(['on','On','ON','true','True','TRUE'])
bool_true_lookup=frozenset(['1','on','On','ON','true','True','TRUE'])
bool_false_lookup=frozenset(['0','off','Off','OFF','false','False','FALSE'])
pure_bool_false_lookup=frozenset(['off','Off','OFF','false','False','FALSE'])
def str_to_bool(string:str)->bool:
"""Converts string to boolean value. The function is robust, and case-insensitive. If the string can not be converted to a boolean, the function returns False."""
	assert_string_data(string)
	if string in bool_true_lookup:
		return True
	if string in bool_false_lookup:
		return False
#If leading/trailing spaces
	string=string.strip()
	if string in bool_true_lookup:
		return True
	if string in bool_false_lookup:
		return False
#If enclosed by brackets
	string=Utilities.trim_str_response(string)
	if string in bool_true_lookup:
		return True
	if string in bool_false_lookup:
		return False
	return False
def string_to_pure_bool(string:str)->bool or None:
"""Converts string to boolean value. Compare to str_to_bool(), the values '1' and '0' are not considered boolean. Also, if the method can not convert the string to boolean, it returns None."""
	assert_string_data(string)
	if string in pure_bool_true_lookup:
		return True
	if string in pure_bool_false_lookup:
		return False
#If leading/trailing spaces
	string=string.strip()
	if string in pure_bool_true_lookup:
		return True
	if string in pure_bool_false_lookup:
		return False
#If enclosed by brackets
	string=Utilities.trim_str_response(string)
	if string in pure_bool_true_lookup:
		return True
	if string in pure_bool_false_lookup:
		return False
	return None
number_plus_inf_lookup=frozenset(['Inf','INF','INFINITY','+Inf','+INF','+inf','+INFINITY','+Infinity','+infinity'])
number_minus_inf_lookup=frozenset(['-Inf','-INF','-inf','-INFINITY','-Infinity','-infinity'])
number_nan_lookup=frozenset(['Nan','NAN','nan','NaN','NAV','NaV','NCAP','INV','NONE','none','None','DTX','UND','und'])
number_max_lookup=frozenset(['OFL','ofl','Ofl'])
number_min_lookup=frozenset(['UFL','ufl','Ufl'])
number_si_suffix={'pHz':1E-12,'MHz':1E+6,'kHz':1E+3,'GHz':1E+9,'mHz':1E-3,'uHz':1E-6,'µHz':1E-6,'THz':1E+12,'nHz':1E-9,'ns':1E-9,'fW':1E-15,
					'pW':1E-12,'nW':1E-9,'uW':1E-6,'µW':1E-6,'mW':1E-3,'kW':1E3,'MW':1E6,'GW':1E9,'MV':1E+6,'MA':1E+6,'ps':1E-12,'fs':1E-15,
					'km':1E+3,'kV':1E+3,'kA':1E+3,'pF':1E-2,'Hz':1.0,'mm':1E-3,'mA':1E-3,'mF':1E-3,'mV':1E-3,'pV':1E-12,'nF':1E-9,'nA':1E-9,
					'nV':1E-9,'nm':1E-9,'pm':1E-12,'us':1E-6,'µs':1E-6,'uF':1E-6,'µF':1E-6,'ms':1E-3,'uA':1E-6,'µA':1E-6,'uV':1E-6,'µV':1E-6,
					'um':1E-6,'µm':1E-6,'pA':1E-12,'V':1,'W':1,'A':1,'F':1,'s':1,'m':1}
int_neg_inf=-(sys.maxsize-1)
def strip_si_suffix(string:str)->Tuple[bool,str,float]:
"""Tries to find defined suffixes in the text and returns the stripped text and the multiplier as double number. If no known suffix is detected, the method returns false, strippedText=text, multiplier=1.0
Example:text='123 MHz' strippedText='123' multiplier=1E6"""
	for suffix in number_si_suffix.keys():
		if string.endswith(suffix):
			return True,string[:-len(suffix)].rstrip(),number_si_suffix[suffix]
	return False,string,1.0
def str_to_int(string:str)->int:
"""Converts string to integer value. Float values are coerced to integer.
Also recognizes case-insensitive special values like NaN,INV,NCAP..."""
	assert_string_data(string)
	string=string.strip(" \t\r\n'\"")
	if string=='':
		return 0
	value=str_special_values_to_int(string)
	if value:
		return value
#Hexadecimal numbers
	if string.startswith('#H') or string.startswith('0x'):
		if ',' in string:
			return int(string[2:string.find(',')],16)
		else:
			return int(string[2:],16)
#Binary numbers
	if string.startswith('#B') or string.startswith('0b'):
		if ',' in string:
			return int(string[2:string.find(',')],2)
		else:
			return int(string[2:],2)
#Octal numbers
	if string.startswith('#Q') or string.startswith('0o'):
		if ',' in string:
			return int(string[2:string.find(',')],8)
		else:
			return int(string[2:],8)
#Simulation
	if string=='Simulating':
		return 0
	try:
		return int(round(float(string)))
	except ValueError:
		result=strip_si_suffix(string)
		if result[0] is False:
			raise
		try:
			return int(round(float(result[1])*result[2]))
		except ValueError:
			raise ValueError(f"could not convert string to integer:'{string}'")
def str_special_values_to_int(string:str)->int:
"""Converts special string values to integer. Returns None if no special value was found."""
	assert_string_data(string)
	if string in number_plus_inf_lookup or string in number_max_lookup:
		return sys.maxsize
	if string in number_minus_inf_lookup or string in number_min_lookup or string in number_nan_lookup:
		return int_neg_inf
	if string=='OFF':
		return int_neg_inf+1
	if string=='ON':
		return int_neg_inf+2
	if string=='OK':
		return sys.maxsize-1
	if string=='DC':
#noinspection PyTypeChecker
		return int_neg_inf/100
	if string=='ULEU':
		return int(sys.maxsize/10)
	if string=='ULEL':
#noinspection PyTypeChecker
		return int_neg_inf/10
#noinspection PyTypeChecker
	return None
def str_to_int_or_bool(string:str)->int or bool:
"""Similar to str_to_int, but for special values "ON/OFF" the function returns boolean"""
	result=string_to_pure_bool(string)
	if result is not None:
		return result
	return str_to_int(string)
def str_to_float(string:str)->float:
"""Converts string to float value.
Also recognizes case-insensitive special values like NaN, INV, NCAP..."""
	assert_string_data(string)
	string=string.strip(" \t\r\n'\"")
	if string=='':
		return 0.0
	if string in number_plus_inf_lookup:
		return math.inf
	if string in number_minus_inf_lookup:
		return -math.inf
	if string in number_nan_lookup:
		return math.nan
	if string in number_max_lookup:
		return sys.float_info.max
	if string in number_min_lookup:
		return -sys.float_info.max
	if string=='OFF':
		return -sys.float_info.epsilon
	if string=='ON':
		return -2*sys.float_info.epsilon
	if string=='OK':
		return sys.float_info.epsilon
	if string=='DC' or string=='':
		return -sys.float_info.max/100
	if string=='ULEU':
		return sys.float_info.max/10
	if string=='ULEL':
		return -sys.float_info.max/10
	if string=='Simulating':
		return 0.0
	try:
		return float(string)
	except ValueError:
		result=strip_si_suffix(string)
		if result[0] is False:
			raise
		try:
			return float(result[1])*result[2]
		except ValueError:
			raise ValueError(f"could not convert string to float:'{string}'")
def str_to_float_or_bool(string:str)->float or bool:
"""Similar to str_to_float, but for special values "ON/OFF" the function returns boolean"""
	result=string_to_pure_bool(string)
	if result is not None:
		return result
	return str_to_float(string)
def float_to_str(value:float)->str:
"""Converts double number to string using {.12g} formatter."""
	return format(value,".12g")
def bool_to_str(value:bool)->str:
"""Converts boolean to 'ON' or 'OFF' string."""
	if type(value) is bool:
		return 'ON' if value is True else 'OFF'
	else:
		raise RsInstrException(f"bool_to_str:unsupported variable type '{type(value)}',value '{value}'. Only boolean values are supported.")
def str_enclose_by_quotes(string:str)->str:
"""Returns string enclosed by single quotes."""
	assert_string_data(string)
	return "'"+string+"'"
def list_to_csv_str(value:List,delimiter:str=',')->str:
"""Converts list of elements to strings separated by commas.
Element types can differ on an individual basis.
Supported element types:
- int
- bool
- float
- string->string no quotes
- enum"""
	assert_list_data(value)
	result=[]
	for x in value:
		el=value_to_str(x)
		if not el:
			raise TypeError(f"List element type is not supported by Conversions.list_to_csv_str:'{x}'")
		result.append(el)
	return delimiter.join(result)
def list_to_csv_quoted_str(value:List)->str:
"""Converts list of elements to quoted strings separated by commas.
Only string elements are enclosed by single quotes
Element types can differ on an individual basis.
Supported element types:
- int
- bool
- float
- string->string enclosed by quotes
- enum"""
	assert_list_data(value)
	result=[]
	for x in value:
		if isinstance(x,str):
			el=str_enclose_by_quotes(x)
		else:
			el=value_to_str(x)
		if not el:
			raise TypeError(f"List element type is not supported by Conversions.list_to_csv_quoted_str:'{x}'")
		result.append(el)
	return ','.join(result)
def decimal_value_to_str(x:int or float)->str:
"""Converts scalar decimal value to string.
Supported element types:
- int
- float"""
	if isinstance(x,int) and type(x) is not bool:
		return str(x)
	elif isinstance(x,float):
		return float_to_str(x)
	else:
		raise RsInstrException(f"decimal_value_to_str:unsupported variable type '{type(x)}',value '{x}'. Only integer and float types are supported.")
def decimal_or_bool_value_to_str(x:int or float or bool)->str:
"""Converts scalar decimal value to string.
Supported element types:
- int
- float
- boolean"""
	if type(x) is bool:
		return bool_to_str(x)
	if isinstance(x,int):
		return str(x)
	elif isinstance(x,float):
		return float_to_str(x)
	else:
		raise RsInstrException(f"decimal_or_bool_value_to_str:unsupported variable type '{type(x)}',value '{x}'. Only integer,float and boolean types are supported.")
def value_to_str(x:int or bool or float or str or Enum)->str:
"""Converts scalar value to string.
Supported element types:
- int
- bool
- float
- string
- enum"""
	if isinstance(x,bool):
		return bool_to_str(x)
	elif isinstance(x,int):
		return str(x)
	elif isinstance(x,float):
		return float_to_str(x)
	elif isinstance(x,str):
		return x
	elif isinstance(x,Enum):
		if isinstance(x.value,str):
			return enum_value_to_scpi_string(x.value)
		return enum_value_to_scpi_string(x.name)
	else:
		raise RsInstrException(f"value_to_str:unsupported variable type '{type(x)}',value '{x}'. Supported types:int,bool,float,str,enum.")
def enum_value_to_scpi_string(enum_value:str)->str:
"""Conversion EnumValue->SCPI_String  Unescapes all the special characters that can not be contained in the enum member definition, but can be sent to the instrument as enum string. Use this to send the scpi enum value to the instrument."""
	for key in enum_spec_prefixes:
		if enum_value.startswith(key):
			enum_value=enum_spec_prefixes[key]+enum_value[len(key):]
	for key in enum_spec_strings:
		enum_value=enum_value.replace(key,enum_spec_strings[key])
	return enum_value
def value_to_quoted_str(x:int or bool or float or str or Enum)->str:
"""Converts scalar value to string enclosed by single quotes.
Supported element types:
- int
- bool
- float
- string
- enum"""
	return f"'{value_to_str(x)}'"

def str_to_float_list(string:str)->List[float]:
"""Converts string with comma-separated values to list of Floats."""
	assert_string_data(string)
	if not string:
		return []
	result=[*map(str_to_float,string.split(','))]
	return result
def str_to_float_or_bool_list(string:str)->List[float or bool]:
"""Converts string with comma-separated values to list of float or boolean values."""
	assert_string_data(string)
	if not string:
		return []
	result=[*map(str_to_float_or_bool,string.split(','))]
	return result
def str_to_int_list(string:str)->List[int]:
"""Converts string with comma-separated values to list of Integers."""
	assert_string_data(string)
	if not string:
		return []
	result=[*map(str_to_int,string.split(','))]
	return result
def str_to_int_or_bool_list(string:str)->List[int or bool]:
"""Converts string with comma-separated values to list of integer or boolean values."""
	assert_string_data(string)
	if not string:
		return []
	result=[*map(str_to_int_or_bool,string.split(','))]
	return result
def str_to_bool_list(string:str)->List[bool]:
"""Converts string with comma-separated values to list of booleans."""
	assert_string_data(string)
	if not string:
		return []
	result=[*map(str_to_bool,string.split(','))]
	return result
def str_to_str_list(string:str,clear_one_empty_item:bool=False)->List[str]:
"""Converts string with comma-separated values to list of strings. Each element is trimmed by trim_str_response(). If the clear_one_empty_item is set to True (default is False), and the result is exactly one empty string item, the method returns empty list."""
	assert_string_data(string)
	if not string:
		return []
	result=[*map(Utilities.trim_str_response,string.split(','))]
	if clear_one_empty_item and len(result)==1 and result[0]=='':
		return []
	return result
def str_to_scalar_enum_helper(string:str,scpi_enum:ScpiEnum,array_search:bool,exc_if_not_found)->Enum:
"""Converts string to one enum element. array_search signal no need to force the comma removing,
because the elements definitely do not have any commas-commas have been used to split string to the list of strings
The function can also return:
- integer special value, if the string was not found in the enum, and it is a special value.
- input string, if the string was not found and raise_if_not_found is set to False-used for the EnumExt types."""
	if scpi_enum.has_quotes:
		value=Utilities.trim_str_response(string,mode=Utilities.TrimStringMode.white_chars_double_quotes)
	else:
		value=Utilities.trim_str_response(string)
	enum_value=scpi_enum.find_in_enum_members(value,False)
	if enum_value is not None:
		return enum_value
	if array_search is False:
#If the result is still -1 (not found), try to force removing the comma in the string.
		enum_value=scpi_enum.find_in_enum_members(value,True)
		if enum_value is not None:
			return enum_value
#If not found, search in the special integer numbers:
	spec_value=str_special_values_to_int(value)
	if spec_value:
#noinspection PyTypeChecker
		return spec_value
	if exc_if_not_found:
		raise RsInstrException(f"String '{value}' can not be found in the enum type '{scpi_enum.enum_type}'")
#noinspection PyTypeChecker
	return Utilities.trim_str_response(string)
def str_to_simple_scalar_enum(string:str,enum_type,case_sensitive:bool=True,ignore_underscores:bool=False)->Enum or None:
"""Converts string to one enum element. Does not handle special value or non-mandatory parts.
The function is used in core only for standard enum conversions, not for SCPI enum conversions."""
	value=Utilities.trim_str_response(string)
	enum_members=[x.name for x in enum_type]
	enum_members_mod=[x.name for x in enum_type]
	if not case_sensitive:
		enum_members_mod=[x.upper() for x in enum_members]
		value=value.upper()
	if ignore_underscores:
		enum_members_mod=[x.replace('_','') for x in enum_members_mod]
		value=value.replace('_','')
	if value in enum_members_mod:
		return enum_type[enum_members[enum_members_mod.index(value)]]
	return None
def str_to_list_enum_helper(string:str,scpi_enum:ScpiEnum,exc_if_not_found:bool=True)->List[Enum]:
"""Converts string to list of enum elements. separated by comma"""
	elements=string.split(',')
	return [str_to_scalar_enum_helper(x,scpi_enum,True,exc_if_not_found) for x in elements]
def enum_scalar_to_str(data,enum_type)->str:
"""Converts enum scalar value to string."""
	assert isinstance(data,enum_type),f"Expected command parameter {enum_type},actual data type:{type(data)}. Value:{data}"
	return value_to_str(data)
def enum_ext_scalar_to_str(data,enum_type)->str:
"""Converts enum scalar value to string. If the input value is string, the function returns the string with single quotes."""
	if isinstance(data,str):
#Return string with quotes
		return value_to_quoted_str(Utilities.trim_str_response(data))
	assert isinstance(data,enum_type),f"Expected command parameter string or {enum_type},actual data type:{type(data)}. Value:{data}"
	return value_to_str(data)
def enum_list_to_str(data:List,enum_type)->str:
"""Converts enum list to csv-string."""
#For enums, check that each element is an enum
	assert all(isinstance(x,enum_type) for x in data),f"Expected command parameter list of {enum_type},detected one or more elements of non-enum type. Value:{data}"
	return list_to_csv_str(data)
def enum_ext_list_to_str(data:List,enum_type)->str:
"""Converts enum list to csv-string. Allows the elements to be either enum or string."""
	assert all((isinstance(x,enum_type or str) or isinstance(x,str)) for x in data),f"Expected command parameter list of strings or {enum_type},detected one or more elements of non-enum/non-string type. Value:{data}"
	return list_to_csv_quoted_str(data)
def str_to_scalar_enum(string:str,enum_type)->Enum:
"""Converts string to one enum element. Throws exception if the string can not be converted to an enum element or a special value."""
	return str_to_scalar_enum_helper(string,ScpiEnum(enum_type),False,exc_if_not_found=True)
def str_to_scalar_enum_ext(string:str,enum_type)->Enum:
"""Converts string to one enum element. Compared to str_to_scalar_enum, in case the string can not be converted, it is returned trimmed for quotes and ."""
	return str_to_scalar_enum_helper(string,ScpiEnum(enum_type),False,exc_if_not_found=False)
def str_to_list_enum(string:str,enum_type)->List[Enum]:
"""Converts string to list of enum elements."""
	return str_to_list_enum_helper(string,ScpiEnum(enum_type))
def str_to_list_enum_ext(string:str,enum_type)->List[Enum]:
"""Converts string to list of enum or string elements."""
	return str_to_list_enum_helper(string,ScpiEnum(enum_type),exc_if_not_found=False)
def convert_ts_to_datetime(timestamp:datetime or float)->datetime:
"""Converts timestamp as float to datetime. For datetime tuple it just passes the value."""
	if isinstance(timestamp,float) or isinstance(timestamp,int):
		return datetime.fromtimestamp(timestamp)
	return timestamp
def get_timestamp_string(timestamp:datetime or float)->str:
"""Returns the timestamp as string. The timestamp can be a datetime tuple or float seconds coming from the time.time()."""
	timestamp=convert_ts_to_datetime(timestamp)
	cur_time=timestamp.strftime('%H:%M:%S.%f')[:-3]
	return cur_time
def get_timedelta_fixed_string(time_start:datetime or float,time_end:datetime or float)->str:
"""Returns the time span as string-fixed in the format of '%H:%M:%S.%f'."""
	time_a=convert_ts_to_datetime(time_start)
	time_b=convert_ts_to_datetime(time_end)
	frac=(time_b-time_a).total_seconds()
	wh=math.floor(frac)
	d=int(wh/86400)
	h=int((wh-d*86400))/3600)
	m=int((wh-d*86400+h*3600))/60)
	s=int((wh-d*86400+h*3600+m*60)))
	ms=int((frac-wh)*1000)
	res=f'{h:02d}:{m:02d}:{s:02d}.{ms:03d}'
	if d>0:
		res=f'{d}d '+res
	return res
def get_timedelta_string(time_a:datetime or float,time_b:datetime or float)->str:
"""Returns the time span as string-dynamic based on the difference."""
	time_a=convert_ts_to_datetime(time_a)
	time_b=convert_ts_to_datetime(time_b)
	if time_b<time_a:
		return '0.000 ms'
	diff=time_b-time_a
	if diff.seconds<10:
		return f'{diff.total_seconds()*1000:0.3f} ms'
	elif diff.seconds<1000:
		a=diff.total_seconds()
		return f'{a:0.3f} secs'
	hours,remainder=divmod(diff.seconds,3600)
	minutes,seconds=divmod(remainder,60)
	return f'{hours:02d}:{minutes:02d}:{seconds:02d}'

"""ConverterFromScpiString.py"""
from enum import Enum
from .Conversions import str_to_bool,str_to_int,str_to_int_or_bool,str_to_float,str_to_float_or_bool,str_to_scalar_enum_helper
from .Conversions import str_to_str_list,str_to_bool_list,str_to_int_list,str_to_int_or_bool_list,str_to_float_list,str_to_float_or_bool_list,str_to_list_enum_helper
from .Types import DataType
from .Utilities import trim_str_response
from .InstrumentErrors import RsInstrException
from .ScpiEnums import ScpiEnum
class ConverterFromScpiString:
"""Converter from SCPI response string to argument value. For list argument types, you must use the method get_one_element_value in a loop for each element. Provides methods:
- get_one_element_value(str):returns one scalar value converted from the SCPI string.
- get_list_value(str):return complete list value converted from the SCPI string.
- get_value(str):calls either get_one_element_value or get_list_value() depending on the data type. \n
The reason for the different methods is, that sometimes the list data are interleaved with other arguments. In order to parse them properly, the ArgStructStringParser module must be able to set the argument value element-by-element. The driver methods might want to set the whole argument value, because the result scpi string is a single argument response."""
	def __init__(self,data_type:DataType,enum_type:Enum=None):
		self.scpi_enum=None
		self.data_type=data_type
		self.element_type=self.data_type.element_type
		if self.element_type==DataType.RawString:
			self.converter=trim_str_response
			self.list_converter=str_to_str_list
		elif self.element_type==DataType.String:
			self.converter=trim_str_response
			self.list_converter=str_to_str_list
		elif self.element_type==DataType.Boolean:
			self.converter=str_to_bool
			self.list_converter=str_to_bool_list
		elif self.element_type==DataType.Integer:
			self.converter=str_to_int
			self.list_converter=str_to_int_list
		elif self.element_type==DataType.IntegerExt:
			self.converter=str_to_int_or_bool
			self.list_converter=str_to_int_or_bool_list
		elif self.element_type==DataType.Float:
			self.converter=str_to_float
			self.list_converter=str_to_float_list
		elif self.element_type==DataType.FloatExt:
			self.converter=str_to_float_or_bool
			self.list_converter=str_to_float_or_bool_list
		elif self.element_type.is_scalar_enum:
			assert enum_type,f"For data type enum,you have to define the enum_type variable."
#noinspection PyTypeChecker
			self.scpi_enum=ScpiEnum(enum_type)
		else:
			raise RsInstrException(f"Unsupported data type '{data_type}'")
	def get_one_element_value(self,scpi_string:str):
"""Returns single element (not an array!!!) of the argument value converted from the SCPI string (single element)"""
		assert isinstance(scpi_string,str),f"Input parameter scpi_string must be string. Actual parameter:{type(scpi_string)},value:{scpi_string}"
		if self.element_type.is_scalar_enum:
			return str_to_scalar_enum_helper(scpi_string,self.scpi_enum,False,exc_if_not_found=self.element_type==DataType.Enum)
		return self.converter(scpi_string)
	def get_value(self,scpi_string:str):
"""Returns complete value of the argument converted from the SCPI string (list or scalar)"""
		if not self.data_type.is_list:
			return self.get_one_element_value(scpi_string)
		assert isinstance(scpi_string,str),f"Input parameter scpi_string must be string. Actual parameter:{type(scpi_string)},value:{scpi_string}"
		if self.element_type is DataType.Enum:
			return str_to_list_enum_helper(scpi_string,self.scpi_enum,exc_if_not_found=self.element_type==DataType.Enum)
		return self.list_converter(scpi_string)

"""ConverterToScpiString.py"""
from enum import Enum
from .Conversions import list_to_csv_quoted_str,value_to_quoted_str,list_to_csv_str,value_to_str,enum_list_to_str,enum_scalar_to_str,enum_ext_scalar_to_str,enum_ext_list_to_str
from .Types import DataType
from .InstrumentErrors import RsInstrException
def value_to_scpi_string(data,data_type:DataType)->str:
"""Convert data to SCPI string parameter:data->str. Does not work with enum data types."""
	if data_type.is_list:
		assert isinstance(data,list),f"Expected command parameter list,actual data type:{type(data)}. Value:{data}"
	else:
		assert not isinstance(data,list),f"Expected command parameter scalar,actual data type:{type(data)}. Value:{data}"
#Strings are enclosed by single quotes
	if data_type==DataType.StringList:
		assert all(isinstance(x,str) for x in data),f"Expected command parameter list of strings,detected one or more elements of non-string type. Value:{data}"
		return list_to_csv_quoted_str(data)
	elif data_type==DataType.String:
		assert isinstance(data,str),f"Expected command parameter string,actual data type:{type(data)}. Value:{data}"
		return value_to_quoted_str(data)
#Raw string is not enclosed by quotes
	elif data_type==DataType.RawStringList:
		assert all(isinstance(x,str) for x in data),f"Expected command parameter list of strings,detected one or more elements of non-string type. Value:{data}"
		return list_to_csv_str(data)
	elif data_type==DataType.RawString:
		assert isinstance(data,str),f"Expected command parameter string,actual data type:{type(data)}. Value:{data}"
		return value_to_str(data)
	elif data_type==DataType.BooleanList:
		assert all(type(x)==bool for x in data),f"Expected command parameter list of booleans,detected one or more elements of non-boolean type. Value:{data}"
		return list_to_csv_str(data)
	elif data_type==DataType.Boolean:
		assert type(data)==bool,f"Expected command parameter boolean,actual data type:{type(data)}. Value:{data}"
		return value_to_str(data)
#For integer and float, allow them to be mixed
	elif data_type==DataType.IntegerList or data_type==DataType.FloatList:
		assert all((isinstance(x,int) or isinstance(x,float)) and type(x)!=bool for x in data),f"Expected command parameter list of numbers,detected one or more elements of non-number type. Value:{data}"
		return list_to_csv_str(data)
	elif data_type==DataType.Integer or data_type==DataType.Float:
		assert (isinstance(data,int) or isinstance(data,float)) and type(data)!=bool,f"Expected command parameter number,actual data type:{type(data)}. Value:{data}"
		return value_to_str(data)
#For integer and float extended,allow them to be mixed including the boolean type
	elif data_type==DataType.IntegerExtList or data_type==DataType.FloatExtList:
		assert all((isinstance(x,int) or isinstance(x,float) or isinstance(x,bool)) for x in data),f"Expected command parameter list of numbers or booleans,detected one or more elements of non-number type. Value:{data}"
		return list_to_csv_str(data)
	elif data_type==DataType.IntegerExt or data_type==DataType.FloatExt:
		assert (isinstance(data,int) or isinstance(data,float) or isinstance(data,bool)),f"Expected command parameter number or boolean,actual data type:{type(data)}. Value:{data}"
		return value_to_str(data)
	else:
		raise RsInstrException(f"Unsupported data type:'{type(data_type)}'.")
class ConverterToScpiString:
"""Converter from argument value to SCPI string. Provides method get_value(arg_value)->str"""
	def __init__(self,data_type:DataType,enum_type:Enum=None):
		self.enum_type=enum_type
		self.data_type=data_type
		self.element_type=self.data_type.element_type
		if self.element_type==DataType.Enum or self.element_type==DataType.EnumExt:
			assert self.enum_type,f"For data_type {data_type.name},you have to define the enum_type variable."
	def get_value(self,data)->str:
"""Returns SCPI string converted from the argument data."""
		if self.data_type.is_list:
			assert isinstance(data,list),f"Expected command parameter list,actual data type:{type(data)}. Value:{data}"
		else:
			assert not isinstance(data,list),f"Expected command parameter scalar,actual data type:{type(data)}. Value:{data}"
		if self.data_type==DataType.Enum:
			return enum_scalar_to_str(data,self.enum_type)
		if self.data_type==DataType.EnumExt:
			return enum_ext_scalar_to_str(data,self.enum_type)
		if self.data_type==DataType.EnumList:
			*return enum_list_to_str(data,self.enum_type)
		if self.data_type==DataType.EnumExtList:
			return enum_ext_list_to_str(data,self.enum_type)
		return value_to_scpi_string(data,self.data_type)

"""Core.py"""
from typing import Callable
from . import InstrumentOptions as Options
from .ArgSingle import ArgSingle
from .ArgSingleList import ArgSingleList
from .Conversions import BinFloatFormat,BinIntFormat
from .Instrument import Instrument
from .InstrumentSettings import InstrViClearMode,InstrumentSettings,WaitForOpcMode
from .ScpiLogger import LoggingMode
from .InstrumentErrors import RsInstrException
class Core(object):
"""Main driver component. Provides:\n
- Main core constructor
- 'io' interface for all the write/query operations
- Command parameters string composer for single arguments...
- Link handlers adding/changing/deleting
	driver_version:str=''
"""Placeholder for the driver version string."""
	def __init__(self,
			resource_name:str,
			id_query:bool=True,
			reset:bool=False,
			driver_options:str=None,
			user_options:str=None,
			direct_session:object=None):
"""Initializes new driver session. For cleaner code, use the class methods:\n-Core.from_existing_session()-initializes a new Core with an existing pyvisa session."""
		self.core_version='1.54.0'
		self.resource_name=resource_name
#Typical settings for the Core
		self._instrumentSettings=InstrumentSettings(
			InstrViClearMode.execute_on_all, #Instrument viClear mode
			False, #Full model name. True:SMW200A, False:SMW
			0, #Delay by each write
			0, #Delay by each read
			1000000, #Max chunk read/write size in bytes
			WaitForOpcMode.stb_poll, #Waiting for OPC Mode:Status byte polling
			30000, #OPC timeout
			10000, #VISA timeout
			60000, #Self-test timeout
			Options.ParseMode.Auto, #*OPT? response parsing mode
			BinFloatFormat.Single_4bytes, #Format for parsing of binary float numbers
			BinIntFormat.Integer32_4bytes, #Format for parsing of binary integer numbers
			False, #OPC query after each setting
			LoggingMode.Off  #Logging mode)
		self._instrumentSettings.apply_option_settings(driver_options)
		self._instrumentSettings.apply_option_settings(user_options)
		self.simulating=self._instrumentSettings.simulating
		self.supported_idn_patterns=self._instrumentSettings.supported_idn_patterns
		self.supported_instr_models=self._instrumentSettings.supported_instr_models
		self._args_single_list=ArgSingleList()
		handle=self._resolve_direct_session(direct_session)
		self.io=Instrument(self.resource_name,self.simulating,self._instrumentSettings,handle)
		self.io.query_instr_status=True
#Update the resource name if it changed, for example because of the direct session
		self.resource_name=self.io.resource_name
		self.allow_reconnect=self.io.allow_reconnect
		self._apply_settings_to_instrument(self._instrumentSettings)
		self.io.set_simulating_cmds()
		if id_query:
			self.io.fits_idn_pattern(self.supported_idn_patterns,self.supported_instr_models)
		if reset:
			self.io.reset()
		else:
			self.io.check_status()
	@classmethod
	def from_existing_session(cls,session:object,driver_options:str=None)->'Core':
"""Creates a new Core object with the entered 'session' reused."""
#noinspection PyTypeChecker
		return cls(resource_name=None,id_query=False,reset=False,driver_options=driver_options,user_options=None,direct_session=session)
	def __str__(self):
		return f"Core session '{self.io.resource_name}'"
	def _resolve_direct_session(self,direct_session):
#Resolve the direct_session to handle. Options for direct_session type:
#- VisaSession object, retrieved from the driver's RsInstrument.get_session_handle() method
#- string in case of a simulation session
		handle=direct_session
		if not direct_session:
			return None
#Check if the entered 'direct_session' is either the driver object or the Visa session
		if hasattr(direct_session,'get_session_handle'):
			if not hasattr(direct_session,'_core'):
				raise RsInstrException('Direct session is a class type. It must be an instance of the top-level driver class.')
			handle=direct_session.get_session_handle()
#If the handle is a simulating session, change the session to simulating and set disable the 'from existing session' feature
		if isinstance(handle,str):
			mand_string='Simulating session,resource name '
			if mand_string in handle:
				self.resource_name=handle[len(mand_string):].strip().strip("'").strip()
				self.simulating=True
				handle=None
		return handle
	def set_link_handler(self,link_name:str,handler:Callable)->Callable:
"""Adds/Updates link handler for the entered link_name.
Handler API:handler(event_args:ArgLinkedEventArgs)
Returns the previous registered handler, or None if no handler was registered before."""
		return self.io.set_link_handler(link_name,handler)
	def del_link_handler(self,link_name:str)->Callable:
"""Deletes link handler for the link_name. Returns the deleted handler, or None if none existed."""
		return self.io.del_link_handler(link_name)
	def del_all_link_handlers(self)->int:
"""Deletes all the link handlers.
		Returns number of deleted links."""
		return self.io.del_all_link_handlers()
	def _apply_settings_to_instrument(self,settings:InstrumentSettings)->None:
"""Applies settings relevant for the Instrument from the InstrumentSettings structure."""
		if settings.instrument_status_check is not None:
			self.io.query_instr_status=settings.instrument_status_check
		if self.simulating and settings.instrument_simulation_idn_string is not None:
			self.io.idn_string=settings.instrument_simulation_idn_string
	def compose_cmd_arg_param(self,arg1:ArgSingle,arg2:ArgSingle=None,arg3:ArgSingle=None,arg4:ArgSingle=None,arg5:ArgSingle=None,arg6:ArgSingle=None)->str:
"""Composes command parameter string based on the single argument definition."""
		return self._args_single_list.compose_cmd_string(arg1,arg2,arg3,arg4,arg5,arg6)
	def get_last_sent_cmd(self)->str:
"""Returns the last commands sent to the instrument. Only works in simulation mode"""
		return self.io.get_last_sent_cmd()
	def get_session_handle(self):
"""Returns the underlying pyvisa session."""
		return self.io.get_session_handle()
	def close(self):
"""Closes the Core session."""
		self.io.close()
		self.io=None

"""GlobalData.py"""
from datetime import datetime
class GlobalData:
"""Global package data that are valid for all of its instances."""
    bounded_class=None
    @classmethod
    def is_bounded(cls)->bool:
"""Returns true, if the class is bounded to a global source."""
        return cls.bounded_class is not None
    @classmethod
    def set_logging_target(cls,value:datetime or None)->None:
"""Sets the class variable to the entered value."""
        setattr(cls.bounded_class,'_global_logging_target_stream',value)
    @classmethod
    def get_logging_target(cls):
"""Returns the class variable value."""
        if not cls.is_bounded():
            return None
        return getattr(cls.bounded_class,'_global_logging_target_stream')
    @classmethod
    def set_logging_relative_timestamp(cls,value:datetime or None)->None:
 """Sets the class variable to the entered value."""
        setattr(cls.bounded_class,'_global_logging_relative_timestamp',value)
    @classmethod
    def get_logging_relative_timestamp(cls)->datetime or None:
 """Returns the class variable value."""
        if not cls.is_bounded():
            return None
        return getattr(cls.bounded_class,'_global_logging_relative_timestamp')

"""Instruments.py"""
import re
import threading
from enum import Enum
from typing import Callable,Dict,AnyStr
from datetime import datetime,timedelta
from . import Utilities,InstrumentSettings,InstrumentOptions,Conversions as Conv
from .ArgSingleSuppressed import ArgSingleSuppressed
from .ArgStructList import ArgStructList
from .InternalLinker import InternalLinker
from .IoTransferEventArgs import IoTransferEventArgs
from .StreamReader import StreamReader
from .StreamWriter import StreamWriter
from .Utilities import trim_str_response,size_to_kb_mb_string
from .VisaSession import VisaSession,EventArgsChunk
from .VisaSessionSim import VisaSessionSim
from .RepeatedCapability import RepeatedCapability
from .ScpiLogger import ScpiLogger
from .InstrumentErrors import *
class Instrument(object):
"""Model of an instrument with VISA interface."""
	def __init__(self,resource_name:str,simulate:bool,settings:InstrumentSettings,direct_session=None):
"""Opening an instrument session.
If simulate is true, it cannot be later switched to false anymore."""
		self._simulating:bool=simulate
		self._settings=settings
		self._direct_session=direct_session
		self.logger:ScpiLogger or None=None
		self._last_exc_log:str or None=None
		self._start_time:datetime or None=None
		self.__session=None
		self._global_repcaps:Dict[str,RepeatedCapability]={}
		self._linker=InternalLinker()
#noinspection PyTypeChecker
		self.on_write_handler:Callable=None
#noinspection PyTypeChecker
		self.on_read_handler:Callable=None
		self._io_events_include_data:bool=False
		self._lock=None
		self._before_query_handler=None
		self._before_write_handler=None
#noinspection PyTypeChecker
		self.total_execution_time:timedelta=None
#noinspection PyTypeChecker
		self.total_time_startpoint:datetime=None
		self.reset_time_statistics()
		if self._settings.selftest_timeout==0:
			self._settings.selftest_timeout=100000
#Changeable settings
		self.resource_name:str=resource_name
		self._instr_options:InstrumentOptions=None  #Internal private property for the lazy property self.instr_options-see the getter for self.instr_options. Initialized by the first access
		self.query_instr_status:bool=True
		self.opc_query_after_write:bool=False
		self.bin_float_numbers_format=self._settings.bin_float_numbers_format
		self.bin_int_numbers_format=self._settings.bin_int_numbers_format
		self.opc_query_after_write:bool=self._settings.opc_query_after_write
		self.stb_in_error_check:bool=self._settings.stb_in_error_check
		self.each_cmd_as_query:bool=self._settings.each_cmd_as_query
		self.manufacturer:str='Rohde&Schwarz'
		self.model:str='R&S Instrument'
		self.serial_number:str='100001'
		self.firmware_version:str='1.00'
		direct_start_time=datetime.now()
		try:
			dir_str=' from direct session' if self._direct_session else ''
			if self._simulating:
#noinspection PyTypeChecker
				self._set_session(VisaSessionSim(resource_name,self._settings,direct_session))
				self._init_logger(self._session.resource_name)
				self._log_start_segment(direct_start_time)
				self._lock=self._session.get_lock()
				self._instr_options=InstrumentOptions.Options('K0',InstrumentOptions.ParseMode.KeepOriginal)
				self._session.write('*OPT K0')
				self._log_info('Simulation session init',f"Simulation device{dir_str} '{self.resource_name}'")
				self._log_end_segment()
				return
			self._set_session(VisaSession(resource_name,self._settings,direct_session))
			self._init_logger(self._session.resource_name)
			self._log_start_segment(direct_start_time)
			self._lock=self._session.get_lock()
			with self._lock:
				self._session.clear_before_read()
				self.idn_string=Utilities.trim_str_response(self._session.query_str(self._session.cmd_idn)).strip()
#NRP-Z session coercing
				if self._session.is_rsnrp_session():
					self._settings.instr_options_parse_mode=InstrumentOptions.ParseMode.Skip
					self.stb_in_error_check=False
				self.instr_options_parse_mode=self._settings.instr_options_parse_mode
			self._log_info('Session init',f"Device{dir_str} '{self.resource_name}' IDN:{self.idn_string}")
		except RsInstrException as e:
			if not self.logger:
				self._assure_logger_exists()
				self._log_start_segment(direct_start_time)
			self._log_error('Session init error',e.args[0],self._start_time,datetime.now())
			raise
		finally:
			if not self.logger:
				self._assure_logger_exists()
				self._log_start_segment(direct_start_time)
			self.logger.allow_log_string_adjust=True
			self._log_end_segment()
	def __str__(self):
		if self._simulating:
			return f"Simulated,Model:'{self.model}',ResourceName:'{self.resource_name}'"
		else:
			return f"Instrument Model:'{self.model}',ResourceName:'{self.resource_name}'"
	def _init_logger(self,rsrc_name:str)->None:
"""Initializes the logger with default settings."""
		self.logger=ScpiLogger(rsrc_name,self._settings.encoding)
		if self._settings.logging_name is not None and self._settings.logging_name!=rsrc_name:
			self.logger.device_name=self._settings.logging_name
		self.logger.allow_log_string_adjust=False
		self.logger.mode=self._settings.logging_mode
		self.logger.log_to_console=self._settings.log_to_console
		self.logger.log_to_udp=self._settings.log_to_udp
		self.logger.udp_port=self._settings.log_udp_port
		if self._settings.log_to_global_target:
			self.logger.set_logging_target_global()
	def _assure_logger_exists(self)->None:
"""Initializes backup logger if the VisaSession ended with exception causing main logger to not be initialized.
		If the logger instance exists, the method does nothing."""
		if self.logger:
			return
		if self._direct_session:
			session=VisaSession.get_and_check_direct_session(self._direct_session)
			self._init_logger(session.resource_name)
			return
		self._init_logger(self.resource_name)
	@property
	def _session(self)->VisaSession:
"""Returns instrument VISA session. Throws exception if null."""
		if self.__session is None:
			raise RsInstrException(f'Instrument session \'{self.resource_name}\' is invalid. You have probably closed it already.')
		return self.__session
	def _set_session(self,session:VisaSession)->None:
"""Sets the VISA session to the provided value."""
		self.__session=session
	def _clear_session(self)->None:
"""Sets the VISA session to None."""
		self.__session=None
	def _session_exists(self)->bool:
"""Returns true, if the VISA session is not None."""
		return self.__session is not None
	@property
	def allow_reconnect(self)->bool:
"""Returns true, if the reconnection is supported-the session is unique, and not reused."""
		return not self._direct_session
	def reconnect(self,force_close:bool=False)->bool:
"""If the connection is not active, the method tries to reconnect to the device
If the connection is active, and force_close is False, the method does nothing.
If the connection is active, and force_close is True, the method closes, and opens the session again.
Returns True, if the reconnection has been performed."""
		if not self.allow_reconnect:
			raise RsInstrException('Reused sessions do not support reconnection')
		self._start_time=datetime.now()
		active=self.is_connection_active()
		log_info='Forced Reconnection' if force_close else 'Reconnection'
		if force_close and active:
			self._log_info(log_info,'Session was active,closing the session')
			self.close(log_info)
			active=False
		if active is True:
			self._log_info(log_info,'Session is still active,no action needed')
			return False
		if not active:
#Connect again
			try:
				dir_str=' from direct session' if self._direct_session else ''
				sim=' simulation' if self._direct_session else ''
				init_method=VisaSessionSim if self._simulating else VisaSession
				self._log_start_segment()
				self.__session=init_method(self.resource_name,self._settings,self._direct_session)
				self._log_info(log_info,f"Session init,{sim} device{dir_str} '{self.resource_name},IDN:{self.idn_string}'")
				self._log_end_segment()
				with self._lock:
					self._session.clear_before_read()
			except RsInstrException as e:
				if self.logger:
					self._log_error(log_info,e.args[0])
				raise
			finally:
				if self.logger:
					self._log_end_segment()
			return True
	def set_simulating_cmds(self)->None:
"""Updated cached values in the simulating VISA session to properly respond to *IDN? or *OPT?"""
		if self._simulating:
			self._session.write(f'*idn {self.idn_string}')
			self._session.write(f'*opt {Conv.list_to_csv_str(self.instr_options.get_all())}')
			self._session.write(f'*opc 1')
			self._session.write(f'*stb 0')
			self._session.write(f'*tst 0,"Passed"')
			self._session.write(f'syst:err 0,"No Error"')
			self._session.write(f'system:error 0,"No Error"')
	def get_last_sent_cmd(self)->str:
"""Returns the last commands sent to the instrument. Only works in simulation mode."""
		if self._simulating:
#noinspection PyUnresolvedReferences
			return self._session.get_last_sent_cmd()
		raise RsInstrException('get_last_sent_cmd() can only be used in simulation mode')
	def assign_lock(self,lock:threading.RLock)->None:
"""Assigns the thread lock provided from by the user. Trickles down to the VisaSession."""
		self._lock=lock
		self._session.assign_lock(lock)
	def get_lock(self)->threading.RLock:
"""Returns the current RLock object."""
		return self._lock
	def clear_lock(self):
"""Clears the existing thread lock, making the current session thread-independent from others that might share the current thread lock."""
		self.assign_lock(threading.RLock())
	def lock_resource(self,timeout:int,requested_key:str or bytes=None)->bytes or None:
"""Locks the instrument to prevent it from communicating with other clients."""
		return self._session.lock_resource(timeout,requested_key)
	def unlock_resource(self)->None:
"""Unlocks the instrument to other clients."""
		self._session.unlock_resource()
	def _log_start_segment(self,direct_start_time:datetime=None):
"""Sets start time for the log entry to be able to calculate the duration. You can enter a direct start time."""
		self._last_error_log=None
		if direct_start_time:
			self._start_time=direct_start_time
		else:
			self._start_time=datetime.now()
		self.logger.start_new_segment()
	def _log_info(self,log_string_info:str,log_string:str)->None:
"""Logs an ASCII entry."""
		self._last_exc_log=None
		self.logger.info(self._start_time,datetime.now(),log_string_info,log_string)
	def _log_info_list(self,log_string_info:str,list_data:List)->None:
"""Logs a List entry."""
		self._last_exc_log=None
		self.logger.info_list(self._start_time,datetime.now(),log_string_info,list_data)
	def _log_info_bin(self,log_string_info:str,log_data:bytes)->None:
"""Logs a binary entry."""
		self._last_exc_log=None
		self.logger.info_bin(self._start_time,datetime.now(),log_string_info,log_data)
	def _log_info_var_stream(self,log_string_info:str,binary:bool,content:AnyStr)->None:
"""Logs a stream entry-must be variable only, but can be binary or ascii."""
		self._last_exc_log=None
		if binary:
			self.logger.info_bin(self._start_time,datetime.now(),log_string_info,content)
		else:
			self.logger.info(self._start_time,datetime.now(),log_string_info,content)
	def _log_error(self,log_string_info:str,log_string:str,start_time:datetime=None,end_time:datetime=None)->None:
"""Logs an ASCII error entry."""
		self.logger.error(start_time,end_time,log_string_info,log_string)
	def _log_exception(self,e:Exception,context:str=None,start_time:datetime=None,end_time:datetime=None)->None:
"""Logs an ASCII error entry taken from the exception message."""
		if start_time is None:
			start_time=self._start_time
		if end_time is None:
			end_time=datetime.now()
		msg:str=e.args[0]
		if isinstance(e,StatusException):
#Status exceptions are handled specially to prevent duplicate logging of the same StatusException
			if msg==self._last_exc_log:
				return
			self._last_exc_log=msg
			msg=f'{e.__class__.__name__}:{msg}'
			self.logger.error(start_time,end_time,context,msg)
		else:
			self._last_exc_log=None
			self.logger.error(start_time,end_time,context,f'{e.__class__.__name__}:{msg}')
	def _log_end_segment(self)->None:
"""Ends logging segment."""
		if self._start_time:
#Accumulate the spent times
			end_time=datetime.now()
			if end_time >=self._start_time:
				diff=end_time-self._start_time
				self.total_execution_time+=diff
		self._start_time=None
		self._last_exc_log=None
		self.logger.end_current_segment()
	@property
	def visa_manufacturer(self)->str:
"""Returns the visa manufacturer of the current session."""
		return self._session.manufacturer
	@property
	def encoding(self)->str:
"""Returns string<=>bytes encoding of the session."""
		return self._session.encoding
	@encoding.setter
	def encoding(self,value:str)->None:
"""Sets string<=>bytes encoding of the session."""
		self._session.encoding=value
		self.logger.encoding=value
	def set_link_handler(self,link_name:str,handler:Callable)->Callable:
"""Adds/Updates link handler for the entered link_name. Handler API:handler(event_args:ArgLinkedEventArgs). Returns the previous registered handler, or None if no handler was registered before."""
		return self._linker.set_handler(link_name,handler)
	def del_link_handler(self,link_name:str)->Callable:
"""Deletes link handler for the link_name. Returns the deleted handler, or None if none existed."""
		return self._linker.del_handler(link_name)
	def del_all_link_handlers(self)->int:
"""Deletes all the link handlers. Returns number of deleted links."""
		return self._linker.del_all_handlers()
	@property
	def idn_string(self)->str:
"""Returns instrument's identification string."""
		return self._idn_string
	@idn_string.setter
	def idn_string(self,value:str)->None:
"""IDN string. Set it to force a different IDN string than the default *IDN? response."""
		self._idn_string=value
		self._parse_idn_string(self._idn_string)
	@property
	def instr_options(self)->InstrumentOptions:
"""Public getter for the lazy property instr_options."""
		if self._instr_options is None:
			self._query_options_and_parse(self.instr_options_parse_mode)
		return self._instr_options
	@property
	def opc_timeout(self)->int:
"""See the opc_timeout.setter."""
		return self._session.opc_timeout
	@opc_timeout.setter
	def opc_timeout(self,value:int)->None:
"""Sets/Gets timeout in milliseconds for all the operations that use OPC synchronization."""
		self._session.opc_timeout=value
	@property
	def visa_timeout(self)->int:
"""See the visa_timeout.setter."""
		return self._session.visa_timeout
	@visa_timeout.setter
	def visa_timeout(self,value:int)->None:
"""Sets/Gets visa IO timeout in milliseconds."""
		self._session.visa_timeout=value
	@property
	def data_chunk_size(self)->int:
"""Returns max chunk size of one data block."""
		return self._session.data_chunk_size
	@data_chunk_size.setter
	def data_chunk_size(self,chunk_size:int)->None:
"""Sets the maximum size of one block transferred during write/read operations."""
		self._session.data_chunk_size=int(chunk_size)
#noinspection PyMethodMayBeStatic
	def _sim_cached_value_found(self,value)->bool:
		return value!='Simulating'
#noinspection PyMethodMayBeStatic
	def _sim_cached_value_not_found(self,value)->bool:
		return value=='Simulating'
	def _parse_idn_string(self,idn_string:str)->None:
"""Parse the *IDN? response to:
- Manufacturer
- Model
- SerialNumber
- FirmwareRevision"""
		idn_string=Utilities.trim_str_response(idn_string).strip()
		items=idn_string.split(',')
		items_count=len(items)
		if len(idn_string)==0:
			items_count=0
		self.manufacturer="Rohde&Schwarz"
		if items_count >=1:
			self.manufacturer=Utilities.trim_str_response(items[0].strip())
		self.full_model_name="RsInstrument1000"
		if items_count >=2:
			self.full_model_name=Utilities.trim_str_response(items[1].strip())
		self.model=self.full_model_name
		if self._settings.idn_model_full_name is False:
			m=re.search(r'([a-zA-Z ]+)([\-\da-zA-Z ]*)',self.full_model_name)
			if m:
				self.model=m.group(1)
		self.serial_number="100000"
		if items_count >=3:
			self.serial_number=Utilities.trim_str_response(items[2].strip())
		self.firmware_version="1.0.0"
		if items_count >=4:
			self.firmware_version=Utilities.trim_str_response(items[3].strip())
	def fits_idn_pattern(self,patterns:List[str],supported_models:List[str])->None:
"""Throws exception if the current instrument model does not fit  any of the patterns. The supported_models argument is only used for exception messages."""
		matches=False
		assert self._idn_string,f'*IDN? was not assigned yet.'
		for x in patterns:
			matches=re.search(x,self.idn_string,re.IGNORECASE)
			if matches:
				break
		if not matches:
			message=f"Instrument is not supported.\n*IDN? string:'{self.idn_string}'"
			if len(supported_models)>0:
				message+=f"\nSupported models:'{','.join(supported_models)}'"
			if len(patterns)==1:
				message+=f"\nSupported IDN pattern:'{patterns[0]}'"
			if len(patterns)>1:
				message+="\nSupported IDN patterns:\n"+'\n'.join(patterns)
			raise UnexpectedResponseException(self.resource_name,message)
	def reset_time_statistics(self)->None:
"""Resets all execution and total time counters. Changes the self.total_time_startpoint and resets the self.total_execution_time."""
		self.total_execution_time=timedelta()
		self.total_time_startpoint=datetime.now()
	def _query_options_and_parse(self,mode:InstrumentOptions.ParseMode)->None:
"""Queries *OPT? and parses it based on the ParseMode."""
		if mode==InstrumentOptions.ParseMode.Skip:
			self._instr_options=InstrumentOptions.Options('',mode)
			return
		if self._simulating is False:
			with self._lock:
				log_info='Query Instrument Options'
				try:
					self._log_start_segment()
					opts=self._session.query_str_no_tout_err('*OPT?',1000)
					if opts is None:
						opts='Cannot read the instrument options-*OPT? query is not supported'
					self._instr_options=InstrumentOptions.Options(opts,mode)
					self._log_info(log_info,f'*OPT? {opts}')
				except RsInstrException as e:
					self._log_exception(e,log_info)
					raise
				finally:
					self._log_end_segment()
	def add_global_repcap(self,name:str,rep_cap:RepeatedCapability)->None:
"""Adds the global repcap name to the list of global repcaps and sets its value to the provided default value."""
		if name in self._global_repcaps:
			raise RsInstrException(f"Error adding new global repcap:'{name}' already exists in the list.")
		self._global_repcaps[name]=rep_cap
	def set_global_repcap_value(self,name:str,enum_value:Enum)->None:
"""Updates the existing global repcap value as enum"""
		if name not in self._global_repcaps:
			raise RsInstrException(f"Error updating global repcap:'{name}' does not exist in the list.")
		self._global_repcaps[name].set_enum_value(enum_value)
	def get_global_repcap_value(self,name:str)->Enum:
"""Returns the current global repcap value as enum"""
		if name not in self._global_repcaps:
			raise RsInstrException(f"Error retrieving global repcap:'{name}' does not exist in the list.")
		return self._global_repcaps[name].get_enum_value()
	def _replace_global_repcaps(self,cmd:str)->str:
"""Replaces all the global repcaps in the command:e.g. '<instance>'=>'1'.
		Returns the replaced command."""
		for name,value in self._global_repcaps.items():
			cmd_value=value.get_cmd_string_value()
			cmd=cmd.replace(name,cmd_value)
		return cmd
	def query_opc(self,timeout:int=0)->bool:
"""Sends *OPC? query and returns the result. If you define timeout>0, the VISA timeout is set to that value just for this method call."""
		if self._settings.disable_opc_query:
			return True
		with self._lock:
			try:
				self._log_start_segment()
				self.start_send_read_event('*OPC?',False)
				opc:bool=self._session.query_opc(timeout)
				self.end_send_read_event()
				self._log_info('Query OPC','1' if opc else '0')
			except RsInstrException as e:
				self._log_exception(e,'Query OPC')
				raise
			finally:
				self._log_end_segment()
			return opc
	def query_all_syst_errors(self,include_codes:bool=True,enable_log:bool=True)->List[str] or List[int,str] or None:
"""Returns all errors in the instrument's error queue. If no error is detected, the return value is None.
If include_codes is False:
you get List of strings with messages.
If include_codes is True:
- you get List of Tuples (code, message)"""
		with self._lock:
			log_info='Query all system errors'
			if enable_log is True:
				if self._start_time is None:
					self._start_time=datetime.now()
			try:
				self.start_send_read_event('SYST:ERROR?',False)
				errors=self._session.query_all_syst_errors()
				self.end_send_read_event()
				if errors is not None:
					if include_codes:
						entries=[f"{x[1]},'{x[0]}'" for x in errors]
					else:
						errors=[x[1] for x in errors]
						entries=errors
#Return errors as list of strings
				if enable_log is True:
					if errors is None or len(errors)==0:
						self._log_info(log_info,'No errors')
					elif len(errors)==1:
						self._log_info(log_info,f'1 error detected-{entries[0]}')
					else:
						self._log_info(log_info,f'{len(errors)} errors detected (last one on top)')
						i=1
						for x in entries:
							self._log_info(f'SYST:ERROR? {i}',x)
							i+=1
			except RsInstrException as e:
#General errors:log the exception message
				if enable_log is True:
					self._log_exception(e,log_info,start_time=self._start_time,end_time=datetime.now())
				raise
			return errors
	def check_status(self)->None:
"""Throws InstrumentStatusException in case of an error in the instrument's error queue. The procedure is skipped, if the QueryInstrumentStatus is set to false."""
		with self._lock:
			if not self.query_instr_status:
				return
			if self._start_time is None:
				self._start_time=datetime.now()
			try:
				call_syst_error=self._session.error_in_error_queue() if self.stb_in_error_check else True
				if call_syst_error:
					errors=self.query_all_syst_errors(enable_log=False)
					assert_no_instrument_status_errors(self.resource_name,errors)
				if self.logger.log_status_check_ok:
					self._log_info('Status check','OK')
			except RsInstrException as e:
#General errors:log the exception message
				self._log_exception(e,'Status check',start_time=self._start_time,end_time=datetime.now())
				raise
	def is_connection_active(self)->bool:
"""Returns true, if the VISA connection is active and the communication with the instrument still works. This is achieved by:
- checking the session property timeout
- sending the *IDN? query"""
		if self._session_exists() is False:
			return False
		return self._session.is_connection_active()
	def clear_status(self)->None:
"""Clears instrument's status subsystem."""
		with self._lock:
			try:
				self._log_start_segment()
				self._session.clear()
				self._session.clear_before_read()
				self._log_info('Clear status','OK')
			except RsInstrException as e:
				self._log_exception(e,'Clear status')
				raise
			finally:
				self._log_end_segment()
	def reset(self,timeout:int=0)->None:
"""Resets the instrument and clears its status. If you define timeout>0, the VISA timeout is set to that value just for this method call."""
		old_tout=0
		if timeout!=0:
			old_tout=self.visa_timeout
			self.visa_timeout=timeout
		try:
			with self._lock:
				self.write(self._settings.cmd_reset,True)
				self.query_opc()
				self.clear_status()
				self._log_start_segment()
				self.check_status()
				self._log_end_segment()
		finally:
			if old_tout>0:
				self.visa_timeout=old_tout
	def write(self,cmd:str,block_callback:bool=False,log_info:str='Write')->None:
"""Writes string command to the instrument."""
		if self.each_cmd_as_query:
			self.query_str(cmd,block_callback,log_info)
			return
		with self._lock:
			try:
				self._log_start_segment()
				cmd=self._replace_global_repcaps(cmd)
				self._call_before_write_handler(cmd,block_callback)
				self._session.write(cmd)
				if self.opc_query_after_write:
					self._session.query_opc()
				if self.on_write_handler:
					self.send_write_str_event(cmd,False)
				self._log_info(log_info,cmd)
				self.check_status()
			except RsInstrException as e:
				self._log_exception(e,log_info)
				raise
			finally:
				self._log_end_segment()
	def write_with_opc(self,cmd:str,timeout:int=None,block_callback:bool=False,log_info:str='Write string with OPC')->None:
"""Writes a OPC-synced command.
Also performs error checking if the property self.query_instr_status is set to True.
If you do not provide timeout, the method uses current opc_timeout."""
		if self.each_cmd_as_query:
			self.query_str_with_opc(cmd,timeout,block_callback,log_info)
			return
		with self._lock:
			try:
				self._log_start_segment()
				cmd=self._replace_global_repcaps(cmd)
				self._call_before_write_handler(cmd,block_callback)
				self._session.write_with_opc(cmd,timeout)
				self._session.query_and_clear_esr()
				if self.on_write_handler:
					self.send_write_str_event(cmd,True)
				self._log_info(log_info,cmd)
				self.check_status()
			except RsInstrException as e:
				self._log_exception(e,log_info)
				raise
			finally:
				self._log_end_segment()
	def write_struct(self,cmd:str,struct:object)->None:
"""Writes command to the instrument with the parameter composed of the entered structure."""
		with self._lock:
			worker=ArgStructList(struct)
			param=worker.compose_cmd_string()
			cmd+=f' {param}'.rstrip()
			self.write(cmd,log_info='Write structure')
	def write_struct_with_opc(self,cmd:str,struct:object,timeout:int=None)->None:
"""Writes OPC-synced command to the instrument with the parameter composed of the entered structure. If you do not provide timeout, the method uses current opc_timeout."""
		with self._lock:
			worker=ArgStructList(struct)
			param=worker.compose_cmd_string()
			cmd+=f' {param}'.rstrip()
			self.write_with_opc(cmd,timeout,log_info='Write structure with OPC')
	def query_str(self,query:str,block_callback:bool=False,log_info:str='Query string')->str:
"""Sends a query and reads response from the instrument. The response is trimmed of any trailing LF characters and has no length limit."""
		with self._lock:
			try:
				self._log_start_segment()
				query=self._replace_global_repcaps(query)
				self.start_send_read_event(query,False)
				self._call_pre_query_handler(query,block_callback)
				response=self._session.query_str(query)
				self.end_send_read_event()
				self._log_info(log_info,f'{query} {response}')
				self.check_status()
			except RsInstrException as e:
				self._log_exception(e,log_info)
				raise
			finally:
				self._log_end_segment()
			return response
	def query_str_with_opc(self,query:str,timeout:int=None,block_callback:bool=False,log_info:str='Query string with OPC')->str:
"""Sends a OPC-synced query. Also performs error checking if the self.query_instr_status is true. The response is trimmed of any trailing LF characters and has no length limit. If you do not provide timeout, the method uses current opc_timeout."""
		with self._lock:
			try:
				self._log_start_segment()
				query=self._replace_global_repcaps(query)
				self.start_send_read_event(query,True)
				self._call_pre_query_handler(query,block_callback)
				response=self._session.query_str_with_opc(query,timeout,log_info)
				self.end_send_read_event()
				self._session.query_and_clear_esr()
				self._log_info(log_info,f'{query} {response}')
				self.check_status()
			except RsInstrException as e:
				self._log_exception(e,log_info)
				raise
			finally:
				self._log_end_segment()
			return response
	def query_bin_block(self,query:str,log_info:str='Query binary block')->bytes:
"""Queries binary data block to bytes and returns data as bytes. Throws an exception if the returned data was not a binary data."""
		with self._lock:
			with StreamWriter.as_bin_var() as stream:
				try:
					log_info=f'{log_info} {query}'
					self._log_start_segment()
					query=self._replace_global_repcaps(query)
					self.start_send_read_event(query,False)
					self._call_pre_query_handler(query,False)
					self._session.query_bin_block(query,stream,True)
					self.end_send_read_event()
					content=stream.content
					self._log_info_var_stream(f'{log_info}, received',stream.binary,content)
					self.check_status()
				except RsInstrException as e:
					self._log_exception(e,log_info)
					raise
				finally:
					self._log_end_segment()
				return content
	def query_bin_block_with_opc(self,query:str,timeout:int=None,log_info:str='Query binary block with OPC')->bytes:
"""Sends a OPC-synced query and returns data as bytes. If you do not provide timeout, the method uses current opc_timeout."""
		with self._lock:
			with StreamWriter.as_bin_var() as stream:
				try:
					log_info=f'{log_info} {query}'
					self._log_start_segment()
					query=self._replace_global_repcaps(query)
					self.start_send_read_event(query,True)
					self._call_pre_query_handler(query,False)
					self._session.query_bin_block_with_opc(query,stream,True,timeout)
					self.end_send_read_event()
					self._session.query_and_clear_esr()
					content=stream.content
					self._log_info_var_stream(f'{log_info},received',stream.binary,content)
					self.check_status()
				except RsInstrException as e:
					self._log_exception(e,log_info)
					raise
				finally:
					self._log_end_segment()
				return content
	def query_bin_block_to_file(self,query:str,file_path:str,append:bool=False,log_info='Query binary block to file')->None:
"""Queries binary data block to the provided file.
If append is False, any existing file content is discarded.
If append is True, the new content is added to the end of the existing file, or if the file does not exit, it is created.
Throws an exception if the returned data was not a binary data."""
		with self._lock:
			with StreamWriter.as_bin_file(file_path,append) as stream:
				try:
					self._log_start_segment()
					query=self._replace_global_repcaps(query)
					self.start_send_read_event(query,False)
					self._call_pre_query_handler(query,False)
					self._session.query_bin_block(query,stream,True)
					self.end_send_read_event()
					add_str='target file' if append is False else 'appended to target file'
					self._log_info(log_info,f'Query {query}-written {size_to_kb_mb_string(stream.written_len,True)},{add_str} {file_path}')
					self.check_status()
				except RsInstrException as e:
					self._log_exception(e,log_info)
					raise
				finally:
					self._log_end_segment()
	def query_bin_block_to_file_with_opc(self,query:str,file_path:str,append:bool=False,timeout:int=None,log_info='Query binary block to file with OPC')->None:
"""Sends a OPC-synced query and writes the returned data to the provided file.
If append is False, any existing file content is discarded.
If append is True, the new content is added to the end of the existing file, or if the file does not exit, it is created.
Throws an exception if the returned data was not a binary data."""
		with self._lock:
			with StreamWriter.as_bin_file(file_path,append) as stream:
				try:
					self._log_start_segment()
					query=self._replace_global_repcaps(query)
					self.start_send_read_event(query,True)
					self._call_pre_query_handler(query,False)
					self._session.query_bin_block_with_opc(query,stream,True,timeout)
					self.end_send_read_event()
					self._session.query_and_clear_esr()
					add_str='target file' if append is False else 'appended to target file'
					self._log_info(log_info,f'Query {query}-written {size_to_kb_mb_string(stream.written_len,True)},{add_str} {file_path}')
					self.check_status()
				except RsInstrException as e:
					self._log_exception(e,log_info)
					raise
				finally:
					self._log_end_segment()
	def query_int(self,query:str)->int:
"""Sends a query and reads response from the instrument as integer."""
		with self._lock:
			string=self.query_str(query,log_info='Query integer')
			if self._simulating and self._sim_cached_value_not_found(string):
				return 0
			return Conv.str_to_int(string)
	def query_int_with_opc(self,query:str,timeout:int=None)->int:
"""Sends a OPC-synced query and reads response from the instrument as integer number. If you do not provide timeout, the method uses current opc_timeout."""
		with self._lock:
			string=self.query_str_with_opc(query,timeout,log_info='Query integer with OPC')
			if self._simulating and self._sim_cached_value_not_found(string):
				return 0
			return Conv.str_to_int(string)
	def query_float(self,query:str)->float:
"""Sends a query and reads response from the instrument as float number."""
		with self._lock:
			string=self.query_str(query,log_info='Query float')
			if self._simulating and self._sim_cached_value_not_found(string):
				return 0.0
			return Conv.str_to_float(string)
	def query_float_with_opc(self,query:str,timeout:int=None)->float:
"""Sends a OPC-synced query and reads response from the instrument as float number. If you do not provide timeout, the method uses current opc_timeout."""
		with self._lock:
			string=self.query_str_with_opc(query,timeout,log_info='Query float with OPC')
			if self._simulating and self._sim_cached_value_not_found(string):
				return 0.0
			return Conv.str_to_float(string)
	def query_bool(self,query:str)->bool:
"""Sends a query and reads response from the instrument as boolean value."""
		with self._lock:
			string=self.query_str(query,log_info='Query boolean')
			if self._simulating and self._sim_cached_value_not_found(string):
				return False
			return Conv.str_to_bool(string)
	def query_bool_with_opc(self,query:str,timeout:int=None)->bool:
"""Sends a OPC-synced query and reads response from the instrument as boolean value. If you do not provide timeout, the method uses current opc_timeout."""
		with self._lock:
			string=self.query_str_with_opc(query,timeout,log_info='Query boolean with OPC')
			if self._simulating and self._sim_cached_value_not_found(string):
				return False
			return Conv.str_to_bool(string)
	def query_str_list(self,query:str)->List[str]:
"""Sends a query and reads response from the instrument as csv-list."""
		with self._lock:
			string=self.query_str(query,log_info='Query string list')
			if self._simulating and self._sim_cached_value_not_found(string):
				string='AAA,BBB,CCC,DDD,EEE,FFF,GGG,HHH,III,JJJ'
			response=[trim_str_response(x) for x in string.split(',')]
			return response
	def query_str_list_with_opc(self,query:str,timeout:int=None)->List[str]:
"""Sends a OPC-synced query and reads response from the instrument as csv-list. If you do not provide timeout, the method uses current opc_timeout."""
		with self._lock:
			string=self.query_str_with_opc(query,timeout,log_info='Query string list with OPC')
			if self._simulating and self._sim_cached_value_not_found(string):
				string='AAA,BBB,CCC,DDD,EEE,FFF,GGG,HHH,III,JJJ'
			response=[trim_str_response(x) for x in string.split(',')]
			return response
	def query_bool_list(self,query:str)->List[bool]:
"""Sends a query and reads response from the instrument as csv-list of booleans."""
		with self._lock:
			string=self.query_str(query,log_info='Query boolean list')
			if self._simulating and self._sim_cached_value_not_found(string):
				string='True,False,0,1,1,True,true,false,true,false'
			response=[Conv.str_to_bool(x) for x in string.split(',')]
			return response
	def query_bool_list_with_opc(self,query:str,timeout:int=None)->List[bool]:
"""Sends a OPC-synced query and reads response from the instrument as csv-list of booleans. If you do not provide timeout, the method uses current opc_timeout."""
		with self._lock:
			string=self.query_str_with_opc(query,timeout,log_info='Query boolean list with OPC')
			if self._simulating and self._sim_cached_value_not_found(string):
				string='True,False,0,1,1,True,true,false,true,false'
			response=[Conv.str_to_bool(x) for x in string.split(',')]
			return response
	def write_bin_block(self,cmd:str,payload:bytes,log_info:str='Write binary block')->None:
"""Writes all the payload as binary data block to the instrument.
The binary data header is added at the beginning of the transmission automatically, do not include it in the payload!!!"""
		with self._lock:
			try:
				self._log_start_segment()
				cmd=self._replace_global_repcaps(cmd)
				self._call_before_write_handler(cmd,False)
				stream=StreamReader.as_bin_var(payload)
				if self.on_write_handler:
					self.start_send_write_bin_event(cmd)
				self._session.write_bin_block(cmd,stream)
				self.end_send_write_bin_event()
				self._log_info_bin(f'{log_info} {cmd},binary data',payload)
				self.check_status()
			except RsInstrException as e:
				self._log_exception(e,log_info)
				raise
			finally:
				self._log_end_segment()
	def write_bin_block_from_file(self,cmd:str,file_path:str,log_info:str='Write binary block from file')->None:
"""Writes all the file content as binary data block to the instrument. The binary data header is added at the beginning of the transmission automatically, do not include it in the file content!!!"""
		with self._lock:
			with StreamReader.as_bin_file(file_path) as stream:
				try:
					self._log_start_segment()
					cmd=self._replace_global_repcaps(cmd)
					self._call_before_write_handler(cmd,False)
					if self.on_write_handler:
						self.start_send_write_bin_event(cmd)
					self._session.write_bin_block(cmd,stream)
					self.end_send_write_bin_event()
					self._log_info(log_info,f'Command {cmd}-written {size_to_kb_mb_string(stream.read_len,True)},source file {file_path}')
					self.check_status()
				except RsInstrException as e:
					self._log_exception(e,log_info)
					raise
				finally:
					self._log_end_segment()
	def send_file_from_pc_to_instrument(self,source_pc_file:str,target_instr_file:str)->None:
"""SCPI Command:MMEM:DATA \n. Sends file from PC to the instrument"""
		cmd=f"MMEM:DATA '{target_instr_file}',"
		self.write_bin_block_from_file(cmd,source_pc_file,log_info='Send file from PC to the instrument')
	def read_file_from_instrument_to_pc(self,source_instr_file:str,target_pc_file:str,append_to_pc_file:bool=False)->None:
"""SCPI Command:MMEM:DATA? \n Reads file from instrument to the PC. \n  Set the append_to_pc_file to True if you want to append the read content to the end of the existing PC file"""
		cmd=f"MMEM:DATA? '{source_instr_file}'"
		self.query_bin_block_to_file(cmd,target_pc_file,append_to_pc_file,log_info='Read file from instrument to the PC')
	def get_file_size(self,instr_file:str)->int or None:
"""Returns the size of the file if it exists. If not, the method returns None. Warning!!!-for non-VXI sessions (SOCKET, ASRL) this method transfers the entire file to the control PC, which might take a long time."""
		query=f"MMEM:DATA? '{instr_file}'"
		log_info='Testing file existence'
		with self._lock:
			try:
				self._log_start_segment()
				self._call_pre_query_handler(query,False)
				length=self._session.get_bin_data_length(query)
				if length is None:
					self._log_info(log_info,f'File {instr_file} does not exist.')
				else:
					self._log_info(log_info,f'File {instr_file} exists,size {size_to_kb_mb_string(length,True)}')
				self.check_status()
				return length
			except RsInstrException as e:
				self._log_exception(e,log_info)
				raise
			finally:
				self._log_end_segment()
	def query_bin_or_ascii_float_list(self,query:str,log_info:str='Query binary or ascii float list')->List[float]:
"""Queries a list of floating-point numbers that can be read in ASCII format or in binary format.
- For ASCII format, the list numbers are decoded as comma-separated values.
- For Binary Format, the numbers are decoded based on the property BinFloatFormat, usually float 32-bit (FORM REAL,32)."""
		with self._lock:
			try:
				log_info=f'{log_info} {query}'
				self._log_start_segment()
				query=self._replace_global_repcaps(query)
				self.start_send_read_event(query,False)
				stream=StreamWriter.as_bin_var()
				self._call_pre_query_handler(query,False)
				self._session.query_bin_block(query,stream,False)
				self.end_send_read_event()
				if self._simulating and not self._session.cached_to_stream:
					return [0.1,1.2,2.3,3.4,4.5,5.6,6.7,7.8,8.9,9.1,10.2]
				if stream.binary:
					result=Conv.bytes_to_list_of_floats(stream.content,self.bin_float_numbers_format)
					self._log_info_list(f'{log_info},received binary format list {size_to_kb_mb_string(stream.written_len,True)} {stream.written_len // len(result)} bytes per number',result)
				else:
					result=Conv.str_to_float_list(stream.content)
					self._log_info_list(f'{log_info},received ascii format list',result)
				self.check_status()
				return result
			except RsInstrException as e:
				self._log_exception(e,log_info)
				raise
			finally:
				self._log_end_segment()
	def query_bin_or_ascii_float_list_with_opc(self,query:str,timeout:int=None,log_info:str='Query binary or ascii float list with OPC')->List[float]:
"""Sends a OPC-synced query and reads a list of floating-point numbers that can be read in ASCII format or in binary format.
- For ASCII format, the list numbers are decoded as comma-separated values.
- For Binary Format, the numbers are decoded based on the property BinFloatFormat, usually float 32-bit (FORM REAL,32).
If you do not provide timeout, the method uses current opc_timeout."""
		with self._lock:
			try:
				log_info=f'{log_info} {query}'
				self._log_start_segment()
				query=self._replace_global_repcaps(query)
				self.start_send_read_event(query,True)
				stream=StreamWriter.as_bin_var()
				self._call_pre_query_handler(query,False)
				self._session.query_bin_block_with_opc(query,stream,False,timeout)
				self.end_send_read_event()
				if self._simulating and not self._session.cached_to_stream:
					return [0.1,1.2,2.3,3.4,4.5,5.6,6.7,7.8,8.9,9.1,10.2]
				if stream.binary:
					result=Conv.bytes_to_list_of_floats(stream.content,self.bin_float_numbers_format)
					self._log_info_list(f'{log_info},received binary format list {size_to_kb_mb_string(stream.written_len,True)} {stream.written_len // len(result)} bytes per number',result)
				else:
					result=Conv.str_to_float_list(stream.content)
					self._log_info_list(f'{log_info},received ascii format list',result)
				self._session.query_and_clear_esr()
				self.check_status()
				return result
			except RsInstrException as e:
				self._log_exception(e,log_info)
				raise
			finally:
				self._log_end_segment()
	def query_bin_or_ascii_float_list_suppressed(self,query:str,suppressed:ArgSingleSuppressed)->List[float]:
"""Queries string of unknown size from instrument, and returns the part without the suppressed argument as list of floats. The current implementation allows for the rest of the string to be only ASCII format."""
		with self._lock:
			string=self.query_str(query,log_info='Query float list suppressed')
			if self._simulating and self._sim_cached_value_not_found(string):
				return [0.1,1.2,2.3,3.4,4.5,5.6,6.7,7.8,8.9,9.1,10.2]
			response=self._linker.cut_from_response_string(suppressed,string,query)
			return Conv.str_to_float_list(response)
	def query_bin_or_ascii_float_list_suppressed_with_opc(self,query:str,suppressed:ArgSingleSuppressed,timeout:int=None)->List[float]:
"""Queries string of unknown size from instrument, and returns the part without the suppressed argument as list of floats.
If you do not provide timeout, the method uses current opc_timeout. The current implementation allows for the rest of the string to be only ASCII format."""
		with self._lock:
			string=self.query_str_with_opc(query,timeout,log_info='Query float list suppressed with OPC')
			if self._simulating and self._sim_cached_value_not_found(string):
				return [0.1,1.2,2.3,3.4,4.5,5.6,6.7,7.8,8.9,9.1,10.2]
			response=self._linker.cut_from_response_string(suppressed, string,query)
			return Conv.str_to_float_list(response)
	def query_bin_or_ascii_int_list(self,query:str,log_info:str='Query binary or ascii integer list')->List[int]:
"""Queries a list of integer numbers that can be read in ASCII format or in binary format.
- For ASCII format, the list numbers are decoded as comma-separated values.
- For Binary Format, the numbers are decoded based on the property BinIntFormat, usually int 32-bit (FORM REAL,32)."""
		with self._lock:
			try:
				log_info=f'{log_info} {query}'
				self._log_start_segment()
				query=self._replace_global_repcaps(query)
				self.start_send_read_event(query,False)
				stream=StreamWriter.as_bin_var()
				self._call_pre_query_handler(query,False)
				self._session.query_bin_block(query,stream,False)
				self.end_send_read_event()
				if self._simulating and not self._session.cached_to_stream:
					return [1,2,3,5,10,15,20,30,50,100]
				if stream.binary:
					result=Conv.bytes_to_list_of_integers(stream.content,self.bin_int_numbers_format)
					self._log_info_list(f'{log_info},received binary format list {size_to_kb_mb_string(stream.written_len,True)} {stream.written_len // len(result)} bytes per number',result)
				else:
					result=Conv.str_to_int_list(stream.content)
					self._log_info_list(f'{log_info},received ascii format list',result)
				self.check_status()
				return result
			except RsInstrException as e:
				self._log_exception(e,log_info)
				raise
			finally:
				self._log_end_segment()
	def query_bin_or_ascii_int_list_with_opc(self,query:str,timeout:int=None,log_info:str='Query binary or ascii integer list with OPC')->List[int]:
"""Sends a OPC-synced query and reads a list of integer numbers that can be read in ASCII format or in binary format.
- For ASCII format, the list numbers are decoded as comma-separated values.
- For Binary Format, the numbers are decoded based on the property BinIntFormat, usually int 32-bit (FORM REAL,32).
If you do not provide timeout, the method uses current opc_timeout."""
		with self._lock:
			try:
				log_info=f'{log_info} {query}'
				self._log_start_segment()
				query=self._replace_global_repcaps(query)
				self.start_send_read_event(query,True)
				stream=StreamWriter.as_bin_var()
				self._call_pre_query_handler(query,False)
				self._session.query_bin_block_with_opc(query,stream,False,timeout)
				self.end_send_read_event()
				if self._simulating and not self._session.cached_to_stream:
					return [1,2,3,5,10,15,20,30,50,100]
				if stream.binary:
					result=Conv.bytes_to_list_of_integers(stream.content,self.bin_int_numbers_format)
					self._log_info_list(f'{log_info},received binary format list {size_to_kb_mb_string(stream.written_len,True)} {stream.written_len // len(result)} bytes per number',result)
				else:
					result=Conv.str_to_int_list(stream.content)
					self._log_info_list(f'{log_info},received ascii format list',result)
				self._session.query_and_clear_esr()
				self.check_status()
				return result
			except RsInstrException as e:
				self._log_exception(e,log_info)
				raise
			finally:
				self._log_end_segment()
	def query_bin_or_ascii_int_list_suppressed(self,query:str,suppressed:ArgSingleSuppressed)->List[int]:
"""Queries string of unknown size from instrument, and returns the part without the suppressed argument as list of integers.
The current implementation allows for the rest of the string to be only ASCII format."""
		with self._lock:
			response=self.query_str(query,log_info='Query integer list suppressed')
			if self._simulating:
				return [1,2,3,5,10,15,20,30,50,100]
			response=self._linker.cut_from_response_string(suppressed,response,query)
			return Conv.str_to_int_list(response)
	def query_bin_or_ascii_int_list_suppressed_with_opc(self,query:str,suppressed:ArgSingleSuppressed,timeout:int=None)->List[int]:
"""Queries string of unknown size from instrument, and returns the part without the suppressed argument as list of integers.
If you do not provide timeout, the method uses current opc_timeout. The current implementation allows for the rest of the string to be only ASCII format."""
		with self._lock:
			response=self.query_str_with_opc(query,timeout,log_info='Query integer list suppressed with OPC')
			if self._simulating:
				return [1,2,3,5,10,15,20,30,50,100]
			response=self._linker.cut_from_response_string(suppressed,response,query)
			return Conv.str_to_int_list(response)
	def query_struct(self,query:str,struct:object)->object:
"""Queries string of from instrument, and parses it based on the provided structure object. The method returns the copy of the entered object that it had modified."""
		with self._lock:
			string=self.query_str(query,log_info='Query structure')
			if self._simulating and self._sim_cached_value_not_found(string):
				return struct
			struct_list=ArgStructList(struct)
			struct_list.parse_from_cmd_response(string)
			self._linker.invoke_struct_intern_links(struct,struct_list.args,query)
			return struct
	def query_struct_with_opc(self,query:str,struct:object,timeout:int=None)->object:
"""Queries string of from instrument, and parses it based on the provided structure object. The method returns the copy of the entered object that it had modified."""
		with self._lock:
			string=self.query_str_with_opc(query,timeout,log_info='Query structure with OPC')
			if self._simulating and self._sim_cached_value_not_found(string):
				return struct
			struct_list=ArgStructList(struct)
			struct_list.parse_from_cmd_response(string)
			self._linker.invoke_struct_intern_links(struct,struct_list.args,query)
			return struct
	def query_str_suppressed(self,query:str,suppressed:ArgSingleSuppressed)->str:
"""Queries string of unknown size from instrument, and returns the part without the suppressed argument."""
		with self._lock:
			string=self.query_str(query,log_info='Query string suppressed')
			if self._simulating and self._sim_cached_value_not_found(string):
				return string
			response=self._linker.cut_from_response_string(suppressed,string,query)
			return response
	def query_str_suppressed_with_opc(self,query:str,suppressed:ArgSingleSuppressed,timeout:int=None)->str:
"""Queries string of unknown size from instrument, and returns the part without the suppressed argument."""
		with self._lock:
			string=self.query_str_with_opc(query,timeout,log_info='Query string suppressed with OPC')
			if self._simulating and self._sim_cached_value_not_found(string):
				return string
			response=self._linker.cut_from_response_string(suppressed,string,query)
			return response
	def self_test(self,timeout:int=None)->Tuple[int,str]:
"""Performs instrument's selftest (*TST?). Returns tuple (code:int,message:str). . Code 0 means the self-test passed.
You can define the custom timeout in milliseconds. If you do not define it, the default selftest timeout is used (usually 60 s)."""
		with self._lock:
			if timeout is None or timeout==0:
				timeout=self._settings.selftest_timeout
			response=self.query_str_with_opc('*TST?',timeout,log_info='Self Test')
			m=re.search(r'^(-?\d+)(,(.*))?',response)
			if not m:
				raise UnexpectedResponseException(self.resource_name,f"Unexpected response to a '*TST?' self-test query:'{response}'")
			code=Conv.str_to_int(m.group(1))
			msg=Utilities.trim_str_response(m.group(3))
			self.check_status()
			return code,msg
	def go_to_local(self)->None:
"""Puts the instrument into local state."""
		with self._lock:
			log_info='Go To Local'
			try:
				self._log_start_segment()
				self._session.go_to_local()
				self._log_info(log_info,'Going to Local State')
			except RsInstrException as e:
				self._log_exception(e,log_info)
				raise
			finally:
				self._log_end_segment()
	def go_to_remote(self)->None:
"""Puts the instrument into remote state."""
		with self._lock:
			log_info='Go To Remote'
			try:
				self._log_start_segment()
				self._session.go_to_remote()
				self._log_info(log_info,'Going to Remote State')
			except RsInstrException as e:
				self._log_exception(e,log_info)
				raise
			finally:
				self._log_end_segment()
	def get_session_handle(self)->object:
"""Returns the underlying pyvisa session."""
		return self._session.get_session_handle()
	def close(self,log_info='Close')->None:
"""Closes the Instrument session."""
		with self._lock:
			try:
				self._log_start_segment()
				if self._session_exists():
					reused=self._session.reusing_session
					self._session.close()
					self._clear_session()
					try:
#Tolerate error when trying to log to the closed stream.  #This is only tolerated in the close() method.
						log_string='Closing reused session' if reused else 'Closing session'
						self._log_info(log_info,log_string)
					except RsInstrException as e:
						if 'Error logging to the stream' not in e.args[0]:
							raise
			except RsInstrException as e:
				self._log_exception(e,log_info)
				raise
			finally:
				self._log_end_segment()

#Events part -------------------------------------------------------------
	@property
	def io_events_include_data(self)->bool:
"""If true, the read and write handlers also include read and written data."""
		return self._io_events_include_data
	@io_events_include_data.setter
	def io_events_include_data(self,value:bool)->None:
"""If true, the read and write handlers also include read and written data."""
		self._io_events_include_data=value
		self._session.io_events_include_data=value
	def event_args_append_instr_info(self,args:IoTransferEventArgs)->IoTransferEventArgs:
"""Appends instrument-related information to the read/write event argument"""
		args.chunk_size=self.data_chunk_size
		args.resource_name=self.resource_name
		return args
	def send_write_str_event(self,cmd:str,opc_sync:bool)->None:
"""Creates and sends write string event. The transfer is marked as done (end_of_transfer=True)."""
		args=IoTransferEventArgs.write_str(opc_sync,len(cmd),cmd)
		args.transferred_size=args.total_size
		args.chunk_ix=0
		args.end_of_transfer=True
		args=self.event_args_append_instr_info(args)
		if self._io_events_include_data:
			args.data=cmd
		self.on_write_handler(args)
	def start_send_read_event(self,query:str,opc_sync:bool)->None:
"""Registers VisaSession.on_read_chunk_handler() which then generates events with each chunk transfer. Event handler for these events is the local function of this method, which sends IoTransferEventArgs further up to the Instrument.on_read_handler()"""
		if not self.on_read_handler:
			return
		def _read_chunk_handler(visa_args:EventArgsChunk)->None:
"""Receives events from VisaSession on read chunk transfers, and sends them as IoTransferEventArgs to the Instrument.on_read_handler()"""
			args.end_of_transfer=visa_args.end_of_transfer
			args.chunk_ix=visa_args.chunk_ix
			args.total_chunks=visa_args.total_chunks
			args.chunk_size=visa_args.chunk_size
			args.transferred_size=visa_args.transferred_size
			args.total_size=visa_args.total_size
			args.data=visa_args.data
			args.binary=visa_args.binary
			self.on_read_handler(args)
		args=IoTransferEventArgs.read_chunk(opc_sync,query)
		args=self.event_args_append_instr_info(args)
		self._session.on_read_chunk_handler=_read_chunk_handler
	def end_send_read_event(self):
"""Unregisters VisaSession.on_read_chunk_handler()"""
		self._session.on_read_chunk_handler=None
	def start_send_write_bin_event(self,cmd:str)->None:
"""Registers VisaSession.on_write_chunk_handler() which then generates events with each chunk transfer. Event handler for these events is the local function of this method, which sends IoTransferEventArgs further up to the Instrument.on_write_handler()"""
		if not self.on_write_handler:
			return
		def _write_chunk_handler(visa_args:EventArgsChunk)->None:
"""Receives events from VisaSession on write chunk transfers, and sends them as IoTransferEventArgs to the Instrument.on_write_handler()"""
			args.end_of_transfer=visa_args.end_of_transfer
			args.chunk_ix=visa_args.chunk_ix
			args.total_chunks=visa_args.total_chunks
			args.chunk_size=visa_args.chunk_size
			args.transferred_size=visa_args.transferred_size
			args.total_size=visa_args.total_size
			args.data=visa_args.data
			args.binary=visa_args.binary
			self.on_write_handler(args)
		args=IoTransferEventArgs.write_bin(cmd)
		args=self.event_args_append_instr_info(args)
		self._session.on_write_chunk_handler=_write_chunk_handler
	def end_send_write_bin_event(self):
"""Unregisters VisaSession.on_write_chunk_handler()"""
		self._session.on_write_chunk_handler=None
	def _call_before_write_handler(self,cmd:str,block_callback:bool)->None:
"""Calls the _pre_write_handler if defined. Used in all the base write methods."""
		if block_callback is False and self._before_write_handler:
			self._before_write_handler(self,cmd)
	def _call_pre_query_handler(self,query:str,block_callback:bool)->None:
"""Calls the _pre_query_handler if defined. Used in all the base query methods."""
		if block_callback is False and self._before_query_handler:
			self._before_query_handler(self,query)
	@property
	def before_write_handler(self)->Callable:
"""Returns the handler of before_write events. \n  :return:current before_write_handler"""
		return self._before_write_handler
	@before_write_handler.setter
	def before_write_handler(self,handler:Callable)->None:
"""Sets handler for before_write events. The before_write event is invoked before each write operation (only once, not for every chunk) Event prototype:handler(io:Instrument,cmd:str) :param handler:new handler"""
		self._before_write_handler=handler
	@property
	def before_query_handler(self)->Callable:
"""Returns the handler of before_query events. \n
		:return:current before_query_handler"""
		return self._before_query_handler
	@before_query_handler.setter
	def before_query_handler(self,handler:Callable)->None:
"""Sets handler for before_query events. The before_query event is invoked before each query operation (only once, not for every chunk). Event prototype:handler(io:Instrument, query:str) :param handler:new handler"""
		self._before_query_handler=handler
"""Definition of RsInstrument exceptions, assert functions, and other error-related functions. InstrumentErrors.py"""
from typing import List,Tuple
class RsInstrException(Exception):
"""Exception base class for all the RsInstrument exceptions."""
	def __init__(self,message:str):
		super(RsInstrException,self).__init__(message)
		self.message=message
class TimeoutException(RsInstrException):
"""Exception for timeout errors."""
	def __init__(self,message:str):
		super(TimeoutException,self).__init__(message)
class StatusException(RsInstrException):
"""Exception for instrument status errors. The field  errors_list contains the complete list of all the errors with messages and codes."""
	def __init__(self,rsrc_name:str,message:str,errors_list:List[Tuple[int,str]],first_exc:Exception=None):
		self.rsrc_name:str=rsrc_name
		self.first_exc:Exception=first_exc
		self.errors_list:List[Tuple[int,str]]=errors_list
		super(StatusException,self).__init__(message)
class UnexpectedResponseException(RsInstrException):
"""Exception for instrument unexpected responses."""
	def __init__(self,rsrc_name:str,message:str):
		self.rsrc_name:str=rsrc_name
		super(UnexpectedResponseException,self).__init__(message)
class ResourceError(RsInstrException):
"""Exception for resource name - e.g. resource not found."""
	def __init__(self,rsrc_name:str,message:str):
		self.rsrc_name:str=rsrc_name
		super(ResourceError,self).__init__(message)
class DriverValueError(RsInstrException):
"""Exception for different driver value settings e.g. RepCap values or Enum values."""
	def __init__(self,rsrc_name:str,message:str):
		self.rsrc_name:str=rsrc_name
		super(DriverValueError,self).__init__(message)
def get_instrument_status_errors(rsrc_name:str,errors:List[Tuple[int,str]],context:str='')->str or None:
"""Checks the errors list and of it contains at least one element, it returns the error message. Otherwise, it returns None."""
	if errors is None or len(errors)==0:
		return
	if context:
		message=f"'{rsrc_name}':{context} "
	else:
		message=f"'{rsrc_name}':"
	errors_msg='\n'.join([f'{x[0]},"{x[1]}"' for x in errors])
	if len(errors)==1:
		message+=f'Instrument error detected:{errors_msg}'
		return message
	if len(errors)>1:
		message+=f'{len(errors)} Instrument errors detected:\n{errors_msg}'
		return message
def assert_no_instrument_status_errors(rsrc_name:str,errors:List[Tuple[int,str]],context:str='',first_exc=None)->None:
"""Checks the errors list and of it contains at least one element, it throws StatusException."""
	msg=get_instrument_status_errors(rsrc_name,errors,context)
	if msg:
		raise StatusException(rsrc_name,msg,errors,first_exc=first_exc)
def throw_opc_tout_exception(opc_tout:int,used_tout:int,context:str='')->None:
"""Throws TimeoutException - use it for any timeout error."""
	if not context:
		message=''
	else:
		message=f'{context} '
	if used_tout<0 or used_tout==opc_tout:
		message=message+f"Timeout expired before the operation completed. Current OPC timeout is set to {opc_tout} milliseconds."\"Change it with the property '_driver.UtilityFunctions.opc_timeout'."\"Optionally, if the method API contains an optional timeout parameter, set it there."
	else:
		message=message+f"Timeout expired before the operation completed. Used timeout:{used_tout} ms"
	raise TimeoutException(message)
def throw_bin_block_unexp_resp_exception(rsrc_name:str,received_data:str)->None:
"""Throws InvalidDataException-use it in case an instrument response is not a binary block."""
	if received_data.endswith('\n'):
		raise UnexpectedResponseException(
			rsrc_name,"Expected binary data header starting with #(hash),received data '{}'".format(received_data.replace('\n','\\n')))
	else:
		raise UnexpectedResponseException(
			rsrc_name,f"Expected binary data header starting with #(hash),received data starting with '{received_data}'...")
def assert_query_has_qmark(query:str,context:str='')->None:
"""Throws Exception if the query does not contain any question marks."""
	if '?' in query:
		return
	message=''
	if context:
		message=context.strip()+':'
	message=message+"Query commands must contain question-marks. Sent query:'{0}'".format(query.strip('\n'))
	raise RsInstrException(message)
def assert_cmd_has_no_qmark(command:str,context:str='')->None:
"""Throws Exception if the query contains a question marks."""
	if '?' not in command:
		return
	message=''
	if context:
		message=context.strip()+':'
	message=message+"Set commands must not contain question-marks. Sent command:'{0}'".format(command.strip('\n'))
	raise RsInstrException(message)

"""InstrumentOptions.py"""
import re
from enum import Enum
from .Utilities import trim_str_response
class ParseMode(Enum):
"""Options parse mode enum."""
	Skip=0
	KeepOriginal=1
	KeepBeforeDash=2
	KeepAfterDash=3
	Auto=4
class Options(object):
"""Class for handling the instrument options-parsing from the *OPT? string and providing method get_all()"""
	_optionsList=[]
	def __init__(self,options_str:str,mode=ParseMode.Auto):
"""Initializes the options with the *OPT? return string."""
		self._initialize_from_string(options_str,mode)
	def __str__(self):
		return ','.join(self._optionsList)
	def _initialize_from_string(self,options_str:str,mode:ParseMode):
"""Fills the self._optionsList from the entered 'options_str'."""
		if mode==ParseMode.Skip:
			return
		parse_patt=r'(.?)(K|B)(\d+)(.*)$'
		options=trim_str_response(options_str).split(',')
		new_opts=[]
		for x in options:
			has_dash='-' in x
			if has_dash:
				dash_ix=x.index('-')
				before=x[0:dash_ix+1].strip('-')
				after=x[dash_ix:].strip('-')
				if mode is ParseMode.KeepBeforeDash:
					x=before
				elif mode is ParseMode.KeepAfterDash:
					x=after
				elif mode is ParseMode.Auto:
					found_before=re.match(parse_patt,before)
					found_after=re.match(parse_patt,after)
					if found_before is not None and found_after is not None:
						x=after if len(found_after.group(0)) >=len(found_before.group(0)) else before
					elif found_before is not None:
						x=before
					elif found_after is not None:
						x=after
			if len(x)>0:
				new_opts.append(x)
#Remove duplicates
		new_opts=set(new_opts)
#Create a weighting number
		result=[]
		for x in new_opts:
			sort_value=x
			m=re.match(parse_patt,x)
			if m:
				kb_weight='02' if m.group(2)=='B' else '01'
				sort_value='{0}{1}{2:09d}{3}'.format(m.group(1),kb_weight,int(m.group(3)),m.group(4))
			result.append('{0}->{1}'.format(sort_value,x))
#Sort keys in that dictionary and then reconstruct the original options
		result.sort()
		self._optionsList=[x.split('->')[1] for x in result]
	def get_all(self):
"""Returns all the options."""
		return self._optionsList

"""InstrumentSettings.py"""
from enum import Enum
from enum import Flag
from re import search
from typing import List
from . import InstrumentOptions as Opts
from . import Conversions as Conv
from .ScpiLogger import LoggingMode
from .Utilities import parse_token_to_key_and_value,trim_str_response
class InstrViClearMode(Flag):
"""Mode for executing viClear() method."""
	disabled=0x00
	ignore_error=0x01
	execute_on_all=0x02
	execute_on_socket=0x04
	execute_on_serial=0x08
	execute_on_usb=0x10
	execute_on_gpib=0x20
	execute_on_tcpvxi=0x40
class WaitForOpcMode(Enum):
"""Mode that is used for OPC-sync commands/queries."""
	stb_poll=1
	stb_poll_slow=2
	stb_poll_superslow=3
	opc_query=4
class InstrumentSettings(object):
"""Defines settings of the instrument session."""
	def __init__(self,
			viclear_exe_mode:InstrViClearMode,
			idn_model_full_name:bool,
			write_delay:int,
			read_delay:int,
			io_segment_size:int,
			opc_wait_mode:WaitForOpcMode,
			opc_timeout:int,
			visa_timeout:int,
			self_test_timeout:int,
			instr_options_parse_mode:Opts.ParseMode,
			bin_float_numbers_format:Conv.BinFloatFormat,
			bin_int_numbers_format:Conv.BinIntFormat,
			opc_query_after_write:bool,
			logging_mode:LoggingMode):
		self.viclear_exe_mode=viclear_exe_mode
		self.idn_model_full_name=idn_model_full_name
		self.write_delay=write_delay
		self.read_delay=read_delay
		self.io_segment_size=io_segment_size
		self.opc_wait_mode=opc_wait_mode
		self.opc_timeout=opc_timeout
		self.visa_timeout=visa_timeout
		self.selftest_timeout=self_test_timeout
		self.instr_options_parse_mode=instr_options_parse_mode
		self.bin_float_numbers_format=bin_float_numbers_format
		self.bin_int_numbers_format=bin_int_numbers_format
		self.opc_query_after_write=opc_query_after_write
		self.logging_mode=logging_mode
		self.logging_name=None
		self.log_to_global_target=False
		self.log_to_console=False
		self.log_to_udp=False
		self.log_udp_port=49200
		self.assure_write_with_tc=False
		self.term_char='\n'
		self.encoding='charmap'
		self.add_term_char_to_write_bin_block=False
		self.open_timeout=0
		self.exclusive_lock=False
		self.vxi_capable=True
		self.cmd_idn='*IDN?'
		self.cmd_reset='*RST'
		self.skip_status_system_setting=False
		self.skip_clear_status=False
		self.stb_in_error_check=True
		self.each_cmd_as_query=False
		self.instr_status_check=False
		self.disable_opc_query=False
		self.visa_select=None
		self._last_settings=None
#Instrument object settings
		self.instrument_status_check=None
		self.instrument_simulation_idn_string=None
#Core object settings
		self.simulating=False
		self.supported_instr_models:List[str]=[]
		self.supported_idn_patterns:List[str]=[]
	def _get_driversetup_item(self,name:str)->str:
"""Looks for a token that either has the name with prefix DRIVERSETUP_ or no prefix. Example:Keynames DRIVERSETUP_WRITEDELAY and WRITEDELAY are equivalent. If both keynames are present, the one with DRIVERSETUP_ has priority."""
		name=name.upper()
		value=self._last_settings.get(f'DRIVERSETUP_{name}')
		if value is None:
			value=self._last_settings.get(name)
		return value
	def _get_item(self,name:str)->str:
"""Returns a token value with the keyname name (case-insensitive) from the last settings dictionary. If the keyname does not exist, the method returns None."""
		value=self._last_settings.get(name.upper())
		return value
#noinspection PyMethodMayBeStatic
	def _parse_init_settings_string(self,text:str)->dict:
"""Parses init string to a dictionary of settings:name->value."""
		tokens={}
		if not text:
			return tokens
#Text enclosed in single brackets '' must have the commas escaped
		literal_pattern=r"'([^']+)'"
		while True:
#literal loop
			m=search(literal_pattern,text)
			if not m:
				break
			lit_part='"'+m.group(1).replace(',','<COMMA_ESC>')+'"'
			text=text.replace(m.group(0),lit_part)
#Remove all the class-options enclosed by round brackets e.g. "<groupName>=(<groupTokens>)"
		group_pattern=r'(\w+)\s*=\s*\(([^\)]*)\)'
#Match class-settings, add them as separate keys with groupName_Key
		while True:
#Group loop
			m=search(group_pattern,text)
			if not m:
				break
			text=text.replace(m.group(0),'')
			group_name=m.group(1).upper()
			group_tokens=m.group(2).strip().split(',')
			for token in group_tokens:
				key,value=parse_token_to_key_and_value(token)
				if value:
					tokens[f'{group_name}_{key.upper()}']=value
#All groups are removed from the text, now we can use splitting on commas and remove white-space-only elements
		for token in text.split(','):
			key,value=parse_token_to_key_and_value(token.replace('<COMMA_ESC>',','))
			if value:
				tokens[key.upper()]=value
		return tokens
	def apply_option_settings(self,text:str or None)->None:
"""Takes options from the settings dictionary and applies them to the InstrumentSettings class properties."""
		if not text:
			return
		if len(text)==0:
			return
		self._last_settings=self._parse_init_settings_string(text)

		value=self._get_item('SelectVisa')
		if value:
			self.visa_select=value
		value=self._get_driversetup_item('WriteDelay')
		if value:
			self.write_delay=Conv.str_to_int(value)
		value=self._get_driversetup_item('ReadDelay')
		if value is not None:
			self.read_delay=Conv.str_to_int(value)
		value=self._get_driversetup_item('OpcWaitMode')
		if value:
			value=value.upper()
			if value=='STBPOLLING':
				self.opc_wait_mode=WaitForOpcMode.stb_poll
			elif value=='STBPOLLINGSLOW':
				self.opc_wait_mode=WaitForOpcMode.stb_poll_slow
			elif value=='STBPOLLINGSUPERSLOW':
				self.opc_wait_mode=WaitForOpcMode.stb_poll_superslow
			elif value=='OPCQUERY':
				self.opc_wait_mode=WaitForOpcMode.opc_query
			else:
				raise ValueError(
					f"Unknown value in InitWithOptions string DriverSetup key 'WaitForOPC'. Value '{value}' is not recognized. "
					"Valid values:'StbPolling','StbPollingSlow','StbPollingSuperSlow','OpcQuery'")
		value=self._get_driversetup_item('AddTermCharToWriteBinBlock')
		if value:
			self.add_term_char_to_write_bin_block=Conv.str_to_bool(value)
		value=self._get_driversetup_item('OpenTimeout')
		if value:
			self.open_timeout=Conv.str_to_int(value)
		value=self._get_driversetup_item('ExclusiveLock')
		if value:
			self.exclusive_lock=Conv.str_to_bool(value)
		value=self._get_driversetup_item('VxiCapable')
		if value:
			self.vxi_capable=Conv.str_to_bool(value)
#Obsolete, use the AssureWriteWithTermChar
		value=self._get_driversetup_item('AssureWriteWithLf')
		if not value:
			value=self._get_driversetup_item('AssureWriteWithTermChar')
		if value:
			self.assure_write_with_tc=Conv.str_to_bool(value)
#Obsolete, use the DataChunkSize
		value=self._get_driversetup_item('IoSegmentSize')
		if not value:
			value=self._get_driversetup_item('DataChunkSize')
		if value:
			self.io_segment_size=Conv.str_to_int(value)
		value=self._get_driversetup_item('TerminationCharacter')
		if value:
			val_lc=value.lower()
			if value=='\\r' or val_lc=='cr':
				self.term_char='\r'
			elif value=='\\n' or val_lc=='lf':
				self.term_char='\n'
			elif value=='\\t' or val_lc=='tab':
				self.term_char='\t'
			elif value=='\\0' or val_lc=='null':
				self.term_char='\0'
			elif val_lc.startswith("0x") and len(val_lc) >=4:
				self.term_char=chr(int(value[2:],16))
			else:
				self.term_char=value
		value=self._get_driversetup_item('Encoding')
		if value:
			self.encoding=value
		value=self._get_driversetup_item('OpcTimeout')
		if value:
			self.opc_timeout=Conv.str_to_int(value)
		value=self._get_driversetup_item('VisaTimeout')
		if value:
			self.visa_timeout=Conv.str_to_int(value)
		value=self._get_driversetup_item('ViClearExeMode')
		if value:			enum_value=Conv.str_to_simple_scalar_enum(value,InstrViClearMode,case_sensitive=False,ignore_underscores=True)
			if enum_value is None:
				try:
					enum_value=InstrViClearMode(Conv.str_to_int(value))
				except ValueError:
					raise ValueError(
						f"Unknown value in InitWithOptions string DriverSetup key 'ViClearExeMode'. Value '{value}' is not recognized. "
						f"Valid values:ExecuteOnAll,Disabled,IgnoreError or integer bit-wise value.")
			self.viclear_exe_mode=enum_value
		value=self._get_driversetup_item('OpcQueryAfterWrite')
		if value:
			self.opc_query_after_write=Conv.str_to_bool(value)
		value=self._get_driversetup_item('StbInErrorCheck')
		if value:
			self.stb_in_error_check=Conv.str_to_bool(value)
		value=self._get_driversetup_item('EachCmdAsQuery')
		if value:
			self.each_cmd_as_query=Conv.str_to_bool(value)
		value=self._get_driversetup_item('DisableOpcQuery')
		if value:
			self.disable_opc_query=Conv.str_to_bool(value)
		value=self._get_driversetup_item('LoggingMode')
		if value:
			enum_value=Conv.str_to_simple_scalar_enum(value,LoggingMode,case_sensitive=False)
			if not enum_value:
				raise ValueError(
					f"Unknown value in InitWithOptions string 'options',key 'LoggingMode'. Value '{value}' is not recognized. "
					f"Valid values:{','.join([x.name for x in LoggingMode])}")
			self.logging_mode=enum_value
#Logging
		value=self._get_driversetup_item('LoggingName')
		if value:
			self.logging_name=value
		value=self._get_driversetup_item('LogToGlobalTarget')
		if value:
			self.log_to_global_target=Conv.str_to_bool(value)
		value=self._get_driversetup_item('LoggingToConsole')
		if value:
			self.log_to_console=Conv.str_to_bool(value)
		value=self._get_driversetup_item('LoggingToUdp')
		if value:
			self.log_to_udp=Conv.str_to_bool(value)
		value=self._get_driversetup_item('LoggingUdpPort')
		if value:
			self.log_udp_port=Conv.str_to_int(value)
#Others
		value=self._get_driversetup_item('CmdIdn')
		if value:
			self.cmd_idn=value
		value=self._get_driversetup_item('CmdReset')
		if value:
			self.cmd_reset=value
		value=self._get_driversetup_item('SkipStatusSystemSettings')
		if value:
			self.skip_status_system_setting=Conv.str_to_bool(value)
		value=self._get_driversetup_item('SkipClearStatus')
		if value:
			self.skip_clear_status=Conv.str_to_bool(value)
		value=self._get_driversetup_item('QueryOpt')
		if value:
			enum_value=Conv.str_to_simple_scalar_enum(value,Opts.ParseMode,case_sensitive=False)
			if not enum_value:
				raise ValueError(
					f"Unknown value in InitWithOptions string 'options',key 'QueryOpt'. Value '{value}' is not recognized. "
					f"Valid values:{','.join([x.name for x in Opts.ParseMode])}")
			self.instr_options_parse_mode=enum_value
#Instrument object settings
		value=self._get_driversetup_item('QueryInstrumentStatus')
		if value:
			self.instrument_status_check=Conv.str_to_bool(value)
		value=self._get_driversetup_item('SimulationIdnString')
		if value:
#Use the '*' instead of the ',' in the value to avoid comma as token delimiter
			self.instrument_simulation_idn_string=value.replace('*',',')
#Core object settings
		value=self._get_driversetup_item('Simulate')
		if value:
			self.simulating=Conv.str_to_bool(value)
		value=self._get_driversetup_item('SupportedInstrModels')
		if value:
			self.supported_instr_models=[*map(trim_str_response,value.split('/'))]
		value=self._get_driversetup_item('SupportedIdnPatterns')
		if value:
			self.supported_idn_patterns=[*map(trim_str_response,value.split('/'))]
#Profile has the ultimate priority.
		value=self._get_driversetup_item('Profile')
		if value:
			val_low=value.lower()
			if val_low=='hm8123':
				self.term_char='\r'
				self.assure_write_with_tc=True
				self.cmd_idn='IDN'
				self.cmd_reset='RST'
				self.skip_status_system_setting=True
				self.skip_clear_status=True
				self.disable_opc_query=True
				self.instrument_status_check=False
				self.stb_in_error_check=False
			elif val_low=='cmq':
				self.term_char='\r'
				self.assure_write_with_tc=True
				self.skip_status_system_setting=True
				self.skip_clear_status=True
				self.disable_opc_query=True
				self.instrument_status_check=False
				self.stb_in_error_check=False
				self.each_cmd_as_query=True
			elif val_low=='minimal':
				self.assure_write_with_tc=True
				self.skip_status_system_setting=True
				self.skip_clear_status=True
				self.disable_opc_query=True
				self.instrument_status_check=False
				self.stb_in_error_check=False
			elif val_low=='ats':
				self.term_char='\0'
				self.assure_write_with_tc=True
				self.skip_status_system_setting=True
				self.skip_clear_status=True
				self.disable_opc_query=True
				self.instrument_status_check=False
				self.stb_in_error_check=False
				self.each_cmd_as_query=True
			else:
				raise ValueError(f"Unknown value in InitWithOptions string 'options',key 'Profile',value '{value}'. Valid values (case-insensitive):HM8123,CMQ,Minimal,ATS")

"""InternalLinker.py"""
from time import time
from typing import Dict,Callable
from . import ArgSingle,ArgSingleSuppressed
from .ArgLinkedEventArgs import ArgLinkedEventArgs
from .Utilities import get_plural_string
from .InstrumentErrors import RsInstrException
class InternalLinker(object):
"""Class for:
- cutting out suppressed arguments from a device response.
- invoking a handler if the argument has InternalLinking defined.
- holds dictionary of handlers where the dict_key is the InternalLinking string.
Handlers registration/deleting is done with:
- set_handler()
- del_handler()
- del_all_handlers()"""
	def __init__(self):
		self._handlers={}
	def __str__(self):
		if len(self._handlers)==0:
			return 'Linker,no handlers'
		return f"Linker,{get_plural_string('handler',len(self._handlers))}:{','.join(self._handlers)}"
	def set_handler(self,link_name:str,handler:Callable)->Callable:
"""Adds/Updates handler for the link_name. Returns the previous registered handler, or None if no handler was registered before."""
		previous=None if link_name not in self._handlers else self._handlers[link_name]
		self._handlers[link_name]=handler
		return previous
	def del_handler(self,link_name:str)->Callable:
"""Deletes handler for the link_name. Returns the deleted handler, or None if none existed."""
		current=None if link_name not in self._handlers else self._handlers[link_name]
		if current:
			del self._handlers[link_name]
		return current
	def del_all_handlers(self)->int:
"""Deletes all the handlers.
		Returns number of deleted links."""
		count=len(self._handlers)
		self._handlers={}
		return count
	def cut_from_response_string(self,arg:ArgSingleSuppressed,response:str,context:str)->str:
"""Takes the string 'response', removes the suppressed argument value from it and returns the rest. The cut-out part is sent via handler if the internal linking exists for that argument exists."""
		result=''
		if arg.argument_ix is None:
			raise RsInstrException(f'Argument has argument_ix attribute not assigned (equals None). Argument:{arg}')
		if arg.argument_ix!=0:
			raise RsInstrException(f'Only arguments with index 0 can be suppressed. Argument:{arg}')
		if arg.is_open_list:
			raise RsInstrException(f'Open List arguments can not be suppressed. Argument:{arg}')
		repetition=0
		i=0
		for c in response:
			if c==',':
				repetition+=1
			if repetition==arg.repetition:
				break
			i+=1
		suppressed_part=response[0:i]
		i+=1
		if i<len(response):
			result=response[i:]
		self.invoke_single_intern_link(arg,context,suppressed_part)
		return result
	def invoke_single_intern_link(self,arg:ArgSingleSuppressed or ArgSingle,context:str,value:str)->None:
"""Invokes the registered handler for the internal linked argument."""
		if arg.intern_link and arg.intern_link in self._handlers:
			event_args=ArgLinkedEventArgs(arg.intern_link,arg.name,value,context,time())
			self._handlers[arg.intern_link](event_args)
	def invoke_struct_intern_links(self,struct,args:Dict,context:str)->None:
"""Invokes handler for each of the Structure arguments that have internal linking."""
		for arg in args.values():
			if arg.intern_link and arg.intern_link in self._handlers:
				event_args=ArgLinkedEventArgs(arg.intern_link,arg.name,getattr(struct,arg.name),context,time())
				self._handlers[arg.intern_link](event_args)

"""IoTransferEventArgs.py"""
import itertools
from typing import AnyStr
from .Utilities import size_to_kb_mb_string
class IoTransferEventArgs(object):
	"""Contains event data for driver read or write operations."""
#first generated is 100
	id_generator=itertools.count(100)
#noinspection PyTypeChecker
	def __init__(self,reading:bool,opc_sync:bool,total_size:int or None,context:str):
"""Initializes new instance of IoTransferEventArgs
		:param reading:True:reading operation,False:writing operation
		:param opc_sync:defines if the command is OPC-synchronised
		:param total_size:total size of the data received
		:param context:SCPI query. It is truncated to maximum of 100 characters."""
		self._transfer_id=next(self.id_generator)
		self.end_of_transfer=False
		self.reading=reading
		self.opc_sync=opc_sync
		self.total_size=total_size
		self.transferred_size:int=0
		self.context:str=(context[:100]+'..') if len(context)>100 else context
#Data to set after the object has been created.
		self.chunk_size:int=None
"""Size of one chunk of data. This number does not change during the transfer."""
		self.chunk_ix:int=None
"""0-based index of the chunk."""
		self.total_chunks:int=None
"""Expected number of chunks."""
		self.resource_name:str=None
"""Visa Resource Name of the instrument that generated the data."""
		self.binary:bool=None
"""True:Binary data, False:string data"""
		self.data:AnyStr=None
"""If the feature of transferring data over R/W event is switched ON, this field contains the whole data."""
	@classmethod
	def read_chunk(cls,opc_sync:bool,context:str)->'IoTransferEventArgs':
"""Creates new IoTransferEventArgs of read string \n
:param opc_sync:defines if the command is OPC-synchronised
:param context:SCPI query. It is truncated to maximum of 100 characters.
:return:IoTransferEventArgs object of a read string operation."""
		return cls(True,opc_sync,None,context)
	@classmethod
	def write_str(cls,opc_sync:bool,total_size:int,context:str)->'IoTransferEventArgs':
"""Creates new IoTransferEventArgs of write string \n
:param opc_sync:defines if the command is OPC-synchronised
:param total_size:size of the data to write
:param context:SCPI command write. It is truncated to maximum of 100 characters
:return:IoTransferEventArgs object of a write-string operation."""
		obj=cls(False,opc_sync,total_size,context)
		obj.binary=False
		return obj
	@classmethod
	def write_bin(cls,context:str)->'IoTransferEventArgs':
"""Creates new IoTransferEventArgs of read binary data \n
:param context:SCPI command. It is truncated to maximum of 100 characters.
:return:IoTransferEventArgs object of a write-binary-data operation."""
#noinspection PyTypeChecker
		obj=cls(False,False,None,context.rstrip())
		obj.binary=True
		return obj
	def __str__(self):
		if self.binary:
			type_info='binary'
		else:
			type_info='ascii'
		if self.opc_sync:
			type_info+=' (opc-synced)'
		if not self.total_chunks:
			chunk_info=f' chunk nr. {self.chunk_ix+1}'
		elif self.total_chunks>1:
			chunk_info=f' chunk nr. {self.chunk_ix+1}/{self.total_chunks}'
		else:
			chunk_info=' chunk nr. 1/1'
		eot=' (EOT)' if self.end_of_transfer else ''
		if self.reading:
			result=f'IoTransferArgs ID {self._transfer_id}:reading {type_info},{chunk_info} {size_to_kb_mb_string(self.chunk_size,True)},' \
					f'sum {size_to_kb_mb_string(self.transferred_size,True)}/{size_to_kb_mb_string(self.total_size,True) if self.total_size else "<N.A.>"}{eot}.'
		else:
			result=f'IoTransferArgs ID {self._transfer_id}:writing {type_info},{chunk_info} {size_to_kb_mb_string(self.chunk_size,True)},' \
						f'sum {size_to_kb_mb_string(self.transferred_size,True)}/{size_to_kb_mb_string(self.total_size,True)}{eot}.'
		if self.context:
			result+=f' Cmd:{self.context}'
		return result
	@property
	def transfer_id(self)->int:
"""Unique number for each transfer for this Instrument. If the transfer is performed in more chunks, the transfer_id stays the same during the whole transfer."""
		return self._transfer_id
	def set_end_of_transfer(self):
"""Sets fields to signal end of transfer."""
		self.transferred_size=self.total_size
		self.end_of_transfer=True

"""RepeatedCapability.py"""
from enum import Enum
#Command integer value that signals Default value "DEFAULT"
VALUE_DEFAULT=-1
#Command integer value that signals "EMPTY"
VALUE_EMPTY=-2
class RepeatedCapability(object):
"""Represents Repeated Capability value and type"""
	def __init__(self,header_name:str,method_get_name:str,method_set_name:str,start_value:Enum):
"""Constructor with header name, group property name and the start value"""
		self._enum_value=None
		self.enum_type=start_value.__class__
		self.name=self.enum_type.__name__
		self.header_name=header_name
		self.method_get_name=method_get_name
		self.method_set_name=method_set_name
		self._start_value=start_value
		self.set_to_start_value()
	def __str__(self)->str:
		out=f'RepCap {self.name}'
		if self._enum_value is not None:
			out+=f"={self._enum_value}"
		return out
	@classmethod
	def clsm_assert_type(cls,enum_value:Enum or int,enum_type)->None:
"""Static assertion function to check if the entered value is a member of the defined repcap enum. In addition, the integer value is also supported."""
		if isinstance(enum_value,int):
			return
		if not isinstance(enum_value,enum_type):
			raise TypeError(f"RepCap value must be of type '{enum_type}'. Entered value type:{type(enum_value)},value '{enum_value}'")
	@classmethod
	def clsm_get_direct_cmd_value_int(cls,enum_value:Enum or int,enum_type)->int:
"""Static function to get an integer interpretation of a direct enum value. Does not work with Empty or Default"""
		RepeatedCapability.clsm_assert_type(enum_value,enum_type)
		if isinstance(enum_value,int):
			return enum_value
		return enum_value.value
	@classmethod
	def clsm_is_default_value(cls,enum_value:Enum or int,enum_type)->bool:
"""Returns True, if the entered value is enum.Default"""
		return cls.clsm_get_direct_cmd_value_int(enum_value,enum_type)==VALUE_DEFAULT
	def is_default_value(self)->bool:
"""Returns True, if the repcap value is enum.Default"""
		return RepeatedCapability.clsm_is_default_value(self._enum_value,self.enum_type)
	def set_enum_value(self,enum_value:Enum or int)->None:
"""Sets new enum value. Can not be Default"""
		if RepeatedCapability.clsm_is_default_value(enum_value,self.enum_type):
			raise ValueError(f"Setting RepCap enum value '{enum_value}' is not allowed. Please select a concrete value")
		if isinstance(enum_value,int):
#Find the enum value that corresponds to the entered integer value
			enum_value=self.enum_type(enum_value)
		self._enum_value=enum_value
	def get_enum_value(self)->Enum:
"""Returns the actual enum value"""
		return self._enum_value
	def set_to_start_value(self)->None:
"""Sets back to the value entered in the constructor"""
		self.set_enum_value(self._start_value)
	def matches_type(self,enum_type)->bool:
"""Returns true, if the entered type matches the EnumType"""
		return self.enum_type==enum_type
	@classmethod
	def clsm_get_cmd_string_value(cls,enum_value:Enum or int,enum_type)->str:
"""Class method version of the get_cmd_string_value().
Converts RepCap integer value to string
ValueEmpty is converted to "" (Not valid, but tolerated)
ValueDefault throws an exception
0 is converted to "" (Not valid, but tolerated)
Positive numbers are converted to integer strings e.g. 1=>'1' """
		number=cls.clsm_get_direct_cmd_value_int(enum_value,enum_type)
		if number==VALUE_EMPTY:
			return ''
		if number==0:
#return empty string, if the enum definition does not contain a valid element with value 0
			enum_values=[x.value for x in enum_type]
			return '0' if 0 in enum_values else ''
		if number==VALUE_DEFAULT:
			raise ValueError(f"RepCap enum value Default can not be converted to the command string value. RepCap:{enum_type}")
		return str(number)
	def get_cmd_string_value(self)->str:
"""Converts RepCap integer value to string
ValueEmpty is converted to "" (Not valid, but tolerated)
ValueDefault throws an exception
0 is converted to "" (Not valid, but tolerated)
Positive numbers are converted to integer strings e.g. 1=>'1' """
		return RepeatedCapability.clsm_get_cmd_string_value(self._enum_value,self.enum_type)

"""ScpiEnums.p"""
from enum import Enum
from typing import List
enum_spec_prefixes={'_minus':'-','_plus':'+','_':''}
enum_spec_strings={'_dash_':'-','_dot_':'.','_cma_':','}
class ScpiEnum:
"""Provides methods for enum members search including the ones with custom SCPI strings."""
    def __init__(self,enum_type):
        self.enum_type=enum_type
        self._members_raw=[x.name for x in self.enum_type]
        self.has_custom_values=any(isinstance(x.value,str) for x in self.enum_type)
        self.has_quotes=False
        self._custom_values=None
        self._members_special=None
        if self.has_custom_values:
            self.members=[]
            self._custom_values={}
            for x in self.enum_type:
                item=x.value if isinstance(x.value,str) else x.name
                if self.has_quotes is False:
                    self.has_quotes="'" in item
                self.members.append(item)
                self._custom_values[x.name]=item
        else:
            self.members=self._members_raw
    def get_scpi_value(self,enum_value:str)->str:
"""Returns the SCPI value of the enum item:name for the integer value and value for the string value."""
        if not self.has_custom_values:
            return enum_value
        return self._custom_values[enum_value]
    def find_in_enum_members(self,item:str,force_comma_remove:bool)->Enum or None:
"""Returns either an EnumMember item or null if not found. The matching is done against the Members, and if unsuccessful, then against the _members_special. The response is always a _members_raw item."""
        ix=self._find_ix_in_enum_members(item,force_comma_remove,self.members)
        if ix >=0:
            return self.enum_type[self._members_raw[ix]]
        self._init_special_values()
        ix=self._find_ix_in_enum_members(item,force_comma_remove,self._members_special)
        if ix >=0:
            return self.enum_type[self._members_raw[ix]]
        return None
    @staticmethod
    def _find_ix_in_enum_members(item:str,force_comma_remove:bool,enum_members:List[str])->int:
"""Matches an item in the provided list of enum_member strings.
The item must be not fully matched.
The item is matched if a member string starts with the item (the item is a prefix of the member).
Example:item='CONN' matches the enum_member 'CONNected'.
If the item contains a comma, the function checks if there is a comma defined in the enum_members.
- If no, the comma and all after it is removed.
- If yes, the comma is kept.
You can override the behaviour by forcing the removal of the comma
Returns found index in the enum_members list."""
        if ',' in item:
            trim_comma=True
            if force_comma_remove is False:
                for x in enum_members:
                    if '_cma_' in x or ',' in x:
                        trim_comma=False
                        break
            if trim_comma:
                item=item[:item.index(',')].strip()
        i=0
        for x in enum_members:
            if x.startswith(item):
                return i
            i+=1
#smart matching:
#item='MAX' matches enum_member 'MAXpeak'
#item='SPECtrum1' matches enum_member 'SPEC1'
#item='SPEC' matches enum_member 'SPECtrum1'
        item=''.join([c for c in item if not c.islower()])
#item must be longer than 1 character
        if len(item)<2:
            return -1
        i=0
        for x in enum_members:
            x_uc=''.join([c for c in x if not c.islower()])
            if x_uc==item:
                return i
            i+=1
        return -1
    def _init_special_values(self):
"""Convert the members to the SCPI values-values to be sent to the instrument   Resolves escapes:
        '^_'=>''
        '^_minus'=>'-'
        '_dash_'=>'-'
        '_dot_'=>'.'
        '_cma_'=>','
This is a lazy init of the self._members_special property, since most of the enums do not have any special values."""
        if self._members_special is not None:
            return
        self._members_special=[]
        for i in range(len(self.members)):
            mem=self.members[i]
            for key in enum_spec_prefixes:
                if mem.startswith(key):
                    mem=enum_spec_prefixes[key]+mem[len(key):]
            for key in enum_spec_strings:
                mem=mem.replace(key,enum_spec_strings[key])
            self._members_special.append(mem)

"""StreamReader.py"""
from enum import Enum
from os import path
from typing import AnyStr
from .Utilities import size_to_kb_mb_string
from .InstrumentErrors import RsInstrException
class Type(Enum):
"""Defines type of the stream-variable or file."""
	Variable=1
	File=2
class StreamReader:
"""Lightweight stream reader implementation. Data source can be:\n
- variable
- file"""
	def __init__(self,binary:bool,source:Type,data:AnyStr):
"""Initializes StreamReader instance.\n
:param binary:True:Binary data, False:ASCII data
:param source:Source type for the stream. Variable/File
:param data:Depending on the 'binary' and 'source':
For source type Variable the data must be either bytes() or str
For source type File data must be string with existing file path."""
		self._source=source
		self._binary=binary
		self._start_ptr=0
		self._read_len=0
		if self._source==Type.Variable:
			if self._binary:
				assert isinstance(data,bytes),f'Data must be of bytes type. Actual type:{type(data)}'
			else:
				assert isinstance(data,str),f'Data must be of string type. Actual type:{type(data)}'
			self._data=data
			self._full_len=len(self._data)
		elif self._source==Type.File:
			assert isinstance(data,str),f'Data must be of string type (file path). Actual type:{type(data)}'
			if not path.isfile(data):
				raise RsInstrException(f'File does not exist. File path:{data}')
			self.file_path=data
			self._data=open(self.file_path,'rb' if self._binary else 'r')
			self._full_len=path.getsize(self.file_path)
		else:
			raise RsInstrException(f'StreamReader unknown type {source}')
	@classmethod
	def as_bin_var(cls,data:bytes)->'StreamReader':
"""Creates new StreamReader from bytes. :param data:[bytes] data for the stream."""
		return cls(True,Type.Variable,data)
	@classmethod
	def as_string_var(cls,data:str)->'StreamReader':
"""Creates new StreamReader from string. :param data:[str] data for the stream."""
		return cls(False,Type.Variable,data)
	@classmethod
	def as_bin_file(cls,file_path:str)->'StreamReader':
"""Creates new StreamReader from binary file. The file must exist at this time. :param file_path:[str] Path to the file."""
		return cls(True,Type.File,file_path)
	@classmethod
	def as_text_file(cls,file_path:str)->'StreamReader':
"""Creates new StreamReader from text file. The file must exist at this time.
:param file_path:[str] Path to the file."""
		return cls(False,Type.File,file_path)
	def __str__(self):
		if self._source==Type.Variable:
			mode='binary' if self._binary else 'string'
			return f'StreamReader {mode} data,full size {size_to_kb_mb_string(self._full_len,True)},remaining size {size_to_kb_mb_string(len(self),True)}'
		if self._source==Type.File:
			mode='binary' if self._binary else 'text'
			return f'StreamReader {mode},full size {size_to_kb_mb_string(self._full_len,True)},remaining size {size_to_kb_mb_string(len(self),True)}'
	def __len__(self):
		"""Returns remaining length."""
		return self._full_len-self._start_ptr
	def __enter__(self):
		return self
	def __exit__(self,exception_type,exception_value,traceback):
		self.close()
	@property
	def full_len(self)->int:
"""Returns original full length."""
		return self._full_len
	@property
	def binary(self)->bool:
"""Returns true, if the data provided is binary."""
		return self._binary
	def read(self,chunk_size:int=None)->AnyStr:
"""Read chunk from the data and moves the data pointer behind it. If the remaining length is smaller than the chunk_size, the method returns the remaining length only. :param chunk_size:chunk to read. If not set, the method reads the entire data."""
		assert self._data is not None,'StreamReader buffer is invalid. You have probably closed it already.'
		chunk_size=len(self) if chunk_size is None else chunk_size
		chunk_size=min(chunk_size,len(self))
		if chunk_size<0:
			raise ValueError(f'Chunk size can not be negative number:{chunk_size}')
		self._read_len+=chunk_size
		if self._source==Type.Variable:
			self._start_ptr+=chunk_size
			return self._data[self._start_ptr-chunk_size:self._start_ptr]
		elif self._source==Type.File:
			self._start_ptr+=chunk_size
			return self._data.read(chunk_size)
	@property
	def read_len(self)->int:
"""Returns number of bytes read from the stream since its creation."""
		return self._read_len
	def read_as_binary(self,encoding:str,chunk_size:int=None)->bytes:
"""Same as read(), but always returns the data in binary format. Practically works exactly as read() for binary streams. For string streams, the method converts the returned data using the provided encoding to bytes()."""
		if self._binary:
			return self.read(chunk_size)
		else:
			return self.read(chunk_size).encode(encoding)
	def close(self):
"""Closes the StreamReader. You can not use its instance afterwards."""
		if self._source==Type.File and self._data:
			self._data.close()
		self._data=None

"""StreamWriter.py"""
from enum import Flag
from typing import AnyStr
from io import BytesIO,StringIO
from .Utilities import size_to_kb_mb_string
from .InstrumentErrors import RsInstrException
class Type(Flag):
"""Defines type of the stream-variable or file."""
Variable=1
Forget=2
File=4
FileAppend=12
class StreamWriter:
"""Lightweight stream writer implementation. Data target can be:\n
- bytes
- string
- file"""
def __init__(self,binary:bool,target:Type,meta_data=None):
"""Initializes StreamWriter instance.\n
:param binary:True:Binary data, False:ASCII data
:param target:Target for the stream. Variable/File (FileAppend)
:param meta_data:Only valid for File and FileAppend-define file path as string:
For Type.File, data must be string with file path. If the file exists, it will be overwritten.
For Type.FileAppend, data must be string with file path. If the file exists, it will be appended."""
		self._binary:bool=binary
		self._written_len:int=0
		self._target=target
		if Type.Variable in self._target:
			assert meta_data is None,f'You can not define input meta_data for a Variable StreamWriter.'
			self._data=BytesIO() if binary else StringIO()
		elif Type.Forget in self._target:
			self._data:AnyStr=''
		elif Type.File in self._target:
			assert isinstance(meta_data,str),f'Additional data must be of string type (file path). Actual type:{type(meta_data)}'
			self._file_path=meta_data
			mode='w' if self._target==Type.File else 'a'
			mode+='b' if self._binary else ''
			self._data=open(self._file_path,mode)
		else:
			raise RsInstrException(f'StreamWriter unknown target {target}')
	@classmethod
	def as_bin_var(cls)->'StreamWriter':
"""Creates new StreamWriter with bytes variable."""
		return cls(True,Type.Variable)
	@classmethod
	def as_string_var(cls)->'StreamWriter':
"""Creates new StreamWriter with string variable."""
		return cls(False,Type.Variable)
	@classmethod
	def as_forget(cls)->'StreamWriter':
"""Creates new StreamWriter which writes to nowhere-forgets the data."""
		return cls(False,Type.Forget)
	@classmethod
	def as_bin_file(cls,file_path:str,append:bool=False)->'StreamWriter':
"""Creates new StreamWriter to binary file.
:param file_path:[str] Path to the file.
:param append:Optional [bool] If True, the content is appended to the existing content."""
		return cls(True,Type.FileAppend if append else Type.File,file_path)
	@classmethod
	def as_text_file(cls,file_path:str,append:bool=False)->'StreamWriter':
"""Creates new StreamWriter to text file.
:param file_path:[str] Path to the file.
:param append:Optional [bool] If True, the content is appended to the existing content."""
	return cls(False,Type.FileAppend if append else Type.File,file_path)
	def __str__(self):
		if Type.Variable in self._target:
			mode='binary' if self._binary else 'string'
			return f'StreamWriter {mode} variable,current size {size_to_kb_mb_string(len(self),True)}'
		if Type.File in self._target:
			mode='binary' if self._binary else 'text'
			append=' appended' if Type.FileAppend in self._target else ''
			return f'StreamWriter {mode} file{append},current{append} size {size_to_kb_mb_string(len(self),True)},file:{self._file_path}'
		if Type.Forget in self._target:
			return 'StreamWriter to nowhere.'
	def __len__(self):
		"""Returns remaining length."""
		return self._written_len
	def __enter__(self):
		return self
	def __exit__(self,exception_type,exception_value,traceback):
		self.close()
	@property
	def binary(self)->bool:
"""Returns true, if the data held is binary. File streams are always binary."""
		return self._binary
	def write(self,data:AnyStr)->None:
"""Writes chunk to the stream.
- For Type.Bytes data must be bytes.
- For Type.String, data must be string.
- For Type.File and Type.FileAppend, data must be bytes."""
		if Type.Forget in self._target:
			self._written_len+=len(data)
			return
		assert self._data is not None,'StreamWriter buffer is invalid. You have probably closed it already.'
		if self._binary:
			assert isinstance(data,bytes),f'Bytes data is required. Actual type:{type(data)}. {self}'
		else:
			assert isinstance(data,str),f'String data is required. Actual type:{type(data)}. {self}'
		if Type.Variable in self._target:
			self._data.write(data)
		elif Type.File in self._target:
			self._data.write(data)
		self._written_len+=len(data)
	def switch_to_string_data(self,encoding:str)->None:
"""Switches from binary to string data.
For variables, the current content is converted to string using the provided encoding.
For files, they are closed and reopened as for appended text writing."""
		if self._binary is False:
			return
		self._binary=False
		if Type.Variable in self._target:
			self._data=StringIO(self.content.decode(encoding))
		elif Type.File in self._target:
			self._data.close()
			self._data=open(self._file_path,'a')
#noinspection PyTypeChecker
	@property
	def content(self)->AnyStr:
"""Returns content of the writer. Only works with variable types."""
		if self._target==Type.Forget:
			return ''
		if self._target!=Type.Variable:
			raise RsInstrException(f'Can not return content for the current {self}')
#noinspection PyTypeChecker
		if not self._data:
			return None
		self._data.seek(0)
		ret_val=self._data.read()
		self._data.close()
		return ret_val
	@property
	def written_len(self)->int:
"""Returns number of bytes written to the stream since its creation."""
		return self._written_len
	def close(self)->None:
"""Closes the StreamWriter. You can not use its instance afterwards."""
		if Type.File in self._target and self._data:
			self._data.close()
		self._data=None

"""StructBase.py"""
from .Types import DataType
class StructBase:
"""Base class for all the driver's argument structures."""
	def __init__(self,owner):
		self.__meta_args_link=dict()
		ix=0
		for arg in self.__get_meta_args_list(owner):
			arg.argument_ix=ix
			ix+=1
			if arg.data_type in [DataType.Enum,DataType.EnumExt,DataType.EnumList,DataType.EnumExtList]:
				assert arg.enum_type, f"Struct Argument '{arg.name}' is of enum type, you must define the parameter 'enum_type'"
			else:
				assert not arg.enum_type,f"Struct Argument '{arg.name}' data type is '{arg.data_type.name}'. You must set the parameter 'enum_type' to None"
			if arg.is_optional:
#set all optional values to None
				setattr(self,arg.name,None)
			else:
#set all mandatory values to their default values
				default=arg.data_type.get_default_value(arg.enum_type)
				setattr(self,arg.name,default)
#noinspection PyMethodMayBeStatic
	def __get_meta_args_list(self,owner):
		args_list=getattr(owner,f'_{owner.__class__.__name__}__meta_args_list')
		return args_list

"""Types.py"""
from enum import Enum,auto
from typing import Any
#noinspection PyArgumentList
class DataType(Enum):
"""Data type of variable in the driver."""
	String=auto()
	RawString=auto()
	Integer=auto()
	IntegerExt=auto()
	Boolean=auto()
	Float=auto()
	FloatExt=auto()
	Enum=auto()
	EnumExt=auto()
	StringList=auto()
	RawStringList=auto()
	IntegerList=auto()
	IntegerExtList=auto()
	BooleanList=auto()
	FloatList=auto()
	FloatExtList=auto()
	EnumList=auto()
	EnumExtList=auto()
	@property
	def is_list(self)->bool:
"""Returns True, if the data type is a list."""
		return self in frozenset(
			{DataType.StringList,
				DataType.RawStringList,
				DataType.IntegerList,
				DataType.IntegerExtList,
				DataType.BooleanList,
				DataType.FloatList,
				DataType.FloatExtList,
				DataType.EnumList,
				DataType.EnumExtList})
	@property
	def is_scalar(self)->bool:
"""Returns True, if the data type is a scalar."""
		return not self.is_list
	@property
	def is_scalar_enum(self)->bool:
"""Returns True, if the data type is a scalar enum or enum_ext."""
		return self==DataType.Enum or self==DataType.EnumExt
	@property
	def is_list_enum(self)->bool:
"""Returns True, if the data type is a list enum or list enum_ext."""
		return self==DataType.EnumList or self==DataType.EnumExtList
	@property
	def is_enum(self)->bool:
"""Returns True, if the data type is enum or enum array-including the extended."""
		return self in [DataType.Enum,DataType.EnumExt,DataType.EnumList,DataType.EnumExtList]
	@property
	def is_raw_string(self)->bool:
"""Returns True for raw string and raw string list."""
		return self==DataType.RawString or self==DataType.RawStringList
	@property
	def is_boolean(self)->bool:
"""Returns True for boolean and boolean list."""
		return self==DataType.Boolean or self==DataType.BooleanList
	@property
	def is_string(self)->bool:
"""Returns True for string and string list."""
		return self==DataType.String or self==DataType.StringList
	@property
	def element_type(self):
"""For lists, the property returns type of the element. For scalars, it returns the same type."""
		if self.is_scalar:
			return self
		elif self==DataType.StringList:
			return DataType.String
		elif self==DataType.RawStringList:
			return DataType.RawString
		elif self==DataType.RawStringList:
			return DataType.RawString
		elif self==DataType.BooleanList:
			return DataType.Boolean
		elif self==DataType.IntegerList:
			return DataType.Integer
		elif self==DataType.IntegerExtList:
			return DataType.IntegerExt
		elif self==DataType.FloatList:
			return DataType.Float
		elif self==DataType.FloatExtList:
			return DataType.FloatExt
		elif self==DataType.EnumList:
			return DataType.Enum
		elif self==DataType.EnumExtList:
			return DataType.EnumExt
	def get_default_value(self,enm:Enum=None)->Any:
"""Returns default value for the current type. If the data type is Enum or EnumString, you have to provide the enum class."""
		if self.is_list:
			return []
		if self==DataType.RawString:
			return ''
		elif self==DataType.String:
			return ''
		elif self==DataType.Boolean:
			return False
		elif self==DataType.Integer:
			return 0
		elif self==DataType.IntegerExt:
			return 0
		elif self==DataType.Float:
			return 0.0
		elif self==DataType.FloatExt:
			return 0.0
		elif self==DataType.Enum:
			return enm(0)
		elif self==DataType.EnumExt:
			return enm(0)

"""Utilities.py"""
from enum import Flag
from typing import Tuple
class TrimStringMode(Flag):
"""Trimming mode for strings."""
	white_chars_only=1
	white_chars_single_quotes=2
	white_chars_double_quotes=3
	white_chars_all_quotes=4
def trim_str_response(text:str,mode=TrimStringMode.white_chars_all_quotes)->str:
"""Trims instrument string response.
In modes white_chars_all_quotes, white_chars_single_quotes, white_chars_double_quotes:
All the symmetrical leading and trailing quotation marks are trimmed,
but only if there are none in the remaining text."""
first_sq_ix=-1
first_dq_ix=-1
rem_sq=True if (mode==TrimStringMode.white_chars_all_quotes or mode==TrimStringMode.white_chars_single_quotes) else False
	rem_dq=True if (mode==TrimStringMode.white_chars_all_quotes or mode==TrimStringMode.white_chars_double_quotes) else False
	if not text:
		return text
	text=text.strip()
	if rem_sq and text=="''":
		return ''
	if rem_dq and text=='""':
		return ''
	start_ix=0
	end_ix:int=len(text)-1
	if end_ix-2<start_ix:
		return text
	if mode is not TrimStringMode.white_chars_only:
#Loop to cut the outer paired quotation marks
		trimmed=True
		while trimmed:
			trimmed=False
			if rem_sq and text[start_ix]=="'" and text[end_ix]=="'":
				if first_sq_ix<0:
					first_sq_ix=start_ix
				start_ix+=1
				end_ix -=1
				trimmed=True
			if end_ix-2<start_ix:
				break
			if rem_dq and text[start_ix]=='"' and text[end_ix]=='"':
				if first_dq_ix<0:
					first_dq_ix=start_ix
				start_ix+=1
				end_ix -=1
				trimmed=True
			if end_ix-2<start_ix:
				break
		if start_ix==0:
			return text
		final_cut_ix=start_ix
		shortened_text=text[start_ix:-start_ix]
		if first_sq_ix >=0 and "'" in shortened_text:
#The cut quotes are also in the shortened string, do not removed the quotes, and set the cutting to start_ix
			final_cut_ix=first_sq_ix
		if first_dq_ix >=0 and '"' in shortened_text:
			if final_cut_ix>first_dq_ix:
				final_cut_ix=first_dq_ix
		if final_cut_ix==0:
			return text
		text=text[final_cut_ix:-final_cut_ix]
	return text
def truncate_string_from_end(string:str,max_len:int)->str:
"""If the string len is below the max_len, the function returns the same string. If the string is above the max len, the function returns only the last max_len characters plus '...' at the beginning."""
	if len(string) <=max_len:
		return string
	return f'Last {max_len} chars:"...{string[-max_len:]}"'
def get_plural_string(word:str,amount:int)->str:
"""Returns singular or plural of the word depending on the amount. Example:
word='piece',amount=0->'0 pieces'
word='piece',amount=1->'1 piece'
word='piece',amount=5->'5 pieces'"""
	if amount==1:
		return f'1 {word}'
	else:
		return f'{amount} {word}s'
def parse_token_to_key_and_value(token:str)->Tuple[str,str]:
"""Parses entered string to name and value with the delimiter '='.
If the token is empty:name=None, value=None.
If the '=' is not found:name=token, value=None.
name is trimmed for white spaces.
value is trimmed with trim_str_response()."""
	token=token.strip()
	if not token:
#noinspection PyTypeChecker
		return None,None
	if '=' in token:
		data=token.split('=')
		name=data[0].strip()
		value=trim_str_response(data[1])
		return name,value
#noinspection PyTypeChecker
	return token.strip(),None
def size_to_kb_mb_string(data_size:int,as_additional_info:bool=False)->str:
"""Returns human-readable string with kilobytes or megabytes depending on the data_size range. \n
:param data_size:data size in bytes to convert
:param as_additional_info:
if True, the dynamic data appear in round bracket after the number in bytes. e.g. '12345678 bytes (11.7 MB)'
if False, only the dynamic data is returned e.g. '11.7 MB' """
	if data_size<1024:
		as_additional_info=False
		dynamic=f'{data_size} bytes'
	elif data_size<1048576:
		dynamic=f'{data_size/1024:0.1f} kB'
	else:
		dynamic=f'{data_size/1048576:0.1f} MB'
	if as_additional_info:
		return f'{data_size} bytes ({dynamic})'
	else:
		return dynamic
def calculate_chunks_count(data_size:int,chunk_size:int)->int:
"""Returns number of chunks needed to transfer the data_size split to maximum of chunk_size blocks. \n
:param data_size:total data size
:param chunk_size:maximum size of one block"""
	return (data_size // chunk_size)+(1 if (data_size % chunk_size)>0 else 0)
def escape_nonprintable_chars(string:str,encoding:str='charmap')->str:
"""Replace nonprintable characters in string s by its hex representation."""
	if string.isprintable():
		return string
	new_string=''
	for char in string:
		if char.isprintable():
			new_string+=char
		elif char=='\n':
			new_string+=r'\n'
		elif char=='\r':
			new_string+=r'\r'
		elif char=='\t':
			new_string+=r'\t'
		else:
			byte=bytes(char,encoding)
			char=byte.hex()
			new_string+=r'\x'+char
	return new_string
def shorten_string_middle(string:str,max_len:int)->str:
"""If the length of the string is bigger than the max_len, the middle of the string is abbreviated with ' .... ' """
	count=len(string)
	if count <=max_len:
		return string
	half=int((max_len-6)/2)
	md=(max_len-6) % 2
	return string[:half+md]+' .... '+string[(count-half):]

"""VisaPluginSocketIo.py"""
import socket
import re
from contextlib import contextmanager
from typing import Any
from .InstrumentErrors import RsInstrException
#noinspection PyPackageRequirements
import pyvisa
class SocketIo:
"""Socket IO plugin providing implementations for all the necessary VISA functions. This class does not need the underlying VISA installation."""
	def __init__(self,resource_name:str):
		self.session=socket.socket()
		self.resource_name=resource_name
		m=re.search(r'TCPIP::([^:]+)::([^:]+)::SOCKET',self.resource_name)
		if not m:
			raise RsInstrException(f"SocketIO instrument unsupported resource name. '{self.resource_name}' Supported resource name example:'TCPIP::192.168.1.100::5025::SOCKET'")
		self.host=m.group(1).strip()
		self.port=int(m.group(2).strip())
		self._read_termination=None
		self._chunk_size=1024
		self._timeout=5000
		self.visalib=VisaLib(self)
	def connect(self):
"""Connects to the server (IP address and port number)"""
		self.session.connect((self.host,self.port))
#noinspection PyUnresolvedReferences
	@property
	def interface_type(self)->int:
		"""Returns interface type as integer number (6)"""
		return pyvisa.constants.VI_INTF_TCPIP
	@property
	def resource_class(self)->str:
"""Returns resource class as string"""
		return 'SOCKET'
	@property
	def read_termination(self)->str:
"""Read termination character"""
		return self._read_termination
	@read_termination.setter
	def read_termination(self,value:str or bool)->None:
"""Read termination character. You can set it to False, or a string value"""
		if isinstance(value,bool):
			if value is True:
				raise ValueError("SocketIO read_termination can not be set to True. You have to provide a string value")
			self._read_termination=None
			return
		if isinstance(value,str):
			self._read_termination=value
			return
		raise ValueError(f"SocketIO read_termination invalid type:'{value}'")
	@property
	def chunk_size(self)->int:
"""Transfer chunk size"""
		return self._chunk_size
	@chunk_size.setter
	def chunk_size(self,chunk_size:int)->None:
"""Transfer chunk size"""
		self._chunk_size=chunk_size
	@property
	def timeout(self)->int:
"""Read and Write timeout"""
		return self._timeout
	@timeout.setter
	def timeout(self,timeout:int)->None:
"""Read and Write timeout"""
		self._timeout=timeout
		tout_float=float(self._timeout/1000)
		self.session.settimeout(tout_float)
	def clear(self)->None:
"""Clear the buffers."""
		return
	def write(self,cmd:str)->None:
"""Writes command as string to the instrument"""
		self.session.send(cmd.encode())
	def write_raw(self,cmd:bytes)->None:
"""Writes command as bytes to the instrument"""
		self.session.send(cmd)
#noinspection PyUnusedLocal
	def read_bytes(self,count:int,**kwargs)->bytes:
"""Reads count bytes."""
		data,status=self.visalib.read(self.session,count)
		return data
	def go_to_local(self)->None:
"""Puts the instrument into local state."""
		self.write("&GTL")
	def go_to_remote(self)->None:
"""Puts the instrument into remote state."""
		self.write("&GTR")
#noinspection PyUnusedLocal
	@contextmanager
	def ignore_warning(self,filter_value:int)->None:
"""Context property with no effect for the socket connection"""
		try:
			yield None
		finally:
#Code to release resource,e.g.:
			pass
	def close(self)->None:
"""Closes the socket connection"""
		self.session.close()
class VisaLib:
	"""Implementation of the pyvisa's VisaLib providing the method read()"""
	def __init__(self,socket_io:SocketIo):
		self._socket_io=socket_io
	def __str__(self):
		return "SocketIO"
#noinspection PyUnresolvedReferences
	def read(self,session,chunk_size:int):
"""Reads bytes from the instrument to the maximum size of chunk_size. Returns Tuple of bytes and status."""
		term_char_detected=False
		read_len=0
		chunk=bytes()
		try:
			while True:
				to_read_len=chunk_size-read_len
				if to_read_len <=0:
					break
				data=session.recv(to_read_len)
				chunk+=data
				read_len+=len(data)
				if self._socket_io.read_termination is not None:
#Read termination character is ON, look for it and stop the reading if found
					term_char=self._socket_io.read_termination.encode()
					if term_char in data:
						term_char_ix=data.index(term_char)
						read_len=term_char_ix+1
						term_char_detected=True
						break
					else:
						pass
		except socket.timeout:
			raise pyvisa.VisaIOError(pyvisa.constants.VI_ERROR_TMO)
		if read_len<chunk_size:
#Less than required data arrived, no more available
			more_data_available=False
		else:
#MaxCount data arrived, possibly more data available
			if self._socket_io.read_termination is not None:
				more_data_available=not term_char_detected
			else:
				more_data_available=True
		return_code=pyvisa.constants.StatusCode.success_max_count_read if more_data_available else pyvisa.constants.StatusCode.success
		return chunk,return_code
class ResourceManager:
"""Implementation of the VISA's Resource Manager."""
	def __init__(self):
		self.VisaManufacturerName="SocketIO"
		self.connection=None
#noinspection PyUnusedLocal
	def open_resource(self,resource_name:str,access_mode:Any=None,open_timeout:Any=None)->SocketIo:
"""Creates new Socket connection. access_mode and open_timeout are here for compatibility reasons with the pyvisa rm.open_resource()"""
		self.connection=SocketIo(resource_name)
		self.connection.connect()
		return self.connection

"""VisaSession.py"""
import time
from enum import Enum,Flag
from typing import List,Tuple,Callable,AnyStr
import os.path
import re
import threading
#noinspection PyPackageRequirements
import pyvisa
from .VisaPluginSocketIo import ResourceManager,SocketIo
from . import InstrumentSettings,InstrumentErrors,Conversions as Conv
from .InstrumentSettings import WaitForOpcMode,InstrViClearMode as ViClearMode
from .StreamReader import StreamReader
from .StreamWriter import StreamWriter
from .Utilities import size_to_kb_mb_string,calculate_chunks_count
import platform
import struct
class SessionKind(Enum):
"""Visa instrument session type."""
	unsupported=0
	gpib=1
	serial=2
	vxi11=3
	socket=5
	usb=6
	rs_nrp=7
class ReadDataType(Enum):
"""Data type returned by the instrument."""
	unknown=0
	ascii=1
	null=2
	bin_known_len=3
	bin_unknown_len=4
class StatusByte(Flag):
"""Status Byte flags."""
	NONE=0x00
	custom_bit_0=0x01
	custom_bit_1=0x02
	error_queue_not_empty=0x04
	questionable_status_reg=0x08
	message_available=0x10
	event_status_byte=0x20
	request_service=0x40
	operation_status_reg=0x80
class EventStatusRegister(Flag):
"""Event Status Register flags."""
	null=0x00
	operation_complete=0x01
#noinspection PyUnresolvedReferences
class VisaSession(object):
"""Extended VISA class."""
	def __init__(self,resource_name:str,settings:InstrumentSettings,direct_session=None):
		self.reusing_session=direct_session is not None
#noinspection PyTypeChecker
		self._data_chunk_size:int=None
		self._std_bin_block_header_max_len:int=999999999
		self._lock=None
		self.disable_opc_query:bool=settings.disable_opc_query
		self.last_status=None
		self.visa_library_name=None
		self.resource_name=resource_name  #might be changed later if direct_session is used
		self.encoding=settings.encoding  #default encoder between bytes and string
		self.cmd_idn=settings.cmd_idn
		self.skip_status_system_setting=settings.skip_status_system_setting
		self.skip_clear_status=settings.skip_clear_status
		self.stb_in_error_check=settings.stb_in_error_check
#Implemented for interface compatibility with VisaSessionSim
		self.cached_to_stream=False
#Event handlers
#noinspection PyTypeChecker
		self.on_read_chunk_handler:Callable=None
"""If assigned a handler, the VisaSession sends it event on each read chunk transfer."""
#noinspection PyTypeChecker
		self.on_write_chunk_handler:Callable=None
"""If assigned a handler, the VisaSession sends it event on each write chunk transfer."""
		self.io_events_include_data:bool=False
"""If true, the VisaSession events sent to on_read_chunk_handler and on_write_chunk_handler contain transferred data."""
		if self.reusing_session:
#Reuse the session
			self._session=VisaSession.get_and_check_direct_session(direct_session)
			self.resource_name=self._session.resource_name
		else:
#Create new session #Check resource_name for the trailing (SelectVisa=..)
			pure_resource_name,visa_select=self._get_pure_resource_name(resource_name)
			if settings.visa_select is not None:
				visa_select=settings.visa_select
			self._rm=VisaSession.get_resource_manager(visa_select)
			self.manufacturer=self._get_visa_manufacturer()
#Resource manager opening
			try:
				acc_mode=pyvisa.constants.AccessModes.no_lock if settings.exclusive_lock is False else pyvisa.constants.AccessModes.exclusive_lock
self._session=self._rm.open_resource(resource_name=pure_resource_name,open_timeout=settings.open_timeout,access_mode=acc_mode)
			except pyvisa.VisaIOError as e:
				if e.error_code!=pyvisa.constants.StatusCode.error_resource_not_found:
					raise e
				message=e.description
				message+=f"\nLibrary:{self._rm.visalib}\nManufacturer:{self.manufacturer}\nResource Name:'{resource_name}'"
				raise InstrumentErrors.ResourceError(resource_name,message)
			self.resource_name=resource_name
#Decide, whether to create a new thread lock or the existing one from the session
		if hasattr(self._session,'session_thread_rlock'):
			rlock=self._session.session_thread_rlock
			if isinstance(rlock,type(threading.RLock())):
				self.assign_lock(rlock)
		if self.get_lock() is None:
#The existing session did not have a thread lock, assign a new one
			self.assign_lock(threading.RLock())
		self._interface_type=SessionKind.unsupported
		if self._session.interface_type==pyvisa.constants.InterfaceType.gpib or self._session.interface_type==pyvisa.constants.InterfaceType.gpib:
			self._interface_type=SessionKind.gpib
		elif self._session.interface_type==pyvisa.constants.InterfaceType.rsnrp:
			self._interface_type=SessionKind.rs_nrp
		elif self._session.interface_type==pyvisa.constants.InterfaceType.asrl:
			self._interface_type=SessionKind.serial
		elif self._session.interface_type==pyvisa.constants.InterfaceType.usb:
#Check whether it is not the NRP-Z
			intf_type=self._session.get_visa_attribute(pyvisa.constants.VI_ATTR_INTF_TYPE)
			if intf_type==pyvisa.constants.InterfaceType.rsnrp:
				self._interface_type=SessionKind.rs_nrp
		elif self._session.interface_type==pyvisa.constants.InterfaceType.tcpip:
			self._interface_type=SessionKind.vxi11
			if self._session.resource_class=='SOCKET':
				self._interface_type=SessionKind.socket
#Specifics for different interfaces
		self._assure_write_with_tc=settings.assure_write_with_tc
		self._term_char=settings.term_char
		self._term_char_bin=self._term_char.encode(self.encoding)
		self._session.write_termination=''
		self.vxi_capable=settings.vxi_capable
		if self._interface_type==SessionKind.serial:
			self.vxi_capable=False
		elif self._interface_type==SessionKind.socket:
			self.vxi_capable=False
#NRP-Z specific settings
		if self.is_rsnrp_session():
			self.disable_opc_query=True
#NRP-Z does not support chunk reading, therefore the segment must be in one piece
			settings.io_segment_size=1000000
			self.vxi_capable=False
		self.write_delay=settings.write_delay
		self.read_delay=settings.read_delay
		self._viclear_exe_mode=settings.viclear_exe_mode
		self._opc_wait_mode=settings.opc_wait_mode
#Parameters that need to be coerced based on Vxi-capability
		if self.vxi_capable:
			self._add_term_char_to_write_bin_block=settings.add_term_char_to_write_bin_block
			self._session.read_termination=''
		else:
			self._add_term_char_to_write_bin_block=True
			self._session.read_termination=self._term_char
			self._assure_write_with_tc=True
#Changeable settings
		self.opc_timeout=10000 if settings.opc_timeout==0 else settings.opc_timeout
		self.visa_timeout=settings.visa_timeout
		self._session.chunk_size=settings.io_segment_size
		self._data_chunk_size=settings.io_segment_size
#Must call the VISA viClear() before any communication with the instrument
		self.clear()
#Further steps are for NRP-Z session not valid
		if self.is_rsnrp_session():
			return
#Clear instrument status
		if self.skip_clear_status is False:
			self.write('*CLS')
			if self.vxi_capable:
				stb=self._read_stb()
				if stb & StatusByte.message_available:
					self._flush_junk_data()
#Apply settings for ESE and SRE, plus coerce the _opcWaitMode if necessary
		self._opc_wait_mode=self._set_regs_ese_sre(self._opc_wait_mode)
	@staticmethod
	def get_and_check_direct_session(direct_session):
"""Returns direct session if it's a proper type. If the direct_session is None, the function returns None.If the direct_session is of an unsupported type, the function raises RsInstrException."""
		if direct_session is None:
			return None
#Reuse the session
		if not isinstance(direct_session,pyvisa.Resource) and not isinstance(direct_session,SocketIo):
			raise InstrumentErrors.RsInstrException(f"Direct_session must be a VISA resource object. Actual type:'{type(direct_session)}',value:'{direct_session}'")
		return direct_session
	@staticmethod
	def _get_pure_resource_name(resource_name:str):
"""Returns pure resource name stripped of the (SelectVisa) part and the visa_select string"""
		m=re.search(r'(.+)\(SelectVisa=([^),]+)\)',resource_name)
		if not m:
			return resource_name,None
		resource_name=m.group(1).strip()
		visa_select=m.group(2).strip()
		return resource_name,visa_select
	@classmethod
	def get_resource_manager(cls,visa_select:str)->pyvisa.ResourceManager:
"""Returns resource manager for the desired VISA implementation"""
		operating_system=platform.system().lower()
		vsl=None if visa_select is None else visa_select.lower()
		bittness=struct.calcsize('P')*8
#Try if you find the default VISA dll
		try:
			if visa_select is None or visa_select in ['@default','@standard','default','standard','defaultvisa','standardvisa','@defaultvisa','@standardvisa']:
				return pyvisa.ResourceManager()
			if vsl in ['@ni','ni','ivi','@ivi','visa-ni','nivisa','ni-visa','nationalinstruments','nationalinstrumentsvisa']:
				return pyvisa.ResourceManager()
			if vsl in ['@py','pyvisa','visa-py','pyvisa-py']:
				return pyvisa.ResourceManager('@py')
		except ValueError:
#None of the required implementations found, fall back to the R&S VISA
			visa_select='rsvisa'
			vsl=visa_select.lower()
#from here, RsVisa implementation is considered
		if 'rohde&schwarz' in vsl or 'rohdeschwarz' in vsl or vsl=='rsvisa' or vsl=='rs' or vsl=='r&s':
			if operating_system=='windows':
				if bittness==32:
					visa_select=r'c:\Windows\SysWOW64\RsVisa32.dll'
				else:
					visa_select=r'c:\Windows\system32\RsVisa32.dll'
				return pyvisa.ResourceManager(visa_select)
			elif operating_system=='linux':
#The default install location may be different.  for debian/red hat/opensuse derived distributions
				check_visa=[f'/usr/lib{bittness}/librsvisa.so',r'/usr/lib/librsvisa.so']
				for check in check_visa:
					if os.path.isfile(check):
						return pyvisa.ResourceManager(check)
			elif operating_system=='darwin':
#MacOS
				check_visa=[f'/Library/Frameworks/RsVisa.framework/Versions/Current/RsVisa/librsvisa.dylib']
				for check in check_visa:
					if os.path.isfile(check):
						return pyvisa.ResourceManager(check)
		if vsl in ['socketio','socket','none']:
			return ResourceManager()
		return pyvisa.ResourceManager(visa_select)
	def _get_visa_manufacturer(self)->str:
"""Returns manufacturer of the current VISA"""
		if hasattr(self._rm,'VisaManufacturerName'):
			return self._rm.VisaManufacturerName
		try:
			return self._rm.visalib.get_attribute(self._rm.session,pyvisa.constants.VI_ATTR_RSRC_MANF_NAME)[0]
		except TypeError:
			return self._rm.visalib.__class__.__name__
	def is_rsnrp_session(self)->bool:
"""Returns True, if the current session is a NRP-Z session"""
		return self._interface_type==SessionKind.rs_nrp
	def assign_lock(self,lock:threading.RLock)->None:
"""Assigns the provided thread lock by setting the pyvisa runtime session attribute 'session_thread_rlock'
This is done, because if the session is to be entered as an existing session to another RsInstrument object, the lock must be shared as well. The lock is only used by the parent class Instrument."""
		setattr(self._session,'session_thread_rlock',lock)
		self._lock=lock
	def get_lock(self)->threading.RLock:
"""Returns the current RLock object."""
		return self._lock
	def lock_resource(self,timeout:int,requested_key:str or bytes=None)->bytes or None:
"""Locks the instrument to prevent it from communicating with other clients."""
		if requested_key is None:
			self._session.lock_excl(timeout)
			return None
		else:
			return self._session.lock(timeout,requested_key)
	def unlock_resource(self)->None:
"""Unlocks the instrument to other clients."""
		self._session.unlock()
	@property
	def visa_timeout(self)->int:
"""See the visa_timeout.setter."""
		return int(self._session.timeout)
	@visa_timeout.setter
	def visa_timeout(self,value:int)->None:
"""Sets/Gets visa IO timeout in milliseconds."""
		self._session.timeout=int(value)
	@property
	def data_chunk_size(self)->int:
"""Returns max chunk size of one data block."""
		return self._data_chunk_size
	@data_chunk_size.setter
	def data_chunk_size(self,chunk_size:int)->None:
"""Sets the maximum size of one block transferred during write/read operations."""
		self._data_chunk_size=int(chunk_size)
		self._session.chunk_size=int(chunk_size)
	def _resolve_opc_timeout(self,timeout:int)->int:
"""Resolves entered timeout value-if the input value is less than 1, it is replaces with opc_timeout."""
		if timeout is None or timeout<1:
			return self.opc_timeout
		else:
			return timeout
	def _set_regs_ese_sre(self,mode:WaitForOpcMode)->WaitForOpcMode:
"""Based on the WaitForOpcMode, it sets the ESE and SRE register masks.
		Returns coerced WaitForOpcMode."""
#Set the SRE and ESE registers accordingly. #No SRE is supported
		if self.skip_status_system_setting:
			return mode
		self._set_ese_mask(EventStatusRegister.operation_complete)
		self._set_sre_mask(StatusByte.NONE)
		return mode
#noinspection PyTypeChecker
	def _set_ese_mask(self,mask:EventStatusRegister,reset:bool=True)->None:
"""Sends *ESE command with mask parameter."""
		if reset is False:
			current_value=int(self._query_str_no_events('*ESE?'))
			mask=current_value|mask.value
		self.write("*ESE %d" % mask.value)
#noinspection PyTypeChecker
	def _set_sre_mask(self,mask:StatusByte,reset:bool=True)->None:
"""Sends *SRE command with StatusByte mask parameter."""
		if reset is False:
			current_value=int(self._query_str_no_events('*SRE?'))
			mask=current_value|mask.value
#Also affect the _opc_wait_mode:
#If the mask has event_status_byte==false, and the _opc_wait_mode is service_request, set it to stb_poll
#If the mask has event_status_byte==true, do not change anything
		self.write(f'*SRE {mask.value}')
	def _write_and_poll_stb_vxi(self,command:str,is_query:bool,timeout:int,end_mask:StatusByte)->StatusByte:
"""Reads Status Byte Register and ends if the ESB bit (5) is set to 1. Also works with the SOCKET and SERIAL interface by sending *STB? query. In that case however, command cannot be a query. Returns the last read Status Byte value."""
		timeout_secs=timeout/1000
		self.clear_before_read()
		if command.endswith(self._term_char):
			command=command.rstrip(self._term_char)
		self.write(command+';*OPC')
#Use catch to return the VISA Timeout back
		start=time.time()
#STB polling loop
		while True:
			stb=self._read_stb()
			elapsed=self._polling_delay(start)
			if elapsed>timeout_secs:
				self._narrow_down_opc_tout_error(command,is_query,timeout)
			if end_mask & stb:
				break
		return stb
	def _write_and_poll_stb_non_vxi(self,command:str,timeout:int,end_mask:StatusByte)->StatusByte:
"""Queries Status Byte Register (*STB?) and ends if the ESB bit (5) is set to 1. The command must not be a query. Also works with the SOCKET and SERIAL interface. Returns the last read Status Byte value."""
		timeout_secs=timeout/1000
		self.clear_before_read()
		if command.endswith(self._term_char):
			command=command.rstrip(self._term_char)
		self.write(command+';*OPC')
		start=time.time()
#STB polling loop
		while True:
			stb=self._query_stb()
			elapsed=self._polling_delay(start)
			if elapsed>timeout_secs:
				InstrumentErrors.throw_opc_tout_exception(self.opc_timeout,timeout)
			if stb & end_mask:
				break
		return stb
	def _narrow_down_opc_tout_error(self,command:str,is_query:bool,timeout:int)->None:
"""Called by the _write_and_poll_stb_vxi when the timeout expires. The method tries to closer identify the cause of the timeout."""
		stb=self._read_stb()
		timeout=self._resolve_opc_timeout(timeout)
		if is_query:
			if stb & StatusByte.error_queue_not_empty:
				self.clear()
				context=f"Query '{command.strip()}' with OPC Wait resulted in timeout. OPC Timeout is set to {timeout} ms. Additionally,"
InstrumentErrors.assert_no_instrument_status_errors(self.resource_name,self.query_all_syst_errors(),context,first_exc=InstrumentErrors.TimeoutException)
			InstrumentErrors.throw_opc_tout_exception(self.opc_timeout,timeout,f"Query '{command.strip()}'.")
		else:
			if stb & StatusByte.error_queue_not_empty:
				self.clear()
				context=f"Command '{command.strip()}' with OPC Wait resulted in timeout. OPC Timeout is set to {timeout} ms additionally,"
InstrumentErrors.assert_no_instrument_status_errors(self.resource_name,self.query_all_syst_errors(),context,first_exc=InstrumentErrors.TimeoutException)
			InstrumentErrors.throw_opc_tout_exception(self.opc_timeout,timeout,f"Command '{command.strip()}'.")
	def _narrow_down_io_tout_error(self,context:str,visa_timeout:int=0)->None:
"""Called internally after IOTimeoutException can narrow down the error to more specific exception. You can define the visa_timeout value for the error message. Otherwise, the current visa_timeout is reported."""
		context_stripped=context.strip().rstrip("- ")
		if self.stb_in_error_check is False:
			raise InstrumentErrors.TimeoutException(context_stripped)
		if self.vxi_capable:
			stb=self._read_stb()
		else:
#Non-Vxi session
			old_tout=self.visa_timeout
			try:
				self.visa_timeout=500
				stb=self._query_stb(False)
			finally:
				self.visa_timeout=old_tout
		if visa_timeout <=0:
			visa_timeout=self.visa_timeout
		context=context+f'VISA Timeout error occurred ({visa_timeout} milliseconds)'
		if stb & StatusByte.error_queue_not_empty:
		InstrumentErrors.assert_no_instrument_status_errors(self.resource_name,self.query_all_syst_errors(),context+' and ...',first_exc=InstrumentErrors.TimeoutException)
#In case none of the previous exceptions is thrown raise InstrumentErrors.TimeoutException(context)
def _polling_delay(self,start): Generates progressive polling delay."""
		elapsed=time.time()-start
		if self._opc_wait_mode==WaitForOpcMode.stb_poll:
			if elapsed<0.01:
				return elapsed
			if elapsed<0.1:
				time.sleep(0.005)
				return elapsed
			if elapsed<1:
				time.sleep(0.02)
				return elapsed
			if elapsed<5:
				time.sleep(0.05)
				return elapsed
			if elapsed<10:
				time.sleep(0.1)
				return elapsed
			if elapsed<50:
				time.sleep(0.5)
				return elapsed
			time.sleep(1)
		elif self._opc_wait_mode==WaitForOpcMode.stb_poll_slow:
			if elapsed<0.01:
				time.sleep(0.001)
				return elapsed
			if elapsed<1:
				time.sleep(0.02)
				return elapsed
			if elapsed<5:
				time.sleep(0.1)
				return elapsed
			if elapsed<10:
				time.sleep(0.2)
				return elapsed
			if elapsed<20:
				time.sleep(0.5)
				return elapsed
			time.sleep(1)
		elif self._opc_wait_mode==WaitForOpcMode.stb_poll_superslow:
			if elapsed<1:
				time.sleep(0.1)
				return elapsed
			if elapsed<10:
				time.sleep(0.5)
				return elapsed
			if elapsed<20:
				time.sleep(1)
				return elapsed
			time.sleep(2)
		return elapsed
	@staticmethod
	def _parse_err_query_response(response:str)->Tuple[int,str]:
"""Parses entered response string to Tuple(code,message). E.g.:response='-110,"Command error"' returns:(-110,'Command error')"""
		m=re.match(r'([-+]?\d+).*?[\'"](.*)[\'"]',response)
		code=0
		if m:
			try:
				code=int(m.group(1))
			except ValueError:
				pass
			return code,m.group(2)
		else:
			return code,response
	def query_syst_error(self)->Tuple[int,str] or None:
"""Returns one response to the SYSTEM:ERROR? query. The response is a Tuple of (code:int, message:str)"""
		error=self._query_str_no_events('SYST:ERR?')
		if error.startswith('0,') or error.startswith('+0,'):
			return None
		return self._parse_err_query_response(error.strip())
	def query_all_syst_errors(self)->List[Tuple[int,str]] or None:
"""Returns all errors in the instrument's error queue. If no error is detected, the return value is None."""
		errors=[]
		while True:
			entry=self.query_syst_error()
			if entry is None:
				break
			errors.append(entry)
			if len(errors)>50:
#Safety stop
				errors.append('query_all_syst_errors-max limit 50 of SYST:ERR? sent.')
				break
		if len(errors)==0:
			return None
		else:
			return errors
	def _query_stb(self,allow_tout_error_narrow_down:bool=True)->StatusByte:
"""Sends *STB? query and reads the result."""
		return StatusByte(int(self._query_str_no_events('*STB?',allow_tout_error_narrow_down)))
	def _read_stb(self)->StatusByte:
"""Calls viReadStb and returns the result."""
		return StatusByte(self._session.read_stb())
	def clear_before_read(self)->None:
"""Clears IO buffers and the ESR register before reading/writing responses synchronized with *OPC."""
#For NRP-Z sessions, skip this completely
		if self.is_rsnrp_session() or self.skip_clear_status:
			return
		if not self.vxi_capable:
#Non-Vxi session must use *CLS in any case
			self.write('*CLS')
			correct=False
			if self.disable_opc_query:
				opc='1'
			else:
				opc=self._query_str_no_events('*OPC?')
			repeat=0
			while not correct:
				if len(opc) <=2:
					opc=opc.strip()
					correct=opc=='0' or opc=='1'
				if not correct:
#Read again with a small VISA timeout
					opc=self._read_str_timed(5,True)
				repeat+=1
				if repeat>10:
					break
		stb=self._query_stb()
		condition=StatusByte.error_queue_not_empty|StatusByte.message_available|StatusByte.event_status_byte
		if not stb & condition:
			return
		repeat=0
#Loop more times to clear the status subsystem
		while stb & condition:
			if stb & StatusByte.error_queue_not_empty:
				self.write('*CLS')
				_=self.query_all_syst_errors()
			if stb & StatusByte.message_available:
#Clear output buffer
				self._flush_junk_data()
			if stb & StatusByte.event_status_byte:
#OPC or error bits in the ESR
				self.write('*CLS')
				self.query_and_clear_esr()
#Check if the status byte value changed
			previous_stb=stb
			stb=self._query_stb()
			if stb==previous_stb:
				repeat+=1
				if repeat>10:
					raise RsInstrException(f"Cannot clear the instrument's status subsystem. Status Byte:'{stb}'")
	def _flush_junk_data(self)->None:
"""Reads junk bytes to clear the instrument's output buffer."""
		if self.read_delay>0:
			time.sleep(self.read_delay/1000)
		self._read_unknown_len(StreamWriter.as_bin_var(),False)
	def clear(self)->None:
"""Perform VISA viClear conditionally based on the instrument settings."""
		perform_all=ViClearMode.execute_on_all in self._viclear_exe_mode
		perform=False
		if perform_all:
			perform=True
		else:
#Perform on all is blocked, use the SessionKind to decide
			if self._interface_type==SessionKind.gpib:
				perform=ViClearMode.execute_on_gpib in self._viclear_exe_mode
			elif self._interface_type==SessionKind.serial:
				perform=ViClearMode.execute_on_serial in self._viclear_exe_mode
			elif self._interface_type==SessionKind.socket:
				perform=ViClearMode.execute_on_socket in self._viclear_exe_mode
			elif self._interface_type==SessionKind.usb:
				perform=ViClearMode.execute_on_usb in self._viclear_exe_mode
			elif self._interface_type==SessionKind.vxi11:
				perform=ViClearMode.execute_on_tcpvxi in self._viclear_exe_mode
		if not perform:
			return
		if ViClearMode.ignore_error in self._viclear_exe_mode:
#noinspection PyBroadException
			try:
				self._session.clear()
			except Exception:
				pass
		else:
			self._session.clear()
	def is_connection_active(self)->bool:
"""Returns true, if the VISA connection is active and the communication with the instrument still works. This is achieved by:
- checking the session property timeout
- sending the *IDN? query"""
		if self._session is None:
			return False
#noinspection PyBroadException
		try:
			old_tout=self.visa_timeout
			self.visa_timeout=2000
			self.write(self.cmd_idn)
			_=self._read_str_no_events()
			self.visa_timeout=old_tout
			return True
		except Exception:
			return False
	def _write_and_wait_for_opc(self,command:str,is_query:bool,timeout:int)->StatusByte:
"""Internal method to synchronise a command with OPC timeout. Timeout value 0 means the OPC timeout is used."""
		timeout=self._resolve_opc_timeout(timeout)
		if command.endswith(self._term_char):
			command=command.rstrip(self._term_char)
		if is_query:
			InstrumentErrors.assert_query_has_qmark(command,'Query with OPC')
		else:
			InstrumentErrors.assert_cmd_has_no_qmark(command,'Write with OPC')
		if self._opc_wait_mode==WaitForOpcMode.opc_query:
			if is_query:
				raise RsInstrException('Sending a query with OpcQuery synchronization is not possible')
			stb=self._write_and_query_opc(command,timeout)
		else:
#STB polling
			end_stb_mask=StatusByte.error_queue_not_empty|StatusByte.event_status_byte
			if is_query:
				end_stb_mask |=StatusByte.message_available
			if self.vxi_capable:
				stb=self._write_and_poll_stb_vxi(command,is_query,timeout,end_stb_mask)
			else:
				stb=self._write_and_poll_stb_non_vxi(command,timeout,end_stb_mask)
		return stb
	def _write_and_query_opc(self,cmd:str,timeout:int)->StatusByte:
"""Internal method to write a command followed by query_opc(). Used for opc-synchronization if the mode is set to WaitForOpcMode.opc_query or the session is not-vxi. Timeout value 0 means the OPC timeout is used."""
		old_tout=self.visa_timeout
#Change VISA Timeout if necessary
		if old_tout!=timeout:
			self.visa_timeout=timeout
		try:
#try-catch to set the VISA timeout back
			self.write(cmd)
			self.query_opc()
		finally:
			if old_tout!=timeout:
				self.visa_timeout=old_tout
		return self._query_stb()
	def write(self,cmd:str)->None:
"""Writes command to the instrument."""
		if self.write_delay>0:
			time.sleep(self.write_delay/1000)
		add_tc=False
		if self._assure_write_with_tc and not cmd.endswith(self._term_char):
			add_tc=True
		cmd_bytes=cmd.encode(self.encoding)
		if add_tc:
			cmd_bytes+=self._term_char.encode(self.encoding)
		self._session.write_raw(cmd_bytes)
	def _read_unknown_len(self,stream:StreamWriter,allow_chunk_events:bool,prepend_data:AnyStr=None)->None:
"""Reads data of unknown length to the provided WriteStream. The read is performed in an incremental chunk steps to optimize memory use (for NRP-Z session it is set to fixed self._data_chunk_size):
- The first read is performed with the fixed size of 1024 bytes
- The 2nd one reads 64 kBytes
- The 3rd one reads 128 kBytes
- The 4th one reads 256 kBytes and so on, with the max cap of self._data_chunk_size
:param stream:[StreamWriter] target for the read data
:param allow_chunk_events:[bool] if True, the method can send the chunk_events. If False, sending events is blocked.
:param prepend_data:Optional[bytes or string] You can prepend this data to the beginning. It will be considered part of the first read chunk
:return:read data [bytes or string], depending on the parameter binary."""
		with self._session.ignore_warning(pyvisa.constants.StatusCode.success_max_count_read):
			if prepend_data and isinstance(prepend_data,str):
				prepend_data=prepend_data.encode(self.encoding)
			chunk_ix=0
			eot=False
			while not eot:
				if self.is_rsnrp_session():
					chunk_size=self._data_chunk_size
				else:
					if chunk_ix==0:
#First read, set 1024 bytes read size
						chunk_size=1024
					elif chunk_ix==1:
						chunk_size=65536
					else:
						chunk_size*=2
				if chunk_size>self._data_chunk_size:
					chunk_size=self._data_chunk_size
				chunk,self.last_status=self._session.visalib.read(self._session.session,chunk_size)
				if chunk_ix==0 and prepend_data:
					chunk=prepend_data+chunk
				eot=not self._last_status_more_data_available()
				if not stream.binary:
					chunk=chunk.decode(self.encoding)
					if eot:
						chunk=chunk.rstrip(self._term_char)
				stream.write(chunk)
				if self.on_read_chunk_handler and allow_chunk_events:
					total_size=len(stream) if eot is True else None
					event_args=EventArgsChunk(stream.binary,chunk_ix,len(chunk),total_size,len(stream),eot,None,chunk if self.io_events_include_data else None)
					self.on_read_chunk_handler(event_args)
				chunk_ix+=1
	def _last_status_more_data_available(self):
"""Returns True, if the last status signalled that more data is available"""
		return self.last_status==pyvisa.constants.StatusCode.success_max_count_read
	def _read_str_no_events(self)->str:
"""Reads response from the instrument. The response is then trimmed for trailing LF. \n  Sending of any read events is blocked."""
		if self.read_delay>0:
			time.sleep(self.read_delay/1000)
		stream=StreamWriter.as_string_var()
		self._read_unknown_len(stream,False)
		return stream.content
	def _query_str_no_events(self,query:str,allow_tout_error_narrow_down:bool=True)->str:
"""Queries the instrument and reads the response as string. The length of the string is not limited. The response is then trimmed for trailing LF. Sending of any read events is blocked. Use this method for all the service VisaSession queries."""
		response=''
		self.write(query)
		try:
			response=self._read_str_no_events()
		except pyvisa.VisaIOError:
			context=f"Query '{query.rstrip(self._term_char)}'"
			if allow_tout_error_narrow_down:
				self._narrow_down_io_tout_error(context+'-')
			else:
				raise InstrumentErrors.TimeoutException(context)
		return response
	def _query_str_no_events_timed(self,query:str,timeout:int,suppress_read_tout:bool=False)->str:
"""Queries the instrument and reads the response as string. The entered timeout sets the VISA timeout just for this call. You can suppress the timeout error. The length of the string is not limited. The response is then trimmed for trailing LF. Sending of any read events is blocked. Use this method for all the service VisaSession queries."""
		response=''
		self.write(query)
		try:
			response=self._read_str_timed(timeout,suppress_read_tout)
		except pyvisa.VisaIOError:
			self._narrow_down_io_tout_error(f"Query with timeout {timeout} ms '{query.rstrip(self._term_char)}'-",timeout)
		return response
	def _read_str_timed(self,timeout:int,suppress_read_tout:bool=False)->str:
"""Reads response from the instrument with a VISA timeout temporarily set for the read. The VISA timeout is set back to the previous value before the method finishes even if an exception occurs. Sending of any read events is blocked."""
		old_visa_tout=self.visa_timeout
		if suppress_read_tout:
			try:
				if timeout!=old_visa_tout:
					self.visa_timeout=timeout
				data=self._read_str_no_events()
				return data
			except TimeoutError:
				pass
			finally:
				self.visa_timeout=old_visa_tout
		else:
			try:
				if timeout!=old_visa_tout:
					self.visa_timeout=timeout
				data=self._read_str_no_events()
				return data
			finally:
				self.visa_timeout=old_visa_tout
	def _read_str(self)->str:
"""Reads response from the instrument. The response is then trimmed for trailing LF."""
		if self.read_delay>0:
			time.sleep(self.read_delay/1000)
		stream=StreamWriter.as_string_var()
		self._read_unknown_len(stream,True)
		return stream.content
	def query_str(self,query:str)->str:
"""Queries the instrument and reads the response as string. The length of the string is not limited. The response is then trimmed for trailing LF."""
		response=''
		self.write(query)
		try:
			response=self._read_str()
		except pyvisa.VisaIOError:
			self._narrow_down_io_tout_error(f"Query '{query.rstrip(self._term_char)}'-")
		return response
	def query_str_no_tout_err(self,query:str,tout:int)->str:
"""Same as query_str, but you can set the timeout just for this one call. If the timeout exception occurs, it is suppressed and the method returns Null"""
		response=None
		old_tout=self.visa_timeout
		try:
			self.visa_timeout=tout
			response=self.query_str(query)
		except (pyvisa.VisaIOError,InstrumentErrors.StatusException):
			pass
		finally:
			self.visa_timeout=old_tout
		return response
	def write_with_opc(self,command:str,timeout:int=None)->None:
"""Sends command with OPC-sync. If you do not provide timeout, the method uses current opc_timeout."""
		self._write_and_wait_for_opc(command,False,timeout)
	def query_str_with_opc(self,query:str,timeout:int=None,context:str='Query string with OPC')->str:
"""Query string with OPC synchronization. The response is trimmed for any trailing LF. If you do not provide timeout, the method uses current opc_timeout."""
		timeout=self._resolve_opc_timeout(timeout)
		if self.vxi_capable and self._opc_wait_mode is not WaitForOpcMode.opc_query:
#For Vxi session, use the STB poll or SRQ wait and then read the response
			stb=self._write_and_wait_for_opc(query,True,timeout)
			self._check_msg_available_after_opc_wait(stb,query,timeout,context)
			response=self._read_str()
		else:
#For non-Vxi sessions, use the longer VISA Timeout without the *OPC? #Same is valid for WaitForOpcMode.OpcQuery
			InstrumentErrors.assert_query_has_qmark(query,'Query with VISA timeout')
			self.write(query)
			old_tout=self.visa_timeout
#Change VISA Timeout if necessary
			if old_tout!=timeout:
				self.visa_timeout=timeout
			try:
#try-catch to set the VISA timeout back
				response=self._read_str()
				if self._opc_wait_mode is WaitForOpcMode.opc_query:
					self.query_opc()
			finally:
				if old_tout!=timeout:
					self.visa_timeout=old_tout
		return response
	def query_opc(self,timeout:int=0)->bool:
"""Sends *OPC? query and reads the result. If you define timeout>0, the VISA timeout is set to that value just for this method call."""
		if self.disable_opc_query:
			return True
		if timeout>0:
			response=self._query_str_no_events_timed('*OPC?',timeout)
		else:
			response=self._query_str_no_events('*OPC?')
		return Conv.str_to_bool(response)
	def query_and_clear_esr(self)->int:
"""Sends *ESR? query and reads the result."""
		response=self._query_str_no_events('*ESR?')
		return int(response)
	def _check_msg_available_after_opc_wait(self,stb:StatusByte,query:str,timeout:int,context:str)->None:
"""Used internally after _StbPolling() to check if the message is available.
		Throws an exception in case of MAV not available."""
		if not self.vxi_capable:
			return
		if stb & StatusByte.message_available:
			return
#Message not available
		context=context+f" Query '{query.rstrip(self._term_char)}'"
		if stb & StatusByte.error_queue_not_empty:
#Instrument reports an error
			InstrumentErrors.assert_no_instrument_status_errors(self.resource_name,self.query_all_syst_errors(),context)
		else:
#Sometimes even if the StatusByte.MessageAvailable is false, the message is available. #Try to read the STB again
			stb=self._read_stb()
			if not stb & StatusByte.event_status_byte:
#Instrument did not respond within the defined time
				InstrumentErrors.throw_opc_tout_exception(self.opc_timeout,timeout,f'{context} No response from the instrument.')
	def error_in_error_queue(self)->bool:
"""Returns true, if error queue contains at least one error."""
		stb=self._query_stb()
		if stb & StatusByte.error_queue_not_empty:
			return True
		return False
	def reset_ese_sre(self)->None:
"""Resets the status of ESE and SRE registers to default values."""
		self._set_regs_ese_sre(self._opc_wait_mode)
	def write_bin_block(self,cmd:str,data_stream:StreamReader)->None:
"""Writes all the payload as binary data block to the instrument.
The binary data header is added at the beginning of the transmission automatically.
:param cmd:[str] SCPI command with which to send the data
:param data_stream:[StreamReader] data provider for the payload"""
		data_size=len(data_stream)
		len_str=f'{data_size}'
		cmd=cmd.rstrip(self._term_char)
		if '#' in cmd:
			raise RsInstrException(
			   f"Command '{cmd}' must be provided without the binary data header."
				f"The method 'write_bin_block' composes and prepends the binary data header automatically.")
		if data_size <=self._std_bin_block_header_max_len:
#Standard bin data header for sizes below 1E9 bytes, e.g.:'#512345'
			cmd_plus_header=f'{cmd}#{len(len_str)}{len_str}'.encode(self.encoding)
		else:
#Big sizes bin data header:e.g.:'#(3000000000)'
			cmd_plus_header=f'{cmd}#({len_str})'.encode(self.encoding)
		if data_size <=self._data_chunk_size:
#Write all in one step
			full_chunk=data_stream.read_as_binary(self.encoding)
			write_buf=cmd_plus_header+full_chunk
			if self._add_term_char_to_write_bin_block:
				write_buf+=self._term_char_bin
			self._session.write_raw(write_buf)
#Event sending
			if self.on_write_chunk_handler:
				event_args=EventArgsChunk(True,0,data_size,data_size,data_size,True,1,full_chunk if self.io_events_include_data else None)
				self.on_write_chunk_handler(event_args)
		else:
#Write in chunks
			try:
#Use finally to set the session send_end back to True
				self._session.send_end=False
				total_chunks=calculate_chunks_count(data_size,self._data_chunk_size)
				chunk_ix=0
				if self.write_delay>0:
					time.sleep(self.write_delay/1000)
#Write bin header
				self._session.write_raw(cmd_plus_header)
#Write chunks
				while True:
					if len(data_stream)>self._data_chunk_size:
#Not the last segment
						chunk=data_stream.read_as_binary(self.encoding,self._data_chunk_size)
						self._session.write_raw(chunk)
#Event sending
						if self.on_write_chunk_handler:
							event_args=EventArgsChunk(
								True,chunk_ix,self._data_chunk_size,data_size,data_size-len(data_stream),False,total_chunks,chunk if self.io_events_include_data else None)
							self.on_write_chunk_handler(event_args)
					else:
#Last segment, indicate end of message again
						chunk=data_stream.read_as_binary(self.encoding)
						if self._add_term_char_to_write_bin_block:
#Append LF
							self._session.write_raw(chunk)
							self._session.send_end=True
							self._session.write_raw(self._term_char_bin)
						else:
							self._session.send_end=True
							self._session.write_raw(chunk)
#Event sending
						if self.on_write_chunk_handler:						event_args=EventArgsChunk(True,chunk_ix,len(chunk),data_size,data_size,True,total_chunks,chunk if self.io_events_include_data else None)
							self.on_write_chunk_handler(event_args)
						break
					chunk_ix+=1
			finally:
				self._session.send_end=True
	def _parse_bin_data_header(self,exc_if_not_bin:bool)->Tuple[ReadDataType,str,int]:
"""Parses the binary data block and returns the expected length of the following data block. \n
:param exc_if_not_bin:[bool] if True, the method throws exception in case the data is not binary.
:return:read_data_type:[ReadDataType], parsed_header:[string], bin_data_len:[integer]"""
		length=-1
		if self.read_delay>0:
			time.sleep(self.read_delay/1000)
		char:AnyStr=self._session.read_bytes(1,break_on_termchar=True)
		if char==b'#':
#binary transfer
			char=self._session.read_bytes(1,break_on_termchar=True)
			if char==b'0':
				data_type=ReadDataType.bin_unknown_len
				return data_type,'#0',-1
			if char==b'(':
#format for big lengths i.e.>1E9 bytes:'#(1234567890123)...'
				data_type=ReadDataType.bin_known_len
				len_str=(self.read_up_to_char(b')',100)[:-1]).decode(self.encoding)
				whole_hdr='#('+len_str+')'
				length=int(len_str)
				return data_type,whole_hdr,length
#classic format for<1E9 bytes:'#9123456789...'
			data_type=ReadDataType.bin_known_len
			len_of_len=int(char)
			len_str=self._session.read_bytes(len_of_len).decode(self.encoding)
			length=int(len_str)
			whole_hdr='#'+char.decode(self.encoding)+len_str
			return data_type,whole_hdr,length
		data_type=ReadDataType.ascii
		if char==self._term_char_bin:
			data_type=ReadDataType.null
		if self.vxi_capable:
#For Vxi session, to be sure, check whether there are more chars in the read buffer
			stb=self._read_stb()
			if stb & StatusByte.message_available:
				data_type=ReadDataType.ascii
		whole_hdr=char.decode(self.encoding)
		if exc_if_not_bin:
			if data_type==ReadDataType.null:
		InstrumentErrors.throw_bin_block_unexp_resp_exception(self.resource_name,self._term_char)
#Read 20 more characters to compose a better exception message
			whole_hdr+=self.read_up_to_char(self._term_char_bin,20).decode(self.encoding)
			if self.last_status==pyvisa.constants.StatusCode.success_max_count_read:
				self._flush_junk_data()
			InstrumentErrors.throw_bin_block_unexp_resp_exception(self.resource_name,whole_hdr)
		return data_type,whole_hdr,length
	def get_bin_data_length(self,query:str)->int or None:
"""Returns only the length binary data header, and discards the actual data. Any timeout error is suppressed, and the method returns None instead. Warning!!!-for non-VXI sessions (SOCKET, ASRL) this method transfers the entire file to the control PC, which might take a long time."""
		if self.vxi_capable and self._opc_wait_mode!=WaitForOpcMode.opc_query:
#For Vxi session, use the STB poll and read the header
			stb=self._write_and_wait_for_opc(query,True,0)
			try:
				self._check_msg_available_after_opc_wait(stb,query,0,'get_bin_data_length')
			except InstrumentErrors.StatusException:
				return None
			data_type,header,length=self._parse_bin_data_header(True)
			self.clear()
			self.clear_before_read()
			return length
		else:
			with StreamWriter.as_forget() as stream:
				old_timeout=self.visa_timeout
				try:
					self.visa_timeout=2000
					self.query_bin_block(query,stream,True)
				except InstrumentErrors.StatusException:
					return None
				finally:
					self.visa_timeout=old_timeout
				length=stream.written_len
		return length
	def read_bin_block(self,stream:StreamWriter,exc_if_not_bin:bool)->None:
"""Reads binary data block to the provided stream. \n
:param stream:[StreamWriter] target for the read data. Can be string, bytes, or a file
:param exc_if_not_bin:if True, the method throws exception if the received data is not binary"""
		data_type,header,length=self._parse_bin_data_header(exc_if_not_bin)
		if data_type==ReadDataType.ascii:
			stream.switch_to_string_data(self.encoding)
			self._read_unknown_len(stream,True,header)
		elif data_type==ReadDataType.null:
#No data, consider it ASCII. Change the stream type to ASCII and return empty string
			stream.switch_to_string_data(self.encoding)
		elif data_type==ReadDataType.bin_unknown_len:
			if not self.vxi_capable:
				raise RsInstrException(f'Non-Vxi11 sessions can not read binary data block of unknown length.')
			self._read_unknown_len(stream,True)
		elif length==0:
			self._flush_junk_data()
		else:
			self._read_bin_block_known_len(stream,length)
	def _read_bin_block_known_len(self,stream:StreamWriter,length:int)->None:
"""Reads binary data of defined length. All remaining data above the length are disposed of. \n
:param stream:[StreamWriter] target for the read data. Can be string, bytes, or a file
:param length:[int] expected length of the data"""
#Use try-catch to switch the termination character back ON in case of an exception (for non-Vxi sessions)
		try:
#Binary transmission, for non-Vxi session, set the termination character to OFF
			if not self.vxi_capable:
				self._session.read_termination=False
#Binary data of known length
			left_to_read=length
			self.last_status=pyvisa.constants.StatusCode.success
			with self._session.ignore_warning(pyvisa.constants.StatusCode.success_max_count_read):
				chunk_ix=0
				total_chunks=calculate_chunks_count(length,self._data_chunk_size)
				while len(stream)<length:
					chunk_size=min(self._data_chunk_size,left_to_read)
					chunk,self.last_status=self._session.visalib.read(self._session.session,chunk_size)
					left_to_read -=len(chunk)
					stream.write(chunk)
					if self.on_read_chunk_handler:
				event_args=EventArgsChunk(True,chunk_ix,chunk_size,length,len(stream),left_to_read==0,total_chunks,chunk if self.io_events_include_data else None)
						self.on_read_chunk_handler(event_args)
					chunk_ix+=1
			if self._last_status_more_data_available():
				if not self.vxi_capable:
					self._session.read_termination=self._term_char
				self._flush_junk_data()
		finally:
#Make sure that in any case the self._session.read_termination is ON again for non-Vxi sessions
			if not self.vxi_capable:
				self._session.read_termination=self._term_char
	def query_bin_block(self,query:str,stream:StreamWriter,exc_if_not_bin:bool=True)->None:
"""Query binary data block and returns it as byte data. \n
:param query:[str] query to send to the instrument
:param stream:[StreamWriter] target for the read data. Can be string, bytes, or a file
:param exc_if_not_bin:[Boolean] if True, the method throws exception if the received data is not binary"""
		self.write(query)
		try:
			self.read_bin_block(stream,exc_if_not_bin)
		except pyvisa.VisaIOError:
			self._narrow_down_io_tout_error(f"Query bin block '{query.rstrip(self._term_char)}'-")
		return
	def query_bin_block_with_opc(self,query:str,stream:StreamWriter,exc_if_not_bin:bool=True,timeout:int=None)->None:
"""Query binary data block with OPC and returns it as byte data.
:param query:[str] query to send to the instrument
:param stream:[StreamWriter] target for the read data. Can be string, bytes, or a file
:param exc_if_not_bin:[Boolean] if True, the method throws exception if the received data is not binary
:param timeout:Optional[Integer] timeout for the operation. If you skip it, the method uses the current opc timeout."""
		timeout=self._resolve_opc_timeout(timeout)
		if self.vxi_capable and self._opc_wait_mode!=WaitForOpcMode.opc_query:
#For Vxi session, use the STB poll and read the response
			stb=self._write_and_wait_for_opc(query,True,timeout) 	self._check_msg_available_after_opc_wait(stb,query,timeout,'query_bin_block_with_opc')
			self.read_bin_block(stream,exc_if_not_bin)
		else:
#For non-Vxi session, use the longer VISA Timeout without the *OPC			InstrumentErrors.assert_query_has_qmark(query,'query_bin_block_with_opc')
			self.write(query)
			old_visa_timeout=self.visa_timeout
#Change VISA Timeout if necessary
			if old_visa_timeout!=timeout:
				self.visa_timeout=timeout
			try:
#try-catch to set the VISA timeout back
				self.read_bin_block(stream,exc_if_not_bin)
				if self._opc_wait_mode==WaitForOpcMode.opc_query:
					self.query_opc()
			finally:
#Change VISA Timeout back if necessary
				if old_visa_timeout!=timeout:
					self.visa_timeout=old_visa_timeout
	def read_up_to_char(self,stop_chars:bytes,max_cnt:int)->bytes:
"""Reads until one of the stop_chars is read or the max_cnt is reached, or EOT is detected. Returns the read data including the stop character."""
		response=b''
		for i in range(max_cnt):
		  char,self.last_status=self._session.visalib.read(self._session.session,1)
			response+=char
			if char in stop_chars:
				break
			if self.last_status!=pyvisa.constants.StatusCode.success_max_count_read:
				break
		return response
	def go_to_local(self)->None:
"""Puts the instrument into local state."""
		if self.vxi_capable:
		self._session.control_ren(pyvisa.constants.RENLineOperation.deassert_gtl)
		else:
			self.write("&GTL")
	def go_to_remote(self)->None:
"""Puts the instrument into remote state."""
		if self.vxi_capable:
		self._session.control_ren(pyvisa.constants.RENLineOperation.asrt_address)
		else:
			self.write("&GTR")
	def get_session_handle(self)->object:
"""Returns the underlying pyvisa session."""
		return self._session
	def close(self)->None:
"""Closes the Visa session. If the object was created with the direct session input, the session is not closed."""
		if not self.reusing_session:
			self._session.close()
#Events
class EventArgsChunk:
	"""Event arguments for chunk io event."""
	def __init__(self,
			binary:bool,
			chunk_ix:int,
			chunk_size:int,
			total_size:int,
			transferred_size:int,
			end_of_transfer:bool,
			total_chunks:int or None,
			data:AnyStr=None):
		self.binary=binary
		self.chunk_ix=chunk_ix
		self.total_chunks=total_chunks
		self.chunk_size=chunk_size
		self.transferred_size=transferred_size
		self.total_size=total_size
		self.end_of_transfer=end_of_transfer
		self.data=data
	def __str__(self):
		if self.binary:
			type_info='binary'
		else:
			type_info='ascii'
		if not self.total_chunks:
			chunk_info=f' chunk nr. {self.chunk_ix+1}'
		elif self.total_chunks>1:
			chunk_info=f' chunk nr. {self.chunk_ix+1}/{self.total_chunks}'
		else:
			chunk_info=' chunk nr. 1/1'
		eot=' (EOT)' if self.end_of_transfer else ''
		result=\
			f'EventArgsChunk {type_info},{chunk_info},{size_to_kb_mb_string(self.chunk_size,True)},' \
			f'sum {size_to_kb_mb_string(self.transferred_size,True)}/{size_to_kb_mb_string(self.total_size,True) if self.total_size else "<N.A.>"}{eot}.'
		return result

"""VisaSessionSim.py"""
import threading
from typing import Callable,Dict,AnyStr
from . import InstrumentSettings
from .StreamReader import StreamReader
from .StreamWriter import StreamWriter
#noinspection PyMethodMayBeStatic,PyUnusedLocal
class VisaSessionSim(object):
"""Visa session in simulation mode. Provides the properties for the simulation mode. Also serves as a cache for the SCPI command values: If you query a SCPI command value, it returns the last set value by that SCPI command."""
	def __init__(self,resource_name:str,settings:InstrumentSettings,direct_session=None):
		self.reusing_session=direct_session is not None
#noinspection PyTypeChecker
		self._data_chunk_size:int=None
#noinspection PyTypeChecker
		self._lock:threading.RLock=None
#Event handlers
#noinspection PyTypeChecker
		self.on_read_chunk_handler:Callable=None
"""If assigned a handler, the VisaSession sends it event on each read chunk transfer."""
#noinspection PyTypeChecker
		self.on_write_chunk_handler:Callable=None
"""If assigned a handler, the VisaSession sends it event on each write chunk transfer."""
		self.io_events_include_data:bool=False
"""If true, the VisaSession events sent to on_read_chunk_handler and on_write_chunk_handler contain transferred data."""
		self.manufacturer:str='Rohde&Schwarz'
		self.resource_name=resource_name
		self.vxi_capable=True
		self.encoding=settings.encoding  #default encoder between bytes and string
#Changeable settings
		self.opc_timeout=10000 if settings.opc_timeout==0 else settings.opc_timeout
		self.visa_timeout=settings.visa_timeout
		self.data_chunk_size=settings.io_segment_size
		self._last_cmd=None
#If the return value is written to a cache, this flag signals if it was a cached value
		self.cached_to_stream=False
#cache command values dictionary
		self._cmd_vals_cache:Dict[str,AnyStr]={}
#Decide, whether to create a new thread lock or the existing one from the direct_session
		if direct_session and hasattr(direct_session,'session_thread_rlock'):
			rlock=direct_session.session_thread_rlock
			if isinstance(rlock,type(threading.RLock())):
				self.assign_lock(rlock)
		if self.get_lock() is None:
#The existing session did not have a thread lock, assign a new one
			self.assign_lock(threading.RLock())
		if self.reusing_session:
			self.resource_name=direct_session.resource_name
	def assign_lock(self,lock:threading.RLock)->None:
"""Assigns the provided thread lock. The lock is only used by the parent class Instrument."""
		self._lock=lock
	def get_lock(self)->threading.RLock:
"""Returns the current RLock object."""
		return self._lock
	def _update_cmd_vals_cache(self,cmd:str,param:AnyStr=None)->None:
"""Parses out the parameter from the command and stores/updates them in the cache"""
		aux=cmd.split(' ',1)
		if len(aux)<2:
			return
		headers=aux[0].strip().lower()
		param=aux[1].strip()
		self._cmd_vals_cache[headers]=param
	def _update_cmd_vals_cache_split(self,cmd:str,param:AnyStr)->None:
"""Stores/updates cmd and param in the cache"""
		headers=cmd.strip().lower()
		self._cmd_vals_cache[headers]=param
	def _get_cmd_cached_value(self,cmd:str)->str or None:
"""Returns cached parameter to the corresponding command
Returns None of the command is not found in the cache"""
		aux=cmd.split('?',1)
		headers=aux[0].strip().lower()
		return self._cmd_vals_cache.get(headers,None)
	def get_last_sent_cmd(self)->str:
"""Returns the last commands sent to the instrument"""
		return self._last_cmd
	def is_rsnrp_session(self)->bool:
"""Returns True, if the current session is a NRP-Z session"""
		return False
	def query_syst_error(self)->str or None:
"""Returns one response to the SYSTEM:ERROR? query."""
		return None
	def query_all_syst_errors(self)->list or None:
"""Returns all errors in the instrument's error queue. If no error is detected, the return value is None."""
		return None
	def clear_before_read(self)->None:
"""Clears IO buffers and the ESR register before reading/writing responses synchronized with *OPC."""
		return
	def clear(self)->None:
"""Perform VISA viClear conditionally based on the instrument settings."""
		return
	def write(self,cmd:str)->None:
"""Writes command to the instrument."""
		self._last_cmd=cmd
		self._update_cmd_vals_cache(cmd)
		return
	def query_str(self,query:str)->str:
"""Queries the instrument and reads the response as string. The length of the string is not limited. The response is then trimmed for trailing LF."""
		self._last_cmd=query
		cached=self._get_cmd_cached_value(query)
		return 'Simulating' if cached is None else cached
	def write_with_opc(self,cmd:str,timeout:int=None)->None:
"""Sends command with OPC-sync. If you do not provide timeout, the method uses current opc_timeout."""
		self.write(cmd)
	def query_str_with_opc(self,query:str,timeout:int=None,context:str='Query string with OPC')->str:
"""Query string with OPC synchronization. The response is trimmed for any trailing LF. If you do not provide timeout, the method uses current opc_timeout."""
		return self.query_str(query)
	def query_opc(self,timeout:int=0)->bool:
"""Sends *OPC? query and reads the result."""
		return True
	def query_and_clear_esr(self)->int:
"""Sends *ESR? query and reads the result."""
		return 0
	def error_in_error_queue(self)->bool:
"""Returns true, if error queue contains at least one error."""
		return False
	def reset_ese_sre(self)->None:
"""Resets the status of ESE and SRE registers to default values."""
		return
	def write_bin_block(self,cmd:str,data_stream:StreamReader)->None:
"""Writes all the payload as binary data block to the instrument. The binary data header is added at the beginning of the transmission automatically."""
		self._last_cmd=cmd
		param=data_stream.read()
		self._update_cmd_vals_cache_split(cmd,param)
	def query_bin_block(self,query:str,stream:StreamWriter,exc_if_not_bin:bool=True)->None:
"""Query binary data block and returns it as byte data."""
		self._last_cmd=query
		cached=self._get_cmd_cached_value(query)
		if cached is None:
			stream.write(bytes([0,1,2,3,4,5,6,7,8,65,66]))
			self.cached_to_stream=False
		else:
			if isinstance(cached,str):
				stream.switch_to_string_data(self.encoding)
			stream.write(cached)
			self.cached_to_stream=True
	def query_bin_block_with_opc(self,query:str,stream:StreamWriter,exc_if_not_bin:bool=True,timeout:int=None)->None:
"""Query binary data block with OPC and returns it as byte data."""
		self.query_bin_block(query,stream)
	def read_up_to_char(self,stop_chars:bytes,max_cnt:int)->bytes:
"""Reads until one of the stop_chars is read or the max_cnt is reached, or EOT is detected. Returns the read data including the stop character."""
		return b'Simulating'
	def get_session_handle(self)->object:
"""Returns the underlying pyvisa session."""
		return f"Simulating session, resource name '{self.resource_name}'"
	def close(self)->None:
"""Closes the Visa session. If the object was created with the direct session input, the session is not closed."""
		return


Examples in python from Rohde-Schwarz on GitHub 

"""RsFsw_GettingStarted_Example.py"""
"""It shows the RsFsw calls and their corresponding SCPI commands. Notice that the python RsFsw interfaces track the SCPI commands syntax."""
from RsFsw import *
#A good practice is to check for the installed version
RsFsw.assert_minimum_version('5.0.0')
#Open the session
   fsw=RsFsw('TCPIP::192.168.1.102::HISLIP',reset=True)
#Greetings, stranger...
   print(f'Hello, I am: {fsw.utilities.idn_string}')
#Print commands to the console with the logger
   fsw.utilities.logger.mode=LoggingMode.On
   fsw.utilities.logger.log_to_console=True
#Driver's instrument status checking (SYST:ERR?) after each command (default value is true):
   fsw.utilities.instrument_status_checking=True
#SYSTem:DISPlay:UPDate ON
   fsw.system.display.update.set(True)
#INITiate:CONTinuous OFF
   fsw.initiate.continuous.set(False)
   print(f'Always work in single-sweep mode.')
#SENSe.FREQuency:STARt 100000000
   fsw.sense.frequency.start.set(100E6)
#SENSe.FREQuency:STOP 200000000
   fsw.sense.frequency.stop.set(200E6)
#DISPlay:WINDow:TRACe:Y:SCALe:RLEVel -20.0
   fsw.display.window.trace.y.scale.refLevel.set(-20.0)
#DISPlay1:WINDow:SUBWindow:TRACe1:MODE:MAXHold
   fsw.display.window.subwindow.trace.mode.set(enums.TraceModeC.MAXHold,repcap.Window.Nr1,repcap.SubWindow.Default,   repcap.Trace.Tr1)
#DISPlay1:WINDow:SUBWindow:TRACe2:MODE MINHold
   fsw.display.window.subwindow.trace.mode.set(enums.TraceModeC.MINHold,repcap.Window.Nr1,repcap.SubWindow.Default,   repcap.Trace.Tr2)
#SENSe:SWEep:POINts 10001
   fsw.sense.sweep.points.set(10001)
#INITiate:IMMediate (with timeout 3000 ms)
   fsw.initiate.immediate_with_opc(3000)
#TRACe1:DATA?
   trace1=fsw.trace.data.get(enums.TraceNumber.TRACe1)
#TRACe2:DATA?
   trace2=fsw.trace.data.get(enums.TraceNumber.TRACe2)
#CALCulate1:MARKer1:TRACe 1
   fsw.calculate.marker.trace.set(1,repcap.Window.Nr1,repcap.Marker.Nr1)
#CALCulate1:MARKer1:MAXimum:PEAK
   fsw.calculate.marker.maximum.peak.set(repcap.Window.Nr1,repcap.Marker.Nr1)
#CALCulate1:MARKer1:X?
   m1x=fsw.calculate.marker.x.get(repcap.Window.Nr1,repcap.Marker.Nr1)
#CALCulate1:MARKer1:Y?
   m1y=fsw.calculate.marker.y.get(repcap.Window.Nr1,repcap.Marker.Nr1)
print(f'Trace 1 points: {len(trace1)}')
print(f'Trace 1 Marker 1: {m1x} Hz,{m1y} dBm')
#CALCulate1:MARKer2:TRACe 2
   fsw.calculate.marker.trace.set(2,repcap.Window.Nr1,repcap.Marker.Nr2)
#CALCulate1:MARKer2:MINimum:PEAK
   fsw.calculate.marker.minimum.peak.set(repcap.Window.Nr1,repcap.Marker.Nr2)
#CALCulate2:MARKer2:X?
   m2x=fsw.calculate.marker.x.get(repcap.Window.Nr1,repcap.Marker.Nr2)
#CALCulate2:MARKer2:Y?
   m2y=fsw.calculate.marker.y.get(repcap.Window.Nr1,repcap.Marker.Nr2)
print(f'Trace 1 points: {len(trace2)}')
print(f'Trace 1 Marker 1: {m2x} Hz,{m2y} dBm')
#Close the session
fsw.close()

"""RsFsw_ArrangingWindows_Example.py"""
"""This RsFsw Python SCPI package example shows creating new FSW applications and arranging windows"""
from RsFsw import *
#A good practice is to check for the installed version
   RsFsw.assert_minimum_version('5.0.0')
#Open the session
   fsw=RsFsw('TCPIP::192.168.1.102::HISLIP',reset=True)
#Greetings,stranger...
   print(f'Hello, I am: {fsw.utilities.idn_string}')
#Print commands to the console with the logger
   fsw.utilities.logger.mode=LoggingMode.On
   fsw.utilities.logger.log_to_console=True
#Do not log status checking messages if the status was OK
   fsw.utilities.logger.log_status_check_ok=False
#Update display in remote
   fsw.system.display.update.set(True)
#Create new instrument VSA
   fsw.instrument.create.new.set(channel_type=enums.ChannelType.K70_VectorSignalAnalyzer,channel_name='MyVsa')
#Create new instrument Pulse
   fsw.instrument.create.new.set(channel_type=enums.ChannelType.K6_PulseAnalysis,channel_name='MyPulse')
#Select the specan instrument by instrument name
   fsw.instrument.select.set(enums.ChannelType.SpectrumAnalyzer)
#Select the MyVsa by name
   fsw.instrument.selectName.set('MyVsa')
   channels=fsw.instrument.listPy.get()
print(f'All active channels (type,name): {channels}')
#Get catalog of all the active windows in the VSA
   windows=fsw.layout.catalog.window.get()
print(f'All active windows in the VSA (number,name): {windows}')
#Add new window with EVM results to the right of the ResultSummary window
new_name=fsw.applications.k70_Vsa.layout.add.window.get('2',enums.WindowDirection.RIGHt,enums.WindowTypeK70.ErrorVectorMagnitude)
print(f"Newly created window name: '{new_name}'")
#Now move the window 1 to the right from the newly created window:
   fsw.applications.k70_Vsa.layout.move.window.set('1',new_name,enums.WindowDirReplace.RIGHt)
#Close the session
fsw.close()

"""RsFsw_HardcopySaveRecall_Example.py"""
"""- Creates new FSW application.
- Takes a screenshot and transfers the file to the control PC.
- Saves the instrument status to a file 'RsFswState.dfl'.
- Copies the 'RsFswState.dfl' file under a different name to the Control PC: 'RsFswState_PC.dfl'
- Copies the file 'RsFswState_PC.dfl' back to the instrument under a new name 'RsFswState_back.dfl'.
    This simulates acquiring and distribution of a setup file from the Control PC
- Resets the instrument
- Recalls the status from the 'RsFswState_back.dfl'"""
from RsFsw import *
#A good practice is to check for the installed version
   RsFsw.assert_minimum_version('5.0.0')
#Open the session
   fsw=RsFsw('TCPIP::192.168.1.102::HISLIP',reset=True)
#Greetings, stranger...
print(f'Hello, I am: {fsw.utilities.idn_string}')
#Update display in remote
   fsw.system.display.update.set(True)
#Create new instrument PhaseNoise
   fsw.instrument.create.new.set(channel_type=enums.ChannelType.K40_PhaseNoise,channel_name='NoiseOnly')
#Add new window with SpotNoiseTable results at the bottom
new_name=fsw.applications.k40_PhaseNoise.layout.add.window.get('2',enums.WindowDirection.BELow,enums.WindowTypeK40.SpotNoiseTable)
#Let's make a screenshot
   fsw.hardCopy.mode.set(enums.HardcopyMode.SCReen)
   fsw.hardCopy.device.color.set(True)
#Set the color map. Colors.Ix4 means: Screen colors without changes
   fsw.hardCopy.cmap.default.set(colors=repcap.Colors.Ix4)
   fsw.massMemory.name.set(r'c:\Temp\Device_Screenshot2.png')
   fsw.hardCopy.immediate.set_with_opc()
#Copy the screenshot to the PC
   fsw.utilities.read_file_from_instrument_to_pc(r'c:\Temp\Device_Screenshot2.png',r'c:\Temp\PC_Screenshot2.png')
print(r'Screenshot saved here: c:\Temp\PC_Screenshot2.png')
#Save the current instrument status to a recall file
fsw.massMemory.store.state.set(r'RsFswState.dfl')
#Copy the setup file to the PC under a different name
   fsw.utilities.read_file_from_instrument_to_pc(r'RsFswState.dfl',r'c:\Temp\RsFswState_PC.dfl')
print(r'Setup file saved here: c:\Temp\RsFswState_PC.dfl')
#Copy the setup file back to the instrument as 'RsFswState_back.dfl'
   fsw.utilities.send_file_from_pc_to_instrument(r'c:\Temp\RsFswState_PC.dfl',r'RsFswState_back.dfl')
#Make a reset and restore the saved state.
   fsw.utilities.reset()
#Restore the instrument status with the file copied back from the PC
   fsw.massMemory.load.state.set(r'RsFswState_back.dfl')
#Close the session
fsw.close()

"""RsFsw_UsingGroupRepCaps_Example.py"""
#The example shows the default repcap setting done in group objects and/or cloning it.
#Each group can be cloned with clone() method, and then its repcaps can be set independently to other default values.
#These values are then taken as a default for all the methods belonging to that group.
#That means, as long as you do not want to use another repcap value, you can use the method overloads without the repcaps.
#Example (see more in the actual code): #var tr3=fsw.display.window.subwindow.trace.clone()
#tr3.repcap_trace_set(repcap.Trace.Tr2)
#Now the following two calls send the same SCPI command: DISPlay1:WINDow:SUBWindow1:TRACe3:MODE MAXHold
#fsw.display.window.subwindow.trace.mode.set(enums.TraceModeCenum.MAXHold,repcap.WindowRepCap.Nr1,repcap.SubWindowRepCap.Nr1,repcap.TraceRepCap.Tr3)
#tr3.mode.set(enums.TraceModeCenum.MAXHold)
#Preconditions:
#- Install the RsFsw driver package over Packet Manager from NuGet.org
#- Adjust the IP address the match your instrument
from RsFsw import *
#A good practice is to check for the installed version
   RsFsw.assert_minimum_version('5.0.0')
#Open the session
   fsw=RsFsw('TCPIP::192.168.1.102::HISLIP',reset=True)
#Greetings, stranger...
print(f'Hello, I am: {fsw.utilities.idn_string}')
   fsw=RsFsw("TCPIP::localhost::HISLIP",True,True)
   #fsw=RsFsw("TCPIP::localhost::HISLIP",True,True,options='SelectVisa=RsVisa')  #Forcing R&S VISA
#fsw=RsFsw("TCPIP::localhost::5025::SOCKET",True,True,options='SelectVisa=SocketIo')  #No VISA installation needed
#Driver's instrument status checking ( SYST:ERR? ) after each command (default value is true):
   fsw.utilities.instrument_status_checking=True
#SYSTem:DISPlay:UPDate ON
   fsw.system.display.update.set(True)
#INITiate:CONTinuous OFF
   fsw.initiate.continuous.set(True)
print('Always work in single-sweep mode.')
#SENSe.FREQuency:STARt 100000000
   fsw.sense.frequency.start.set(100E6)
#SENSe.FREQuency:STOP 200000000
   fsw.sense.frequency.stop.set(200E6)
#DISPlay:WINDow:TRACe:Y:SCALe:RLEVel -20.0
   fsw.display.window.trace.y.scale.refLevel.set(-20.0)
#DISPlay:WINDow:SUBWindow:TRACe:Y:SCALe 60.0
   fsw.display.window.subwindow.trace.y.scale.set(60.0)
#Prepare tr1 and tr2 to work with the trace 1 and trace 2 interfaces:
   tr1=fsw.display.window.subwindow.trace.clone()
   tr1.repcap_trace_set(repcap.Trace.Tr1)
   tr2=fsw.display.window.subwindow.trace.clone()
   tr2.repcap_trace_set(repcap.Trace.Tr2)
#Standard usage with all the repcaps defined in the method call:
#DISPlay1:WINDow:SUBWindow:TRACe1:MODE MAXHold
fsw.display.window.subwindow.trace.mode.set(enums.TraceModeC.MAXHold,repcap.Window.Nr1,repcap.SubWindow.Nr1,repcap.Trace.Tr1)
#Now the following call sends the same command:
   tr1.mode.set(enums.TraceModeC.MAXHold)
#DISPlay1:WINDow:SUBWindow:TRACe2:MODE MINHold
fsw.display.window.subwindow.trace.mode.set(enums.TraceModeC.MINHold,repcap.Window.Nr1,repcap.SubWindow.Nr1,repcap.Trace.Tr2)
#Now the following call sends the same command:
   tr2.mode.set(enums.TraceModeC.MINHold)
#SENSe:SWEep:POINts 10001
   fsw.sense.sweep.points.set(10001)
#INITiate:IMMediate (set timeout 3000 ms)
   fsw.initiate.immediate_with_opc(3000)
#TRACe1:DATA?
   trace1=fsw.trace.data.get(enums.TraceNumber.TRACe1)
#TRACe2:DATA?
   trace2=fsw.trace.data.get(enums.TraceNumber.TRACe2)
#CALCulate1:MARKer1:TRACe 1
   fsw.calculate.marker.trace.set(1,repcap.Window.Nr1,repcap.Marker.Nr1)
   mark1=fsw.calculate.marker.clone()
   mark1.RepCapMarker=repcap.Marker.Nr1
#CALCulate1:MARKer1:MAXimum:PEAK
   fsw.calculate.marker.maximum.peak.set(repcap.Window.Nr1,repcap.Marker.Nr1)
#Same command with the mark1 interface:
   mark1.maximum.peak.set()
#CALCulate1:MARKer1:X?
   m1x=fsw.calculate.marker.x.get(repcap.Window.Nr1,repcap.Marker.Nr1)
#Same command with the mark1 interface:
   m1x=mark1.x.get()
#CALCulate1:MARKer1:Y?
   m1y=fsw.calculate.marker.y.get(repcap.Window.Nr1,repcap.Marker.Nr1)
#Same command with the mark1 interface:
   m1y=mark1.y.get()
print(f'Trace 1 points: {len(trace1)}')
print(f'Trace 1 Marker 1: {m1x} Hz,{m1y} dBm')
#CALCulate1:MARKer2:TRACe 2
   fsw.calculate.marker.trace.set(2,repcap.Window.Nr1,repcap.Marker.Nr2)
   mark2=fsw.calculate.marker.clone()
   mark2.RepCapMarker=repcap.Marker.Nr2
#CALCulate1:MARKer2:MINimum:PEAK
   fsw.calculate.marker.minimum.peak.set(repcap.Window.Nr1,repcap.Marker.Nr2)
#Same effect with the mark2 interface:
   mark2.minimum.peak.set()
#CALCulate2:MARKer2:X?
   m2x=fsw.calculate.marker.x.get(repcap.Window.Nr1,repcap.Marker.Nr2)
#Same effect with the mark1 interface:
   m2x=mark2.x.get()
#CALCulate2:MARKer2:Y?
   m2y=fsw.calculate.marker.y.get(repcap.Window.Nr1,repcap.Marker.Nr2)
#Same command with the mark1 interface:
   m2y=mark2.y.get()
print(f'Trace 2 points: {len(trace2)}')
print(f'Trace 2 Marker 2: {m2x} Hz,{m2y} dBm')
#Close the session
fsw.close()

"""RsInstrument_FPC_trace_to_csv.py"""
"""Requires: FPC1x00 series SPA, FW 1.70 or newer and adequate options
- Installed RsInstrument Python module from pypi.org
- Installed VISA e.g. R&S Visa 5.12.x or newer
Description: Setup measurement, get trace data, slice it, calculate frequency list, and save data to a local CSV file"""
from RsInstrument import *
from time import sleep
#Define variables
resource='TCPIP::10.205.0.184::INSTR'    #VISA resource string for the device
#resource='TCPIP::172.16.10.10::INSTR'  #Original resource string when using USB connection
recdur=10                                #Time in seconds to find max hold peaks
filename=r'C:\test\TraceFile.CSV'
#Define the device handle
instrument=RsInstrument(resource,reset=True,id_query=True,options="SelectVisa='rs'")
'''- option SelectVisa:
    - 'SelectVisa='socket' - uses no VISA implementation for socket connections 
                             - you do not need any VISA-C installation
    - 'SelectVisa='rs' - forces usage of Rohde&Schwarz Visa
    - 'SelectVisa='ni' - forces usage of National Instruments Visa'''
#Define subroutines
def com_prep():
"""Preparation of the communication (termination, timeout, etc...)"""
    print(f'VISA Manufacturer: {instrument.visa_manufacturer}')  #Confirm VISA package to be chosen
    instrument.visa_timeout=5000                               #Timeout in ms for VISA Read Operations
    instrument.opc_timeout=3000                                #Timeout in ms for opc-synchronised operations
    instrument.instrument_status_checking=True                 #Error check after each command
    instrument.clear_status()                                    #Clear status register
def close():
"""Close the VISA session"""
    instrument.close()
def com_check():
"""Check communication with the device by requesting it's ID"""
    idn_response=instrument.query_str('*IDN?')
    print('Hello, I am '+idn_response)
def meas_prep():
"""Prepare instrument for desired measurements
In this case
- Set Center Frequency to 1540 MHz
- Set Span to 100 MHz
- Set Trace to Max Hold (and Positive Peak automatically)"""
    instrument.write_str_with_opc('FREQuency:CENTer 2450e6')      #Center Frequency to 2450 MHz
    instrument.write_str_with_opc('FREQuency:SPAN 100e6')         #SPAN is 100 MHz now
    instrument.write_str_with_opc('DISPlay:TRACe1:MODE MAXHold')  #Trace to Max Hold
def trace_get():
"""Initialize continuous measurement, stop it after the desired time, query trace data"""
    instrument.write_str_with_opc('INITiate:CONTinuous ON')       #Continuous measurement on trace 1 ON
    print('Please wait for maxima to be found...')
    sleep(int(recdur))                                            #Wait for preset record time
    instrument.write('DISPlay:TRACe1:MODE VIEW')                  #Continuous measurement on trace 1 OFF
    instrument.query_opc()
    sleep(0.5)
#Get y data (amplitude for each point)
    trace_data=instrument.query('Trace:DATA? TRACe1')           #Read y data of trace 1
    csv_trace_data=trace_data.split(",")                        #Slice the amplitude list
    trace_len=len(csv_trace_data)                               #Get number of elements of this list
#Reconstruct x data (frequency for each point) as it can not be directly read from the instrument
    start_freq=instrument.query_float('FREQuency:STARt?')
    span=instrument.query_float('FREQuency:SPAN?')
    step_size=span/(trace_len-1)
#Now write values into file
    file=open(filename, 'w')                               #Open file for writing
    file.write("Frequency in Hz;Power in dBm\n")           #Write the headline
    x=0                                                    #Set counter to 0 as list starts with 0
    while x<int(trace_len):                                #Perform loop until all sweep points are covered
        file.write(f'{(start_freq+x * step_size):.1f}')    #Write adequate frequency information
        file.write(";")
        amp=float(csv_trace_data[x])
        file.write(f'{amp:.2f}')                           #Write adequate amplitude information
        file.write("\n")
        x=x+1
    file.close()                                           #Close the file
#Main Program begins here
com_prep()
com_check()
meas_prep()
trace_get()
close()
print('Program successfully ended.')
print('Wrote trace data into', filename)

"""RsInstrument_FSH_Screenshot_to_PC.py"""
"""Description: Setup measurement, get trace data, slice it, calculate frequency list, and save data to a local CSV file"""
from RsInstrument import *
from time import sleep
#Define variables
resource='TCPIP::10.205.0.41::INSTR'     #VISA resource string for the device
#resource='TCPIP::172.16.10.10::INSTR'   #Original resource string when using USB connection
recdur=10                                #Time in seconds to find max hold peaks
inst_filename='"\Public\Screen Shots\screenshot.png"'
pc_filename=r'C:\test\FSH_ScreenShot.PNG'
#Define the device handle
instrument=RsInstrument(resource,reset=True,id_query=True,options="SelectVisa='rs'")
'''- option SelectVisa:
- 'SelectVisa='socket' - uses no VISA implementation for socket connections - you do not need any VISA-C installation
- 'SelectVisa='rs' - forces usage of Rohde&Schwarz Visa
- 'SelectVisa='ni' - forces usage of National Instruments Visa'''
#Define subroutines
def com_prep():
"""Preparation of the communication (termination,timeout,etc...)"""
    print(f'VISA Manufacturer: {instrument.visa_manufacturer}')  #Confirm VISA package to be chosen
    instrument.visa_timeout=5000  #Timeout in ms for VISA Read Operations
    instrument.opc_timeout=3000  #Timeout in ms for opc-synchronised operations
    instrument.instrument_status_checking=True  #Error check after each command
    instrument.clear_status()  #Clear status register
def close():
"""Close the VISA session"""
    instrument.close()
def com_check():
"""Check communication with the device by requesting it's ID"""
    idn_response=instrument.query_str('*IDN?')
    print('Hello, I am '+idn_response)
def meas_prep():
"""Prepare instrument for desired measurements
    In this case
    - Set Center Frequency to 1540 MHz
    - Set Span to 100 MHz
    - Set Trace to Max Hold (and Positive Peak automatically)"""
    instrument.write_str_with_opc('FREQuency:CENTer 2450e6')  #Center Frequency to 2450 MHz
    instrument.write_str_with_opc('FREQuency:SPAN 100e6')  #SPAN is 100 MHz now
    instrument.write_str_with_opc('DISPlay:TRACe1:MODE MAXHold')  #Trace to Max Hold
def measure():
"""Initialize continuous measurement, stop it after the desired time, query trace data"""
    instrument.write_str_with_opc('INITiate:CONTinuous ON')  #Continuous measurement on trace 1 ON
    print('Please wait for maxima to be found...')
    sleep(int(recdur))  #Wait for preset record time
    instrument.write('DISPlay:TRACe1:MODE VIEW')         #Set trace to view mode/stop collecting data
    instrument.query_opc()
def screen_copy():
"""Prepare and perform screenshot, transfer data to local PC"""
    instrument.write('HCOPy:DEVice:LANGuage PNG')        #Select file format for screenshot (possible: PNG or JPG)
    instrument.write(f'MMEMory:NAME {inst_filename}')    #Define path and name for the screenshot on the instrument
    instrument.write('HCOPy:IMMediate')                  #Perform screenshot and save it on the analyzer
    #Transfer file to PC
    instrument.data_chunk_size=10000
    instrument.query_bin_block_to_file(f'MMEMory:DATA? {inst_filename}',f'{pc_filename}',append=False)
    instrument.write(f'MMEMory:DELete {inst_filename}')  #And delete it on the instrument
#Main Program begins here
com_prep()
com_check()
meas_prep()
measure()
screen_copy()
close()
print('Program successfully ended.')
print('Wrote trace data into',pc_filename)

"""RsInstrument_FSH_trace_to_CSV.py"""
"""Requires: FPC1x00 series SPA, FW 1.70 or newer and adequate options
- Installed RsInstrument Python module from pypi.org
- Installed VISA e.g. R&S Visa 5.12.x or newer
Description: Setup measurement, get trace data, slice it, calculate frequency list, and save data to a local CSV file"""
from RsInstrument import *
from time import sleep
#Define variables
resource='TCPIP::10.205.0.184::INSTR'   #VISA resource string for the device
#resource='TCPIP::172.16.10.10::INSTR'  #Original resource string when using USB connection
recdur=10                               #Time in seconds to find max hold peaks
filename=r'C:\test\TraceFile.CSV'
#Define the device handle
instrument=RsInstrument(resource,reset=True,id_query=True,options="SelectVisa='rs'")
'''- option SelectVisa:
- 'SelectVisa='socket' - uses no VISA implementation for socket connections 
                       - you do not need any VISA-C installation
- 'SelectVisa='rs' - forces usage of Rohde&Schwarz Visa
- 'SelectVisa='ni' - forces usage of National Instruments Visa'''
#Define subroutines
def com_prep():
"""Preparation of the communication (termination,timeout,etc...)"""
    print(f'VISA Manufacturer: {instrument.visa_manufacturer}')  #Confirm VISA package to be chosen
    instrument.visa_timeout=5000                                 #Timeout in ms for VISA Read Operations
    instrument.opc_timeout=3000                                  #Timeout in ms for opc-synchronised operations
    instrument.instrument_status_checking=True                   #Error check after each command
    instrument.clear_status()                                    #Clear status register   
def close():
"""Close the VISA session"""
    instrument.close()
def com_check():
"""Check communication with the device by requesting it's ID"""
    idn_response=instrument.query_str('*IDN?')
    print('Hello, I am '+idn_response)
def meas_prep():
"""Prepare instrument for desired measurements 
In this case
- Set Center Frequency to 2540 MHz
- Set Span to 100 MHz
- Set Trace to Max Hold (and Positive Peak automatically)"""
    instrument.write_str_with_opc('FREQuency:CENTer 2450e6')      #Center Frequency to 2450 MHz
    instrument.write_str_with_opc('FREQuency:SPAN 100e6')         #SPAN is 100 MHz now
    instrument.write_str_with_opc('DISPlay:TRACe1:MODE MAXHold')  #Trace to Max Hold
def trace_get():
"""Initialize continuous measurement, stop it after the desired time, query trace data"""
    instrument.write_str_with_opc('INITiate:CONTinuous ON')  #Continuous measurement on trace 1 ON
    print('Please wait for maxima to be found...')
    sleep(int(recdur))                                       #Wait for preset record time
    instrument.write('DISPlay:TRACe1:MODE VIEW')             #Continuous measurement on trace 1 OFF
    instrument.query_opc()
    sleep(0.5)
#Get y data (amplitude for each point)
    trace_data=instrument.query('Trace:DATA? TRACe1')        #Read y data of trace 1
    csv_trace_data=trace_data.split(",")                     #Slice the amplitude list
    trace_len=len(csv_trace_data)                            #Get number of elements of this list
#Reconstruct x data (frequency for each point) as it can not be directly read from the instrument
    start_freq=instrument.query_float('FREQuency:STARt?')
    span=instrument.query_float('FREQuency:SPAN?')
    step_size=span/(trace_len-1)
#Now write values into file
    file=open(filename,'w')                                  #Open file for writing
    file.write("Frequency in Hz;Power in dBm\n")             #Write the headline
    x=0                                                      #Set counter to 0 as list starts with 0
    while x<int(trace_len):                                  #Perform loop until all sweep points are covered
        file.write(f'{(start_freq+x*step_size):.1f}')        #Write adequate frequency information
        file.write(";")
        amp=float(csv_trace_data[x])
        file.write(f'{amp:.2f}')                             #Write adequate amplitude information
        file.write("\n")
        x=x+1
    file.close()                                             #Close the file
#Main Program begins here
com_prep()
com_check()
meas_prep()
trace_get()
close()
print('Program successfully ended.')
print('Wrote trace data into',filename)

"""RsInstrument_FSW_Example.py"""
#Example for FSW/FSV/FSVA/FPS Spectrum Analyzers
#Preconditions: #- Installed RsInstrument Python module from pypi.org #- Installed VISA e.g. R&S Visa 5.12.x or newer
from RsInstrument import * 
from time import time
   fsw=None
RsInstrument.assert_minimum_version('1.53.0')
try:
#Adjust the VISA Resource string to fit your instrument
	fsw=RsInstrument('TCPIP::localhost::INSTR',True,False)
	fsw.visa_timeout=3000                            #Timeout for VISA Read Operations
	fsw.opc_timeout=3000                             #Timeout for opc-synchronised operations
	fsw.instrument_status_checking=True              #Error check after each command
except Exception as ex:
	print('Error initializing the instrument session:\n'+ex.args[0])
	exit()
print(f'Driver Version: {fsw.driver_version}')
print(f'SpecAn IDN: {fsw.idn_string}')
print(f'SpecAn Options: {",".join(fsw.instrument_options)}')
   fsw.clear_status()
   fsw.reset()
   fsw.write_str('INIT:CONT ON')                               #Switch OFF the continuous sweep
   fsw.write_str('SYST:DISPlay:')                              #Display update ON - switch OFF after debugging
#Basic Settings:
   fsw.write_str('DISPlay:WINDow:TRACe:Y:SCALe:RLEVel 10DBM')  #Setting the Reference Level
   fsw.write_str('FREQ:CENT 3.0 GHz')                          #Setting the center frequency
   fsw.write_str('FREQ:SPAN 200 MHz')                          #Setting the span
   fsw.write_str('BAND 100 kHz')                               #Setting the RBW
   fsw.write_str('BAND:VID 300kHz')                            #Setting the VBW
   fsw.write_str('SWE:POIN 10001')                             #Setting the sweep points
   fsw.query_opc()                                    #Using *OPC? query waits until all the instrument settings are finished
#SyncPoint 'SettingsApplied' - all the settings were applied
   fsw.VisaTimeout=2000                                   #Sweep timeout - set it higher than the instrument acquisition time
   fsw.write_str_with_opc('INIT')                              #Start the sweep and wait for it to finish
#SyncPoint 'AcquisitionFinished' - the results are ready #Fetching the trace  #The functions are universal for binary or ascii data format
   t=time()
   trace=fsw.query_bin_or_ascii_float_list('FORM ASC;:TRAC? TRACE1')  #Query ascii array of floats
print(f'Instrument returned {len(trace)} points in the ascii trace, query duration {time()-t:.3f} secs')
   t=time()
   fsw.bin_float_numbers_format=BinFloatFormat.Single_4bytes   #This tells the driver in which format to expect the binary float data
   trace=fsw.query_bin_or_ascii_float_list('FORM REAL,32;:TRAC? TRACE1')  #Query binary array of floats - the query function is the same as for the ASCII format
print(f'Instrument returned {len(trace)} points in the binary trace, query duration {time()-t:.3f} secs')
#Setting the marker to max and querying the X and Y
   fsw.write_str_with_opc('CALC1:MARK1:MAX')   #Set the marker to the maximum point of the entire trace, wait for it to be set
   markerX=fsw.query_float('CALC1:MARK1:X?')
   markerY=fsw.query_float('CALC1:MARK1:Y?')
print(f'Marker Frequency {markerX:.2f} Hz, Level {markerY:.3f} dBm')
#Making an instrument screenshot and transferring the file to the PC
   fsw.write_str("HCOP:DEV:LANG PNG")
   fsw.write_str(r"MMEM:NAME 'c:\temp\Dev_Screenshot.png'")
   fsw.write_str("HCOP:IMM")                   #Make the screenshot now
   fsw.query_opc()                             #Wait for the screenshot to be saved
   fsw.read_file_from_instrument_to_pc(r"c:\temp\Dev_Screenshot.png",r"c:\Temp\PC_Screenshot.png")  
#Transfer the instrument file to the PC
print(r"Instrument screenshot file saved to PC 'c:\Temp\PC_Screenshot.png'")
#Close the session
fsw.close()

"""RsInstrument_FSW_iq_transfer_display.py"""
#Example for FSW/FSV/FSVA/FPS Spectrum Analyzers
#Example for FSW showing binary IQ data read from the instrument and displayed as power spectrum
#Preconditions:
#- Installed RsInstrument Python module from pypi.org
#- Installed VISA e.g. R&S Visa 5.12.x or newer
import numpy as np
import matplotlib.pyplot as plt
from scipy import signal
from RsInstrument import * #The RsInstrument package is hosted on pypi.org.
#Variables
IP='10.102.72.182'        #Analyzer IP address
fs=100e6 		        #Sample rate (Hz)
ct=1e-3		        #Capture time (s)
freq=3.9e9		        #Center frequency (Hz)
RefLev=-10		        #Reference level (dBm)
#Open connection
fsw=None
RsInstrument.assert_minimum_version('1.53.0')
try:
#Adjust the VISA Resource string to fit your instrument
	fsw=RsInstrument('TCPIP::'+IP+'::hislip0',True,False)
	fsw.visa_timeout=10000               #Timeout for VISA Read Operations
	fsw.opc_timeout=10000                #Timeout for opc-synchronised operations
	fsw.instrument_status_checking=True  #Error check after each command
except Exception as ex:
	print('Error initializing the instrument session:\n'+ex.args[0])
	exit()
print(f'Driver Version: {fsw.driver_version}')
print(f'SpecAn IDN: {fsw.idn_string}')
   fsw.clear_status()
   fsw.reset()
#Basic Settings:
   fsw.write_str('DISPlay:WINDow:TRACe:Y:SCALe:RLEVel '+str(RefLev))
   fsw.write_str('FREQ:CENT '+str(freq))
#Configure IQ Analyzer
   fsw.write_with_opc('INST:CRE:NEW IQ,\'IQ Analyzer\'')
   fsw.write_str(':INIT:CONT OFF')
   fsw.write_str(':TRAC:IQ:SRAT '+str(fs))
   fsw.write_str(':SENS:SWE:TIME '+str(ct))
   fsw.query_str_with_opc(':LAY:ADD:WIND? \'1\',BEL,FREQ')
   fsw.query_opc()
#Start measurement
   fsw.write_with_opc('INIT:IMM')
#Get IQ data in binary format
   fsw.write_str('FORM REAL,32')
   fsw.write_with_opc('TRAC:IQ:DATA:FORM IQP')
   tmp=np.array(fsw.query_bin_or_ascii_float_list('TRAC:IQ:DATA:MEM?'))
#Close connection
   fsw.go_to_local()
   fsw.close()
#Create complex array of IQ data
   iq=tmp[0::2]+1j*tmp[1::2]
#FFT
   N=len(iq)
#Window function
   win=signal.windows.flattop(N)
#Window normalization
   U=np.square(np.sum(win))
#Window the data
   iq_win=iq*win
#FFT size
   NFFT=2**(N-1).bit_length()
#FFT
   IQ=np.fft.fft(iq_win,NFFT)
   IQ=np.fft.fftshift(IQ)
#Move the Nyquist point to the right-hand side (pos freq) to be consistent with plot when looking at the positive half only.
   IQ=np.concatenate((IQ[1:],IQ[0]),axis=None)
#Frequency axis
   df=fs/NFFT
   f=np.arange(1,NFFT+1)*df-fs/2
   f=f+freq
#Power spectrum
   Pxx=np.real(IQ*np.conjugate(IQ))/U
#Convert to dBm (50 Ohm load assumed)
   Pxx=10*np.log10(Pxx/50*1000)
#Plot
plt.plot(f,Pxx)
plt.grid()
plt.xlabel('Frequency (Hz)')
plt.ylabel('PSD (dBm)')
plt.show()

"""RsInstrument_LongLasting_Adjustment.py"""
#Example on how to use the RsInstrument module for remote-controlling of your instrument
#Here we show on how to perform a long-lasting operation, like for example an instrument calibration
#Preconditions:
#- Installed RsInstrument Python module from pypi.org
#- Installed VISA e.g. R&S Visa 5.12.x or newer
from RsInstrument import *  #The RsInstrument package is hosted on pypi.org, see Readme.txt for more details
   instr_resource_string='TCPIP::10.112.1.179::HISLIP'
   option_string_empty=''
   option_string_force_ni_visa='SelectVisa=ni'  #Forcing NI VISA usage
   option_string_force_rs_visa='SelectVisa=rs'  #Forcing R&S VISA usage
   option_string_force_no_visa='SelectVisa=SocketIo'  #Socket communication for LAN connections, no need for any VISA installation
#Make sure you have the last version of the RsInstrument
   RsInstrument.assert_minimum_version('1.53.0')
   instr=RsInstrument(instr_resource_string,True,False,option_string_empty)
   idn=instr.query_str('*IDN?')
print(f"\nInstrument: '{idn}'")
print(f'RsInstrument driver version: {instr.driver_version}')
print(f'Visa manufacturer: {instr.visa_manufacturer}')
print(f'Installed options: {",".join(instr.instrument_options)}')
#Start the alignment
   cal_timeout_secs=240
print(f'Starting instrument complete alignment,timeout {cal_timeout_secs} seconds...')
   result=instr.query_str_with_opc('CAL:ALL:MEAS?',cal_timeout_secs * 1000)
print(f'Finished with result {result}')
print('Closing the instrument session')
#Close the session
   instr.close()

"""RsInstrument_HMF25xx_load_ARB_man.py"""
Description: Send an ARB waveform to the instrument and provide the ARB signal to the output."""
from RsInstrument import *
from time import sleep
RsInstrument.assert_minimum_version('1.53.0')
instr=RsInstrument('TCPIP::10.205.0.72::5025::SOCKET',True,True,     #Init with IDN query and reset
                     "SelectVisa='rs',"                                    #VISA type selection (valid parameters: rs or ni)
                     " Termination Character='\n',"             #Just to show how this is done. \n ist standard termination. 
                     " AssureWriteWithTermChar=True")                    #Be sure to have all commands terminated with \n
sleep(1)
   idn=instr.query_str('*IDN?')
print(f"\nHello,I am: '{idn}'")
#We assume the following amplitude values to be defined for a triangle waveform:  0/32767/0/-32768/0
bin_data=bytes([00,00,0x7F,0xFF,00,00,0x80,00,00,00])
   instr.write_bin_block("DATA ",bin_data)        #Transfer the ARB data to the instrument
   instr.write_str('FREQ 3000')                    #Set Frequency to 3 kHz
   instr.write_str('VOLT 2')                       #Voltage is 2 V(pp) now
   instr.write_str('FUNC:ARB RAM')                 #Arbitrary function working from memory
   instr.query_opc()
   instr.write_str('FUNC ARB')                     #Change to ARB mode
   instr.write_str('OUTP ON')                      #Switch output on
   instr.query_opc()
print('\n')
print('Arb File transferred to memory, ARB mode is active,output state is ON')
   instr.close()  #And close the connection finally

"""RsInstrument_MXO-Waveform_transfer_Screenshot.py"""
This Python example shows how to transfer waveform data (ASCII and binary format)+screenshot from MXO oscilloscope to the controller PC. The MXO probe compensation signal can be used for a simple test.
from RsInstrument import *                  #The RsInstrument package is hosted on pypi.org, see Readme.txt for more details
import matplotlib.pyplot as plt
from time import time
def main():
#Make sure you have the last version of the RsInstrument
    RsInstrument.assert_minimum_version('1.53.0')
#mxo=None
    try:
#Adjust the VISA Resource string to fit your instrument
        mxo=RsInstrument('TCPIP::10.205.0.159::INSTR',id_query=True,reset=True,options="SelectVisa='rs'")
        mxo.logger.mode=LoggingMode.On
        mxo.visa_timeout=6000                #Timeout for VISA Read Operations
        mxo.opc_timeout=3000                 #Timeout for opc-synchronised operations
        mxo.instrument_status_checking=True  #Error check after each command
    except Exception as ex:
        print('Error initializing the instrument session:\n'+ex.args[0])
        exit()
    print(f'Device IDN: {mxo.idn_string}')
    print(f'Device Options: {",".join(mxo.instrument_options)}\n')
       mxo.clear_status()
       mxo.reset()
#Basic settings - To test with mxo probe compensation signal connected to CH1
    mxo.write('SYSTem:DISPlay:UPDate ON')      #Keep display on while under remote control
    mxo.opc_timeout=10000                      #Change OPC timeout value as the next action will take more than 3 seconds
    mxo.write_with_opc('AUToscale')            #Perform autoscaling on the used signal
    mxo.opc_timeout=3000                       #And change OPC timeout value back to default
    mxo.write('TRIGger:MODE NORMal')           #Set trigger to Normal to avoid unwanted triggering while in Auto mode
#Perform acquisition
       start=time()
       mxo.write_str_with_opc("RUNsingle")     #Single acquisition is presupposition for retrieving waveform data
       stop=time()
    print('MXO triggered,capturing data ...')
    print(f'Number of sample points: {mxo.query_float("ACQ:POIN?")}')
    print(f'Data capturing elapsed time: {stop-start:.3f}sec\n')
#Get and plot binary data
    start=time()
       mxo.write_str("FORMat:DATA REAL,32;:FORMat:BORDer LSBFirst")
       mxo.bin_float_numbers_format=BinFloatFormat.Single_4bytes
       mxo.data_chunk_size=100000               #transfer in blocks of 100k bytes (default)
    print('Now start to transfer binary waveform data. Please wait for about 20 seconds...')
       data_bin=mxo.query_bin_or_ascii_float_list("CHAN:DATA?")
    print(f'Binary waveform transfer elapsed time: {time()-start:.3f}sec\n')
    plt.figure(1)
    plt.plot(data_bin)
    plt.title('Binary waveform')
#Get and plot ASCII data just to show how long it would take in comparison
       start=time()
       mxo.write_str("FORM:DATA ASC")
       mxo.data_chunk_size=100000               #transfer in blocks of 100k bytes (default)
    print('Now start to transfer ASCII waveform data. Please wait for about 120 seconds...')
       data_asc=mxo.query_bin_or_ascii_float_list("CHAN:DATA?")
    print(f'ASCII waveform transfer elapsed time: {time()-start:.3f}sec')
    plt.figure(2)
    plt.plot(data_asc)
    plt.title('ASCII waveform')
#get screenshot
    file_path_instr=r'/home/instrument/userData/Device_Screenshot.png'  #MXO is a LINUX based device
    file_path_pc=r'c:\temp\Device_Screenshot.png'                       #While this path is based on the WIN world
       mxo.write_str("HCOPy:DEVice1:LANGuage PNG")
       mxo.write_str(f"MMEMory:NAME '{file_path_instr}'")
       mxo.write_str_with_opc("HCOPy:IMMediate1")
       mxo.read_file_from_instrument_to_pc(file_path_instr,file_path_pc)
    print(f'\nTransferred screen shot to {file_path_pc}\n')
       mxo.close()
    print('Close the plot windows to end the script...')
    plt.show()
if __name__=="__main__":
    main()

"""RsInstrument_RTB2000_Example.py"""
from RsInstrument import *
from time import time
rtb=None
try:
#Adjust the VISA Resource string to fit your instrument
	rtb=RsInstrument('TCPIP::192.168.2.10::INSTR',True,False)
	rtb.visa_timeout=3000                #Timeout for VISA Read Operations
	rtb.opc_timeout=15000                #Timeout for opc-synchronised operations
	rtb.instrument_status_checking=True  #Error check after each command
except Exception as ex:
	print('Error initializing the instrument session:\n'+ex.args[0])
	exit()
print(f'RTB2000 IDN: {rtb.idn_string}')
print(f'RTB2000 Options: {",".join(rtb.instrument_options)}')
rtb.clear_status()
rtb.reset()
rtb.write_str("TIM:ACQT 0.01")                           #10ms Acquisition time
rtb.write_str("CHAN1:RANG 5.0")                          #Horizontal range 5V (0.5V/div)
rtb.write_str("CHAN1:OFFS 0.0")                          #Offset 0
rtb.write_str("CHAN1:COUP ACL")                          #Coupling AC 1MOhm
rtb.write_str("CHAN1:STAT ON")                           #Switch Channel 1 ON
rtb.write_str("TRIG:A:MODE AUTO")                        #Trigger Auto mode in case of no signal is applied
rtb.write_str("TRIG:A:TYPE EDGE;:TRIG:A:EDGE:SLOP POS")  #Trigger type Edge Positive
rtb.write_str("TRIG:A:SOUR CH1")                         #Trigger source CH1
rtb.write_str("TRIG:A:LEV1 0.05")                        #Trigger level 0.05V
rtb.query_opc()                                        #Using *OPC? query waits until all the instrument settings are finished
rtb.visa_timeout=2000                                    #Acquisition timeout - set it higher than the acquisition time
rtb.write_str("SING")
t=time()
trace=rtb.query_bin_or_ascii_float_list('FORM ASC;:CHAN1:DATA?')      #Query ascii array of floats
print(f'Instrument returned {len(trace)} points in the ascii trace, query duration {time()-t:.3f} secs')
t=time()
rtb.bin_float_numbers_format=BinFloatFormat.Single_4bytes  #This tells the driver in which format to expect the binary float data
trace=rtb.query_bin_or_ascii_float_list('FORM REAL,32;:CHAN1:DATA?')  #Query binary array of floats - the query function is the same as for the ASCII format
print(f'Instrument returned {len(trace)} points in the binary trace, query duration {time()-t:.3f} secs')
rtb.write_str("MMEM:CDIR '/INT/'")                                    #Change the directory
rtb.InstrumentStatusChecking=False 
#Ignore errors generated by the MMEM:DEL command, the error is generated if the file does not exist
rtb.write_str("MMEM:DEL 'Dev_Screenshot.png'")    
#Delete the file if it already exists, otherwise you get 'Execution error' by creating a new screenshot
rtb.query_opc()
rtb.clear_status()
rtb.InstrumentStatusChecking=True                           #Error checking back ON
rtb.write_str("HCOP:LANG PNG;:MMEM:NAME 'Dev_Screenshot'")  #Hardcopy settings for taking a screenshot - notice no file extension here
rtb.write_str("HCOP:IMM")                                   #Make the screenshot now
rtb.query_opc()                                             #Wait for the screenshot to be saved
rtb.read_file_from_instrument_to_pc(r'Dev_Screenshot.png',r'c:\Temp\PC_Screenshot.png') #Query the instrument file to the PC
print(r"Screenshot file saved to PC 'c:\Temp\PC_Screenshot.png'")
#Close the session
rtb.close()

"""RsInstrument_RTO_Example.py"""
from RsInstrument import *
from time import time
RsInstrument.assert_minimum_version('1.53.0')
rto=None
try:
	rto=RsInstrument('TCPIP::192.168.2.10::INSTR',True,False)
	rto.visa_timeout=3000                #Timeout for VISA Read Operations
	rto.opc_timeout=15000                #Timeout for opc-synchronised operations
	rto.instrument_status_checking=True  #Error check after each command
except Exception as ex:
	print('Error initializing the instrument session:\n'+ex.args[0])
	exit()
print(f'rto2000 IDN: {rto.idn_string}')
print(f'rto2000 Options: {",".join(rto.instrument_options)}')
rto.clear_status()
rto.reset()
rto.write_str("SYST:DISP:UPD ON")    #Display update ON - switch OFF after debugging
                                     #Basic Settings:
rto.write_str("ACQ:POIN:AUTO RECL")  #Define Horizontal scale by number of points
rto.write_str("TIM:RANG 0.01")       #10ms Acquisition time
rto.write_str("ACQ:POIN 20002")      #20002 X points
rto.write_str("CHAN1:RANG 2")        #Horizontal range 2V
rto.write_str("CHAN1:POS 0")         #Offset 0
rto.write_str("CHAN1:COUP AC")       #Coupling AC 1MOhm
rto.write_str("CHAN1:STAT ON")       #Switch Channel 1 ON
                                     #Trigger Settings: 
rto.write_str("TRIG1:MODE AUTO")                      #Trigger Auto mode in case of no signal is applied
rto.write_str("TRIG1:SOUR CHAN1")                     #Trigger source CH1
rto.write_str("TRIG1:TYPE EDGE;:TRIG1:EDGE:SLOP POS") #Trigger type Edge Positive
rto.write_str("TRIG1:LEV1 0.04")                      #Trigger level 40mV
rto.query_opc()                                       #Using *OPC? query waits until all the instrument settings are finished
#SyncPoint 'SettingsApplied' - all the settings were applied
#Arming the rto for single acquisition
rto.visa_timeout=2000                                 #Acquisition timeout - set it higher than the acquisition time
rto.write_str("SING")
#DUT_Generate_Signal() - in our case we use Probe compensation signal 
#where the trigger event (positive edge) is reoccurring
rto.query_opc()                                       #Using *OPC? query waits until the instrument finished the Acquisition
#SyncPoint 'AcquisitionFinished' - the results are ready #Fetching the waveform in ASCII and BINary format
t=time()
trace=rto.query_bin_or_ascii_float_list('FORM ASC;:CHAN1:DATA?')      #Query ascii array of floats
print(f'Instrument returned {len(trace)} points in the ascii trace, query duration {time()-t:.3f} secs')
t=time()
rto.bin_float_numbers_format=BinFloatFormat.Single_4bytes 
#This tells the driver in which format to expect the binary float data
trace=rto.query_bin_or_ascii_float_list('FORM REAL,32;:CHAN1:DATA?')  #Query binary array of floats-the query function is the same as for the ASCII format
print(f'Instrument returned {len(trace)} points in the binary trace, query duration {time()-t:.3f} secs')
#Making an instrument screenshot and transferring the file to the PC
rto.write_str('HCOP:DEV:LANG PNG')                        #Set the screenshot format
rto.write_str(r"MMEM:NAME 'c:\temp\Dev_Screenshot.png'")  #Set the screenshot path
rto.write_str("HCOP:IMM")                                 #Make the screenshot now
rto.query_opc()                                           #Wait for the screenshot to be saved
rto.read_file_from_instrument_to_pc(r'c:\temp\Dev_Screenshot.png',r'c:\Temp\PC_Screenshot.png')  
                                                          #Query the instrument file to the PC
print(r"Screenshot file saved to PC 'c:\Temp\PC_Screenshot.png'")
                                                          #Close the session
rto.close()

"""RsNgx_GettingStarted_Example.py"""
"""RsNgx basic example - sets Voltage, Current limit and output state on two output channels. In comments above the calls, you see the SCPI commands sent. Notice, that the SCPI commands track the python interfaces."""
#Commit search results · GitHub 
import time
from RsNgx import *
   ngx=RsNgx('TCPIP::10.102.52.45::INSTR')
   ngx.utilities.reset()
#Master switch for all the outputs-switch OFF                 #OUTPut:GENeral:STATe OFF
   ngx.output.general.set_state(False)
#Select and set Output 1                                      #INSTrument:SELect 1
   ngx.instrument.select.set(1)
#SOURce:VOLTage:LEVel:IMMediate:AMPlitude 3.3
   ngx.source.voltage.level.immediate.set_amplitude(3.3)
#SOURce:CURRent:LEVel:IMMediate:AMPlitude 0.1
   ngx.source.current.level.immediate.set_amplitude(0.1)
#Prepare for setting the output to ON with the master switch  #OUTPut:SELect ON
   ngx.output.set_select(True)
#Select and set Output 2                                      #INSTrument:SELect 2
   ngx.instrument.select.set(2)
#SOURce:VOLTage:LEVel:IMMediate:AMPlitude 5.1
   ngx.source.voltage.level.immediate.set_amplitude(5.1)
#SOURce:CURRent:LEVel:IMMediate:AMPlitude 0.05
   ngx.source.current.level.immediate.set_amplitude(0.05)
#Prepare for setting the output to ON with the master switch  #OUTPut:SELect ON
   ngx.output.set_select(True)
#The outputs are still OFF, they wait for this master switch: #OUTPut:GENeral:STATe ON
   ngx.output.general.set_state(True)
#Insert a small pause to allow the instrument to settle the output
time.sleep(0.5)
#INSTrument:SELect 1
   ngx.instrument.select.set(1)
#READ?
   measurement=ngx.read()
print(f'Measured values Output 1: {measurement.Voltage} V, {measurement.Current} A')
#INSTrument:SELect 2
   ngx.instrument.select.set(2)
#READ?
   measurement=ngx.read()
print(f'Measured values Output 2: {measurement.Voltage} V, {measurement.Current} A')
ngx.close()

"""RsInstrument_NGP_Arb_Setup.py"""
#GitHub examples repository path: Powersupplies/Python/RsInstrument. 
Description: Initiate Instrument, configure and start ARB curve on CH1"""
from RsInstrument import *
from time import sleep
#Initialize and request instrument for all sessions via VISARsInstrument.assert_minimum_version('1.53.0')
ngp=RsInstrument('TCPIP::10.205.0.149::hislip0',True,True,"SelectVisa='rs',")  #Control the device via RsVISA
idn=ngp.query_str('*IDN?')
print(f"\nHello, I am '{idn}'")
def close():
"""Close VISA connection"""
    ngp.close()                                          #Close the connection finally
def arb_setup():
"""Perform all the ARB settings"""
    ngp.write('INSTrument:SELect OUT1')                  #Choose CH1
    ngp.write('ARB:BLOC:DATA 5,1,2,1,12,2,2,1,15,1,2,1') #Define Arb Block
                                                         #(5 V, 1 A, 2 seconds, interpolated
                                                         #(12 V, 2 A, 2 seconds, interpolated
    ngp.write('ARB:BLOC:REP 1')                          #Block is repeated 1 time in sequence
    ngp.write('ARBitrary:SEQuence:REPetitions 3')        #Sequence will be repeated 3 times
    ngp.write('ARBitrary:SEQuence:BEHavior:END OFF')     #Switch off Channel after sequence is done
    ngp.query_opc()                                      #Check for command completion using *OPC?
    ngp.write('ARBitrary:SEQuence:TRANsfer')             #Transfer Arb sequence into memory
    ngp.query_opc()                                      #Check for command completion using *OPC?
def arb_start():
"""Start the ARB curve"""
    ngp.write('ARBitrary:STATe ON')                      #Arb is active now
    ngp.write('OUTPut:STATe ON')                         #CH1 on (is still chosen from former sequence)
    ngp.write('OUTPut:GENeral:STATe ON')                 #Master Output ON
    ngp.query_opc()                                      #Check for command completion
def off():
"""Wait until CH1 changes to OFF state (ARB sequence is done), then switch off Main Output"""
    state=1
    print('\n')
    print('Waiting for ARB sequence to be completed', end="")
    while state==1:
        sleep(0.4)
        print('.',end="")
        state=ngp.query_int('OUTPut:STATe?')             #Request CH1 state
    ngp.write('OUTPut:GENeral:STATe OFF')                #Switch off Main Output
arb_setup()
arb_start()
off()
close()
print('\n --> I am done now')

"""RsNgx_Hardcopy_Example.py"""
"""RsNgx example showing how to make a screenshot of the instrument display."""
import time
from RsNgx import *
file_path=r'c:\temp\ngx_screenshot.png'
RsNgx.assert_minimum_version('3.0.0.38')
   ngx=RsNgx('TCPIP::10.102.52.45::INSTR')
print(f'Hello, I am: {ngx.utilities.idn_string}')
   ngx.display.window.text.set_data("My Greetings to you ...")
   ngx.hardCopy.formatPy.set(enums.HcpyFormat.PNG)
   picture=ngx.hardCopy.get_data()
file=open(file_path, 'wb')
file.write(picture)
file.close()
print(f'Screenshot saved to: {file_path}')
   ngx.close()


Rigol-instruments

https://github.com/pklaus/DS1054Z/blob/master/DS1054Z/cli.py 

"""cli.py"""
#!/usr/bin/env python
#-*- coding: utf-8 -*-
"""CLI for the DS1054Z scope by Rigol"""
import argparse
import textwrap
import logging
import time
import io
import pkg_resources
import sys
import os
import itertools
import errno
from DS1054Z import DS1054Z
#Py2 fix for input()
try: input=raw_input
except NameError: pass
#Py2 fix for itertools.zip_longest()
try:
    zip_longest=itertools.zip_longest
except AttributeError:
    zip_longest=itertools.izip_longest
SHELL_HOWTO=""" Enter a command. It will be sent to the DS1054Z. If the command contains a question mark ('?'), the answer will be read from the device. Quit the shell with 'quit' or by pressing Ctrl-C"""
def comma_sep(s):
    return s.split(',')
def late_parents(self,parents):
"""Hack to add a positional argument before the parents[]  https://hg.python.org/cpython/file/3.4/Lib/argparse.py#l1649"""
    for parent in parents:
        self._add_container_actions(parent)
        try:
            defaults=parent._defaults
        except AttributeError:
            pass
        else:
            self._defaults.update(defaults)
def main():
    parser=argparse.ArgumentParser(description=textwrap.dedent(__doc__),
        formatter_class=argparse.RawDescriptionHelpFormatter,)
    parser.add_argument('-v','--verbose',action='store_true',help='More verbose output')
    parser.add_argument('--version',action='store_true',
#'Display the version of the tool/package and exit.'
        help=argparse.SUPPRESS)
    parser.add_argument('--debug',action='store_true',  #help='Enable debugging output',
        help=argparse.SUPPRESS,)
    device_parser=argparse.ArgumentParser(add_help=False)
    device_parser.add_argument('device',nargs='?',
        help='The device string. Typically the IP address of the oscilloscope. '
             'Will try to discover a single (!) scope on the network if you leave it out.')
    subparsers=parser.add_subparsers(dest='action',metavar='<action>',
        help="Action to perform on the scope:")
#DS1054Z discover
    action_desc='Discover and list scopes on your network and exit'
    discover_parser=subparsers.add_parser('discover',
        description=action_desc,help=action_desc)
#DS1054Z info
    action_desc='Print information about your oscilloscope'
    cmd_parser=subparsers.add_parser('info',parents=[device_parser],
        description=action_desc,help=action_desc)
#DS1054Z cmd
    action_desc='Send an SCPI command to the oscilloscope'
    cmd_parser=subparsers.add_parser('cmd',
        description=action_desc,help=action_desc)
    cmd_parser.add_argument('command',metavar=':SCPI:CMD',
        help="The command to execute. If the command contains a '?' the answer will be read from the device and printed to stdout.")
    late_parents(cmd_parser,parents=[device_parser])
#DS1054Z save-screen
    action_desc='Save an image of the screen'
    save_screen_parser=subparsers.add_parser('save-screen',parents=[device_parser],
        description=action_desc,help=action_desc)
    save_screen_parser.add_argument('--filename','-f',metavar='IMG_FILENAME',
        help='The filename template for the image')
    save_screen_parser.add_argument('--overlay','-o',metavar='RATIO',type=float,default=0.5,
        help='Dim on-screen controls in --save-screen with a mask (default ratio: 0.5)')
    save_screen_parser.add_argument('--printable','-p',action='store_true',
        help='Make the screenshot more printer-friendly')
#DS1054Z save-data
    action_desc='Save the waveform data to a file'
    save_data_parser=subparsers.add_parser('save-data',parents=[device_parser],
        description=action_desc,help=action_desc)
    save_data_parser.add_argument('--filename','-f',
        metavar='FILENAME',default='DS1054Z-scope-values_{ts}.csv',
        help='The filename template for the data file. '
             'The kind of file is determined by its filename extension. '
             'Defaults to: DS1054Z-scope-values_{ts}.csv')
    save_data_parser.add_argument('--mode',default='NORMal',choices=('NORMal','MAXimum','RAW'),
        help='The mode determins whether you will be reading the 1200 displayed samples (NORMal) '
             'or stopping the scope and reading out the full memory (RAW). '
             'MAXimum either reads the full memory if the scope is already stopped '
             'or the 1200 displayed samples otherwise.'
             'Defaults to NORMal.')
    save_data_parser.add_argument('--without-time',action='store_false',dest='with_time',
        help="If specified, it will save the data without the extra column "
             "of time values that's being added by default")
#DS1054Z settings
    action_desc='View and change settings of the oscilloscope'
    settings_parser=subparsers.add_parser('settings',parents=[device_parser],
        description=action_desc,help=action_desc)
    settings_parser.add_argument('--timebase',type=float,
        help="Change the timebase of the oscilloscope to this value (in seconds/div).")
    settings_parser.add_argument('--timebase-offset',type=float,
        help="Change the timebase offset of the oscilloscope to this value (in seconds).")
#DS1054Z properties
    action_desc='Query properties of the DS1054Z instance'
    properties_parser=subparsers.add_parser('properties',description=action_desc,help=action_desc)
    properties_parser.add_argument('properties',metavar='PROPERTIES',type=comma_sep,
        help="The properties to query separated by a comma, like: 'idn,memory_depth_internal_total'. "
             "Asking for a single one will also work, off course.")
    late_parents(properties_parser,parents=[device_parser])
#DS1054Z run
    action_desc='Start the oscilloscope data acquisition'
    run_parser=subparsers.add_parser('run',parents=[device_parser],
        description=action_desc,help=action_desc)
#DS1054Z stop
    action_desc='Stop the oscilloscope data acquisition'
    stop_parser=subparsers.add_parser('stop',parents=[device_parser],
        description=action_desc,help=action_desc)
#DS1054Z single
    action_desc='Set the oscilloscope to the single trigger mode.'
    single_parser=subparsers.add_parser('single',parents=[device_parser],
        description=action_desc,help=action_desc)
#DS1054Z tforce
    action_desc='Generate a trigger signal forcefully.'
    tforce_parser=subparsers.add_parser('tforce',parents=[device_parser],
        description=action_desc,help=action_desc)
#DS1054Z shell
    action_desc='Start an interactive shell to control your scope.'
    tforce_parser=subparsers.add_parser('shell',parents=[device_parser],
        description=action_desc,help=action_desc)
#DS1054Z measure
    action_desc='Measure a value on a channel'
    measure_parser=subparsers.add_parser('measure',parents=[device_parser],
        description=action_desc,help=action_desc)
    measure_parser.add_argument('--channel','-c',choices=(1,2,3,4),type=int,required=True,
        help='Channel from which to take the measurement')
    measure_parser.add_argument('--type','-t',choices=('CURRent','MAXimum','MINimum','AVERages','DEViation'),default='CURRent') measure_parser.add_argument('item',choices=('vmax','vmin','vpp','vtop','vbase','vamp','vavg','vrms','overshoot','preshoot','marea','mparea','period','frequency','rtime','ftime','pwidth','nwidth','pduty','nduty','rdelay','fdelay','rphase','fphase','tvmax','tvmin','pslewrate','nslewrate','vupper','vmid','vlower','variance','pvrms'),
        help='Value to measure')
    args=parser.parse_args()
    if args.version:
        print(pkg_resources.get_distribution("DS1054Z").version)
        sys.exit(0)
    if args.debug:
        logging.basicConfig(level=logging.DEBUG)
    if not args.action:
        parser.print_help(sys.stderr)
        sys.stderr.write('\nERROR: Please choose an action.\n\n')
        sys.exit(2)
    if args.action=='discover':
        try:
            from DS1054Z.discovery import discover_devices
        except:
            print('Discovery depends on the zeroconf Python package which is missing.')
            sys.exit(1)
        devices=discover_devices()
        for device in devices:
            if args.verbose:
                print("Found a {model} with the IP Address {ip}.".format(**device))
            else:
                print("{ip}".format(**device))
        sys.exit(0)
    if not args.device:
        try:
            from DS1054Z.discovery import discover_devices
        except:
            print("Please specify a device to connect to. Auto-discovery doesn't "
                  "work because the zeroconf Python package is missing.")
            sys.exit(1)
        devices=discover_devices()
        if len(devices) < 1:
            print("Couln't discover any device on the network. Exiting.")
            sys.exit(1)
        elif len(devices) > 1:
            print("Discovered multiple devices on the network:")
            print("\n".join("{model} {ip}".format(**dev) for dev in devices))
            print("Please specify the device you would like to connect to.")
            sys.exit(1)
        else: #len(devices)==0
            if args.verbose: print("Found a scope: {model} @ {ip}".format(**devices[0]))
            args.device=devices[0]['ip']
    ds=DS1054Z(args.device)
    if args.action=='info':fmt="\nVendor:{0}\nProduct:{1}\nSerial:{2}\nFirmware:{3}\n"
        print(fmt.format(ds.vendor,ds.product,ds.serial,ds.firmware))
    if args.action=='cmd':
        if '?' in args.command:
            print(ds.query(args.command))
        else:
            ds.write(args.command)
    if args.action in ('run','stop','single','tforce'):
        getattr(ds,args.action)()
    if args.action=='settings':
        if args.timebase:
            ds.timebase_scale=args.timebase
        if args.timebase_offset:
            ds.timebase_offset=args.timebase_offset
        wp=ds.waveform_preamble_dict
        if args.verbose:
            displayed_channels=ds.displayed_channels
            print("Sample Rate: {0}Sa/s".format(DS1054Z.format_si_prefix(ds.sample_rate)))
            print("Timebase: {0}s/div".format(DS1054Z.format_si_prefix(ds.timebase_scale)))
            print("Timebase Offset: {0}s".format(DS1054Z.format_si_prefix(ds.timebase_offset)))
            ds.set_waveform_mode('NORMal')
            tv=ds.waveform_time_values
            t_from=DS1054Z.format_si_prefix(tv[0],unit='s')
            t_to= DS1054Z.format_si_prefix(tv[-1],unit='s')
            print("The time axis goes from {0} to {1}".format(t_from,t_to))
            print("Displayed Channels: {0}".format(' '.join(displayed_channels)))
            for channel in displayed_channels:
                print("  Channel {0}:".format(channel))
                print("    Scale: {0}V/div".format(DS1054Z.format_si_prefix(ds.get_channel_scale(channel))))
                print("    Offset: {0}V".format(ds.get_channel_offset(channel)))
                print("    Probe Ratio: {}".format(ds.get_probe_ratio(channel)))
                print("    ---".format(DS1054Z.format_si_prefix(ds.get_channel_scale(channel))))
        else:
            print('sample_rate={}'.format(ds.sample_rate))
            print('timebase_scale={}'.format(ds.timebase_scale))
            print('timebase_offset={}'.format(ds.timebase_offset))
            print('displayed_channels={}'.format(','.join(ds.displayed_channels)))
    if args.action=='properties':
        for prop in args.properties:
            val=getattr(ds,prop)
            if args.verbose:
                print('{0}: {1}'.format(prop,val))
            else:
                if type(val) in (list,tuple):
                    print(' '.join(str(v) for v in val))
                else:
                    print(val)
    if args.action=='save-screen':
        try:
            from PIL import Image,ImageOps,ImageEnhance
        except ImportError:
            parser.error('Please install Pillow (or the older PIL) to use --save-screen')
#formatting the filename
        if args.filename: fmt=args.filename
        else: fmt='DS1054Z-scope-display_{ts}.png'
        ts=time.strftime("%Y-%m-%d_%H-%M-%S",time.localtime())
        filename=fmt.format(ts=ts)
#need to find out file extension for Pillow on Windows...
        ext=os.path.splitext(filename)[1]
        if not ext: parser.error('could not detect the image file type extension from the filename')
#getting and saving the image
        im=Image.open(io.BytesIO(ds.display_data))
        overlay_filename=pkg_resources.resource_filename("DS1054Z","resources/overlay.png")
        overlay=Image.open(overlay_filename)
        alpha_100_percent=Image.new(overlay.mode,overlay.size,color=(0,0,0,0))
        overlay=Image.blend(alpha_100_percent,overlay,args.overlay)
        im.putalpha(255)
        im=Image.alpha_composite(im,overlay)
        if args.printable:
            im=Image.merge("RGB",im.split()[0:3])
            im=ImageOps.invert(im)
            im=ImageEnhance.Color(im).enhance(0)
            im=ImageEnhance.Brightness(im).enhance(0.95)
            im=ImageEnhance.Contrast(im).enhance(2)
            im=im.convert('L')
            im=im.point(lambda x: x if x<252 else 255)
        else:
            im=im.convert('RGB')
        im.save(filename,format=ext[1:])
        if not args.verbose: print(filename)
        else: print("Saved file: "+filename)
    if args.action=='save-data':
        ts=time.strftime("%Y-%m-%d_%H-%M-%S",time.localtime())
        filename=args.filename.format(ts=ts)
        ext=os.path.splitext(filename)[1]
        if not ext: parser.error('could not detect the file type extension from the filename')
        kind=ext[1:]
        if kind in ('csv','txt'):
            import csv
            data=[]
            channels=ds.displayed_channels
            for channel in channels:
                data.append(ds.get_waveform_samples(channel,mode=args.mode))
            if args.with_time:
                data.insert(0,ds.waveform_time_values_decimal)
            lengths=[len(samples) for samples in data]
            if len(set(lengths)) !=1:
                logger.error('Different number of samples read for different channels!')
                sys.exit(1)
            zip_longest
            def csv_open(filename):
                if sys.version_info >=(3,0):
                    return open(filename,'w',newline='')
                else:
                    return open(filename,'wb')
            with csv_open(filename) as csv_file:
                delimiter=',' if kind=='csv' else '\t'
                csv_writer=csv.writer(csv_file,delimiter=delimiter)
                if args.with_time:
                    csv_writer.writerow(['TIME']+channels)
                else:
                    csv_writer.writerow(channels)
                for vals in zip_longest(*data):
                    if args.with_time:
                        vals=[vals[0]]+['{:.2e}'.format(val) for val in vals[1:]]
                    else:
                        vals=['{:.2e}'.format(val) for val in vals]
                    csv_writer.writerow(vals)
        else:
            parser.error('This tool cannot handle the requested --type')
        if not args.verbose: print(filename)
        else: print("Saved file: "+filename)
    if args.action=='shell':
        try:
            import atexit
            import readline
            histfile=os.path.join(os.path.expanduser("~"),".DS1054Z_history")
            try:
                readline.read_history_file(histfile)
            except IOError as e:
                if e.errno !=errno.ENOENT:
                    raise e
            atexit.register(readline.write_history_file,histfile)
        except ImportError:
            pass
        run_shell(ds)
    if args.action=='measure':
        v=ds.get_channel_measurement(args.channel,args.item,type=args.type)
        if v is not None:
            print(v)
def run_shell(ds):
""" ds : DS1054Z instance """
    from vxi11.vxi11 import Vxi11Exception
    print(SHELL_HOWTO)
    print('> *IDN?')
    print(ds.query("*IDN?"))
    try:
        while True:
            cmd=input('> ')
            cmd=cmd.strip()
            if cmd in ('quit','exit'):
                break
            if '?' in cmd:
                try:
                    ret=ds.query_raw(cmd)
                    try:
                        print(ret.decode('utf-8').strip())
                    except UnicodeDecodeError:
                        print('binary message:',ret)
                except Vxi11Exception:
                    print("No response from the scope. Bad cmd?")
            else:
                ds.write(cmd)
    except KeyboardInterrupt as e:
        print('\nCtrl-C pressed.')
    except EOFError:
        pass
    print('Exiting...')
if __name__=="__main__":
    main()

"""rigolTrigger.py"""
#! /usr/bin/env python3  rigolScopeClasses/rigolTrigger.py at master · 00has00/rigolScopeClasses · GitHub 
import argparse
import time
import pyvisa
class rigolTrigger:
    def __init__(self,address):
        self.rm=pyvisa.ResourceManager()
        self.inst=self.rm.open_resource(f"TCPIP0::{address}::INSTR")
        self.inst.timeout=2000
        self.source=None
        self.offset=None
        self.channel=1
        self.state=None
        #Query IDN String,print it out
        self.id_str=self.inst.query("*IDN?")
        print(self.id_str)
#Reset the device and set the time based on current workstation time.
    def reset(self):
        self.inst.write("*RST")
        time.sleep(3)
#Set the time
        curdatetime=time.localtime()
        self.inst.write(f":SYST:DATE {curdatetime.tm_year},{curdatetime.tm_mon},{curdatetime.tm_mday}")
        self.inst.write(f":SYST:TIME {time.asctime().split(' ')[3].replace(':',',')}")
        time.sleep(1)

"""rigolChannel.py"""
import argparse
import time
import pyvisa
class RigolChannel:
    def __init__(self,address):
        self.rm=pyvisa.ResourceManager()
        self.inst=self.rm.open_resource(f"TCPIP0::{address}::INSTR")
        self.inst.timeout=2000
        self.scale=None
        self.offset=None
        self.channel=1
        self.state=None
#Query IDN String, print it out
        self.id_str=self.inst.query("*IDN?")
        print(self.id_str)
#Reset the device and set the time based on current workstation time.
    def reset(self):
        self.inst.write("*RST")
        time.sleep(3)
#Set the time
        curdatetime=time.localtime()
        self.inst.write(f":SYST:DATE {curdatetime.tm_year},{curdatetime.tm_mon},{curdatetime.tm_mday}")
        self.inst.write(f":SYST:TIME {time.asctime().split(' ')[3].replace(':',',')}")
        time.sleep(1)
    def set_offset(self,offset):
        self.offset=offset
    def set_scale(self,scale):
        self.scale=scale
    def set_channel(self,channel):
        self.channel=channel
    def set_state(self,state):
        self.state=state
    def get_scale(self):
        print(f"Scale: {self.scale}")
    def configure(self):
        if self.state is not None:
            self.inst.write(f":CHAN{self.channel}:DISP {self.state}")
            self.inst.write(f":CHAN{self.channel}:COUP DC")
            self.inst.write(f":CHAN{self.channel}:PROB 1")
        if self.scale is not None:
            self.inst.write(f":CHAN{self.channel}:SCAL {self.scale}")
        if self.offset is not None:
            self.inst.write(f":CHAN{self.channel}:OFFS {self.offset}")
        time.sleep(1)
    def status(self):
        state=self.inst.query(f":CHAN{self.channel}:DISP?")
        coup=self.inst.query(f":CHAN{self.channel}:COUP?")
        prob=self.inst.query(f":CHAN{self.channel}:PROB?")
        scale=self.inst.query(f":CHAN{self.channel}:SCAL?")
        offset=self.inst.query(f":CHAN{self.channel}:OFFS?")
        if state.strip()=='1':
            state='on'
        else:
            state='off'
        print(
            f"Channel: {self.channel}-{state}-Scale: {scale.strip()}-Offset: {offset.strip()}-Attenuation: {prob.strip()}-Coupling: {coup.strip()}")
    def finish(self):
        self.inst.close()
def main():
#Commands line arguments
    argpar=argparse.ArgumentParser()
    argpar.add_argument('-v',action='store_true',help='Display channel status.')
    argpar.add_argument('-r',action='store_true',help='Reset the device.')
    argpar.add_argument('-o',type=float,help='Set vertical offset.')
    argpar.add_argument('-s',type=float,help='Scale-per division (in volts).')
    argpar.add_argument('-c',choices=['1','2','3','4','a'],help='Select channel to affect')
    argpar.add_argument('-a',dest='hostname',default='10.1.1.146',help='Hostname or IP address of printer.')
    argpar.add_argument('state',nargs='?',action='store',choices=['on','off'],help='channel state-on|off')
    args=argpar.parse_args()
    myscope=RigolChannel(args.hostname)
    if args.r:
        myscope.reset()
    if args.o:
        if (args.o > 0)|(args.o <=50):
            myscope.set_offset(args.o)
    if args.s:
        if (args.s > 0)|(args.s <=50):
            myscope.set_scale(args.s)
    myscope.set_state(args.state)
    if args.c=='a':
        for i in range(1,5):
            myscope.set_channel(i)
            myscope.configure()
    elif int(args.c) in range(1,5):
        myscope.set_channel(args.c)
        myscope.configure()
    else:
        myscope.configure()
#print(f"Scale: {args.s}")
#print(f"Offset: {args.o}")
#print(f"channel: {args.c}")
#print(f"state: {args.state}")
    if args.v:
        if args.c=='a':
            for i in range(1,5):
                myscope.set_channel(i)
                myscope.status()
        elif int(args.c) in range(1,5):
            myscope.set_channel(args.c)
            myscope.status()
        else:
            myscope.status()
    myscope.finish()
if __name__=="__main__":
    main()

"""__init__.py  VISA communication interface for SCPI-based instrument remote control.
:version: 1.55.0 :copyright: 2020 by Rohde & Schwarz GMBH & Co. KG  :license: MIT, see LICENSE for more details."""
__version__='1.55.0'
#Main class
from RsInstrument.RsInstrument import RsInstrument
#Bin data format
from RsInstrument.RsInstrument import BinFloatFormat, BinIntFormat
#Exceptions
from RsInstrument.Internal.InstrumentErrors import RsInstrException, TimeoutException, StatusException, UnexpectedResponseException, ResourceError, DriverValueError
#Callback Event Argument prototypes
from RsInstrument.Internal.IoTransferEventArgs import IoTransferEventArgs
#Logging Mode
from RsInstrument.Internal.ScpiLogger import LoggingMode

"""__init__.py"""
"""The class :py:mod:`ds1054z.DS1054Z` - Easy communication with your scope  ds1054z/ds1054z/__init__.py at master · pklaus/ds1054z · GitHub """
import logging
import re
import time
import sys
import struct
import decimal
import vxi11
logger=logging.getLogger(__name__)
try:
    clock=time.perf_counter
except AttributeError:
    clock=time.time
class DS1054Z(vxi11.Instrument):
"""This class represents the oscilloscope.
:ivar product: like ``'DS1054Z'`` (depending on your device)
:ivar vendor:  should be ``'RIGOL TECHNOLOGIES'``
:ivar serial:  e.g. ``'DS1ZA118171631'``
:ivar firmware: e.g. ``'00.04.03.SP1'``"""
    IDN_PATTERN=r'^RIGOL TECHNOLOGIES,DS1\d\d\dZ( Plus)?,'
    ENCODING='utf-8'
    H_GRID=12
    SAMPLES_ON_DISPLAY=1200
    DISPLAY_DATA_BYTES=100000
    SCALE_MANTISSAE=(1, 2, 5)
    MIN_TIMEBASE_SCALE=5E-9
    MAX_TIMEBASE_SCALE=50E0
    MIN_CHANNEL_SCALE=1E-3
    MAX_CHANNEL_SCALE=1E1
    MIN_PROBE_RATIO=0.01
    MAX_PROBE_RATIO=1000
    CHANNEL_LIST=("CHAN1","CHAN2","CHAN3","CHAN4","MATH")
    def __init__(self, host,*args,**kwargs):
        self.start=clock()
        super(DS1054Z, self).__init__(host,*args,**kwargs)
        idn=self.idn
        match=re.match(self.IDN_PATTERN, idn)
        if not match:
            msg="Unknown device identification:\n%s\n" \
                "If you believe this device should be supported " \
                "by this package, feel free to contact " \
                "the maintainer with this information." % idn
            raise NameError(msg)
        idn=idn.split(',')
        self.vendor=idn[0]
        self.product=idn[1]
        self.serial=idn[2]
        self.firmware=idn[3]
        self.mask_begin_num=None
        self.possible_probe_ratio_values=self._populate_possible_values('PROBE_RATIO')
        self.possible_timebase_scale_values=self._populate_possible_values('TIMEBASE_SCALE')
        self.possible_channel_scale_values=self._populate_possible_values('CHANNEL_SCALE')
        self.possible_memory_depth_values=(12000, 120000, 1200000, 12000000, 24000000,
                                            6000,  60000,  600000,  6000000, 12000000,
                                            3000,  30000,  300000,  3000000,  6000000)
    def clock(self):
        return clock() - self.start
    def log_timing(self, msg):
        logger.info('{0:.3f} - {1}'.format(self.clock(), msg))
    def write_raw(self, cmd, *args, **kwargs):
        self.log_timing('starting write')
        logger.debug('sending: '+repr(cmd))
        super(DS1054Z, self).write_raw(cmd, *args, **kwargs)
        self.log_timing('finishing write')
    def read_raw(self, *args, **kwargs):
        self.log_timing('starting read')
        data=super(DS1054Z, self).read_raw(*args, **kwargs)
        self.log_timing('finished reading {0} bytes'.format(len(data)))
        if len(data) > 200:
            logger.debug('received a long answer: {0} ... {1}'.format(format_hex(data[0:10]), format_hex(data[-10:])))
        else:
            logger.debug('received: '+repr(data))
        return data
    def query(self,message,*args,**kwargs):
"""Write a message to the scope and read back the answer. See :py:meth:`vxi11.Instrument.ask()` for optional parameters."""
        return self.ask(message,*args,**kwargs)
    def query_raw(self, message,*args,**kwargs):
"""Write a message to the scope and read a (binary) answer. This is the slightly modified version of :py:meth:`vxi11.Instrument.ask_raw()`. It takes a command message string and returns the answer as bytes.
:param str message: The SCPI command to send to the scope.
:return: Data read from the device :rtype: bytes"""
        data=message.encode(self.ENCODING)
        return self.ask_raw(data, *args, **kwargs)
    def _interpret_channel(self, channel):
"""wrapper to allow specifying channels by their name (str) or by their number (int)"""
        if type(channel)==int:
            channel='CHAN'+str(channel)
        return channel
    @property
    def running(self):
        return self.query(':TRIGger:STATus?') in ('TD','WAIT','RUN','AUTO')
    @property
    def waveform_preamble(self):
"""Provides the values returned by the command ``:WAVeform:PREamble?``.
They will be converted to float and int as appropriate. Those values are essential if you want to convert BYTE data from the scope to voltage readings or if you want to recreate the scope's display content programmatically.
This property is also accessible via the wrapper property :py:attr:`waveform_preamble_dict` where it returns a :py:obj:`dict` instead of a :py:obj:`tuple`. This property will be fetched from the scope every time you access it.
:return: (fmt, typ, pnts, cnt, xinc, xorig, xref, yinc, yorig, yref)
:rtype: tuple of float and int values"""
        values=self.query(":WAVeform:PREamble?")
        #From the Programming Guide:
        #format: <format>,<type>,<points>,<count>,<xincrement>,<xorigin>,<xreference>,<yincrement>,<yorigin>,<yreference>
        #for example: 0,0,1200,1,2.000000e-05,-1.456000e-02,0,4.000000e-02,-75,127
        #        0   format      0 (BYTE), 1 (WORD) or 2 (ASC)
        #        0   type        0 (NORMal), 1 (MAXimum) or 2 (RAW)
        #     1200   points      an integer between 1 and 12000000
        #        1   count       number of averages
        #2.000000e-05   xincrement  time delta between subsequent data points
        #-1.456000e-02 xorigin     start time
        #        0   xreference  reference time (always zero?)
        #4.000000e-02   yincrement
        #      -75   yorigin
        #      127   yreference
        values=values.split(',')
        assert len(values)==10
        fmt, typ, pnts, cnt, xref, yorig, yref =(int(val) for val in values[:4]+values[6:7]+values[8:10])
        xinc, xorig, yinc=(float(val) for val in values[4:6]+values[7:8])
        return (fmt, typ, pnts, cnt, xinc, xorig, xref, yinc, yorig, yref)
    @property
    def waveform_preamble_dict(self):
"""Provides a dictionary with 10 entries corresponding to the tuple items of the property :py:attr:`waveform_preamble`.
This property will be fetched from the scope every time you access it.
:return: {'fmt','typ','pnts','cnt','xinc','xorig','xref','yinc','yorig','yref'}
:rtype: dict"""
        keys='fmt, typ, pnts, cnt, xinc, xorig, xref, yinc, yorig, yref'.split(', ')
        return dict(zip(keys, self.waveform_preamble))
    def get_waveform_samples(self, channel, mode='NORMal'):
"""Returns the waveform voltage samples of the specified channel. The mode argument translates into a call to ``:WAVeform:MODE`` setting up how many samples you want to read back. If you set it to normal mode, only the screen content samples will be returned.
In raw mode, the whole scope memory will be read out, which can take many seconds depending on the current memory depth.
If you set mode to RAW, the scope will be stopped first. Please start it again yourself, if you need to, afterwards.
If you set mode to NORMal you will always get 1200 samples back. Those 1200 points represent the waveform over the full screen width.
This can happend when you stop the acquisition and move the waveform horizontally so that it starts or ends inside the screen area, the missing data points are being set to float('nan') in the list.
:param channel: The channel name (like 'CHAN1' or 1).
:type channel: int or str
:param str mode: can be 'NORMal', 'MAX', or 'RAW'
:return: voltage samples
:rtype: list of float values"""
        buff=self.get_waveform_bytes(channel, mode=mode)
        fmt, typ, pnts, cnt, xinc, xorig, xref, yinc, yorig, yref=self.waveform_preamble
        samples=list(struct.unpack(str(len(buff))+'B', buff))
        samples=[(val - yorig - yref)*yinc for val in samples]
        if self.mask_begin_num:
            at_begin=self.mask_begin_num[0]
            num=self.mask_begin_num[1]
            if at_begin:
                samples=[float('nan')] * num+samples[num:]
            else:
                samples=samples[:-num]+[float('nan')] * num
        return samples
    def get_waveform_bytes(self, channel, mode='NORMal'):
"""Get the waveform data for a specific channel as :py:obj:`bytes`.
(In most cases you would want to use the higher level function :py:meth:`get_waveform_samples()` instead.)
This function distinguishes between requests for reading the waveform data currently being displayed on the screen
or if you will be reading the internal memory.
If you set mode to RAW, the scope will be stopped first and you will get the bytes from internal memory.
If you set the mode to MAXimum this function will return the internal memory if the scope is stopped, and the screen
memory otherwise. In case the internal memory will be read, the data request will automatically be split into chunks if it's impossible to read all bytes at once.
:param channel: The channel name (like CHAN1, ...). Alternatively specify the channel by its number (as integer).
:type channel: int or str
:param str mode: can be NORMal, MAXimum, or RAW
:return: The waveform data
:rtype: bytes"""
        channel=self._interpret_channel(channel)
        if mode.upper().startswith('NORM') or (self.running and mode.upper().startswith('MAX')):
            return self._get_waveform_bytes_screen(channel,mode=mode)
        else:
            return self._get_waveform_bytes_internal(channel,mode=mode)
    def _get_waveform_bytes_screen(self,channel,mode='NORMal'):
"""This function returns the waveform bytes from the scope if you desire to read the bytes corresponding to the screen content."""
        channel=self._interpret_channel(channel)
        assert mode.upper().startswith('NOR') or mode.upper().startswith('MAX')
        self.write(":WAVeform:SOURce "+channel)
        self.write(":WAVeform:FORMat BYTE")
        self.write(":WAVeform:MODE "+mode)
        wp=self.waveform_preamble_dict
        pnts=wp['pnts']
        starting_at=1
        stopping_at=self.SAMPLES_ON_DISPLAY
        if pnts < self.SAMPLES_ON_DISPLAY:
"""The oscilloscope seems to be stopped and in addition the waveform is not going all the way from the left to the
right end of the screen (due to horizontal scrolling). We will not get back the expected 1200 samples in this case.
Thus, a fix is needed to determine at which side the samples are missing."""
            self.write(":WAVeform:STARt {0}".format(self.SAMPLES_ON_DISPLAY))
            self.write(":WAVeform:STARt 1")
            if int(self.query(":WAVeform:STARt?")) != 1:
                starting_at=self.SAMPLES_ON_DISPLAY - pnts+1
            else:
                stopping_at=pnts
        self.write(":WAVeform:STARt {0}".format(starting_at))
        self.write(":WAVeform:STOP {0}".format(stopping_at))
        tmp_buff=self.query_raw(":WAVeform:DATA?")
        buff=DS1054Z.decode_ieee_block(tmp_buff)
        assert len(buff)==pnts
        if pnts < self.SAMPLES_ON_DISPLAY:
            logger.info('Accessing screen values when the waveform is not entirely ')
            logger.info('filling the screen - padding missing bytes with 0x00!')
            num=self.SAMPLES_ON_DISPLAY - pnts
            zero_bytes=b"\x00" * num
            if starting_at==1:
                buff += zero_bytes
                self.mask_begin_num=(0,num)
            else:
                buff=zero_bytes+buff
                self.mask_begin_num=(1,num)
        else:
            self.mask_begin_num=None
        return buff
    def _get_waveform_bytes_internal(self,channel,mode='RAW'):
"""This function returns the waveform bytes from the scope if you desire to read the bytes corresponding to the internal (deep) memory."""
        channel=self._interpret_channel(channel)
        assert mode.upper().startswith('MAX') or mode.upper().startswith('RAW')
        if self.running:
            self.stop()
        self.write(":WAVeform:SOURce "+channel)
        self.write(":WAVeform:FORMat BYTE")
        self.write(":WAVeform:MODE "+mode)
        wp=self.waveform_preamble_dict
        pnts=wp['pnts']
        buff=b""
        max_byte_len=250000
        pos=1
        while len(buff) < pnts:
            self.write(":WAVeform:STARt {0}".format(pos))
            end_pos=min(pnts,pos+max_byte_len-1)
            self.write(":WAVeform:STOP {0}".format(end_pos))
            tmp_buff=self.query_raw(":WAVeform:DATA?")
            buff += DS1054Z.decode_ieee_block(tmp_buff)
            pos += max_byte_len
        return buff
    def _populate_possible_values(self,which):
"""Populates list of possible values. Uses MIN_which, MAX_which, and SCALE_MANTISSAE attributes."""
        min_val=getattr(self,'MIN_'+which.upper())
        max_val=getattr(self,'MAX_'+which.upper())
        mantissae=self.SCALE_MANTISSAE
        possible_values=[]
#initialize with the decimal mantissa and exponent for min_val
        mantissa_idx=mantissae.index(int('{0:e}'.format(min_val)[0]))
        exponent=int('{0:e}'.format(min_val).split('e')[1])
        value=min_val
        while value <= max_val:
#add the value to the list of possible values
            possible_values.append(value)
#construct the next value:
            mantissa_idx += 1
            mantissa_idx %= len(mantissae)
            if mantissa_idx==0: exponent += 1
            value='{0}e{1}'.format(mantissae[mantissa_idx],exponent)
            value=decimal.Decimal(value)
            value=float(value)
        return possible_values
    @property
    def timebase_offset(self):
"""The timebase offset of the scope in seconds.
You can change the timebase offset by assigning to this property:
>>> scope.timebase_offset=200e-6
The possible values according to the programming manual:
* -Screen/2 to 1s or -Screen/2 to 5000s."""
        return float(self.query(':TIMebase:MAIN:OFFSet?'))
    @timebase_offset.setter
    def timebase_offset(self,new_offset):
        self.write(":TIMebase:MAIN:OFFSet {0}".format(new_offset))
    @property
    def timebase_scale(self):
"""The timebase scale of the scope in seconds.
The possible values according to the programming guide:
* Normal mode:  5 ns  to  50 s  in 1-2-5 steps
* Roll mode:  200 ms  to  50 s  in 1-2-5 steps
You can change the timebase like this:
>>> scope.timebase_scale=200E-9
The nearest possible value will be set."""
        return float(self.query(':TIMebase:MAIN:SCALe?'))
    @timebase_scale.setter
    def timebase_scale(self,new_timebase):
        new_timebase=min(self.possible_timebase_scale_values,key=lambda x:abs(x-new_timebase))
        self.write(":TIMebase:MAIN:SCALe {0}".format(new_timebase))
    @property
    def sample_rate(self):
        return float(self.query(':ACQuire:SRATe?'))
    @property
    def waveform_time_values(self):
"""The timestamps that belong to the waveform samples accessed to
to be accessed beforehand.
Access this property only after fetching your waveform data,
otherwise the values will not be correct.
Will be fetched every time you access this property.
:return: sample timestamps (in seconds)
:rtype: list of float"""
        wp=self.waveform_preamble_dict
        tv=[]
        for i in range(self.memory_depth_curr_waveform):
            tv.append(wp['xinc'] * i+wp['xorig'])
        return tv
    @property
    def waveform_time_values_decimal(self):
"""This is a wrapper for :py:attr:`waveform_time_values`.
It returns the time samples as :py:obj:`Decimal` values instead of float which can be convenient for writing with an appropriate precision to a human readable file format.
Access this property only after fetching your waveform data, otherwise the values will not be correct.
Will be fetched every time you access this property.
:return: sample timestamps (in seconds)
:rtype: list of :py:obj:`Decimal`"""
        wp=self.waveform_preamble_dict
        xinc_fmt=list('{0:.6e}'.format(wp['xinc']).partition('e'))
        xinc_fmt[0]=xinc_fmt[0].rstrip('0')
        xinc_fmt=''.join(xinc_fmt)
        xinc_dec=decimal.Decimal(xinc_fmt)
        return [decimal.Decimal(t).quantize(xinc_dec) for t in self.waveform_time_values]
    @staticmethod
    def format_si_prefix(number,unit=None,as_unicode=True,number_format='{0:.6f}'):
"""Formats the given number by choosing an appropriate metric prefix and stripping the formatted number of its zero-digits
giving a nice human readable form. If you provide a unit, it will be appended to the resulting string.
Example: >>> DS1054Z.format_si_prefix(2E-9, unit='s')'2 ns'"""
        prefixes =[( 1e9,'G'),( 1e6,'M'),( 1e3,'k'),(  1e0,'' )]
        prefixes += [(1e-3,'m'),(1e-6,'u'),(1e-9,'n'),(1e-12,'p')]
        formatted_number=None
        for prefix in prefixes:
            if abs(number) < prefix[0]:
                continue
            formatted_number=[number_format.format(number/prefix[0]),prefix[1]]
            break
        if not formatted_number:
            formatted_number=['{0}'.format(number/prefixes[-1][0]),prefixes[-1][1]]
        formatted_number[0]=formatted_number[0].rstrip('0').rstrip('.')
        formatted_number=' '.join(formatted_number)
        if as_unicode:
            formatted_number=formatted_number.replace('u','µ')
        if unit:
            formatted_number += unit
        return formatted_number

    @staticmethod
    def decode_ieee_block(ieee_bytes):
"""Strips headers (and trailing bytes) from a IEEE binary data block off.
This is the block format commands like ``:WAVeform:DATA?``, ``:DISPlay:DATA?``,
``:SYSTem:SETup?``, and ``:ETABle<n>:DATA?`` return their data in.
Named after ``decode_ieee_block()`` in python-ivi"""
        if sys.version_info >= (3,0):
            n_header_bytes=int(chr(ieee_bytes[1]))+2
        else:
            n_header_bytes=int(ieee_bytes[1])+2
        n_data_bytes=int(ieee_bytes[2:n_header_bytes].decode('ascii'))
        return ieee_bytes[n_header_bytes:n_header_bytes+n_data_bytes]
    @property
    def idn(self):
"""The ``*IDN?`` string of the device. Will be fetched every time you access this property."""
        return self.query("*IDN?")
    def stop(self):
""" Stop acquisition """
        self.write(":STOP")
    def run(self):
""" Start acquisition """
        self.write(":RUN")
    def single(self):
""" Set the oscilloscope to the single trigger mode."""
        self.write(":SINGle")
    def tforce(self):
""" Generate a trigger signal forcefully."""
        self.write(":TFORce")
    def set_waveform_mode(self,mode='NORMal'):
""" Changing the waveform mode """
        self.write('WAVeform:MODE '+mode)
    @property
    def memory_depth_curr_waveform(self):
"""The current memory depth of the oscilloscope. This value is the number of samples to expect when reading the
waveform data and depends on the status of the scope (running/stopped).
Needed by :py:attr:`waveform_time_values`. This property will be updated every time you access it."""
        if self.query(':WAVeform:MODE?').startswith('NORM') or self.running:
            return self.SAMPLES_ON_DISPLAY
        else:
            return self.memory_depth_internal_total
    @property
    def memory_depth_internal_currently_shown(self):
        """The number of samples in the **raw (=deep) memory** of the oscilloscope
        which are **currently being displayed on the screen**.
        This property will be updated every time you access it."""
        mdep=self.query(":ACQuire:MDEPth?")
        if mdep=="AUTO":
            srate=self.sample_rate
            scal=self.timebase_scale
            mdep=srate * scal * self.H_GRID
        return int(float(mdep))
    @property
    def memory_depth_internal_total(self):
"""The total number of samples in the **raw (=deep) memory** of the oscilloscope. If it's running, the scope will be stopped temporarily when accessing this value. This property will be updated every time you access it."""
        mdep=self.query(":ACQuire:MDEPth?")
        if mdep=="AUTO":
            curr_running=self.running
            curr_mode=self.query(':WAVeform:MODE?')
            if curr_running:
                self.stop()
            if curr_mode.startswith('NORM'):
#in this case we need to switch to RAW mode to find out the memory depth
                self.write(':WAVeform:MODE RAW')
                mdep=self.waveform_preamble_dict['pnts']
                self.write(':WAVeform:MODE '+curr_mode)
            else:
                mdep=self.waveform_preamble_dict['pnts']
            if curr_running:
                self.run()
        return int(float(mdep))
    @property
    def memory_depth(self):
"""This maps to the aquisition memory depth the scope is currently set to. In contrast to :py:attr:`memory_depth_curr_waveform`, :py:attr:`memory_depth_internal_currently_shown` and      :py:attr:`memory_depth_internal_total`, this property is simply a quite direct access to the `:ACQuire:MDEPth`
command of the oscilloscope.
You can change the memory_depth like this: >>> scope.memory_depth=12e6
This will set the memory depth to 12M data points.
Please note that changing the memory_depth is only possible when the oscilloscope is :py:attr:`running`.
Otherwise, setting this property will raise an exception.
In addition, not all values are valid in all cases. This depends on the number of channels currently in use (including the trigger!).
Please read the property back after setting it, to check that your desired value was actually acknowledged by the oscilloscope. When requesting this property, an integer value is returned or the string 'AUTO'.
This value of this property will be updated every time you access it."""
        mdepth=self.query(':ACQuire:MDEPth?')
        try:
            return int(mdepth)
        except:
            return mdepth
    @memory_depth.setter
    def memory_depth(self,mdepth):
        if not self.running:
            raise NameError("Cannot set memory depth when not running.")
        if type(mdepth) in (float,int):
#determine closest memory depth:
            new_mdepth=min(self.possible_memory_depth_values,key=lambda x:abs(x-mdepth))
        else:
            new_mdepth=mdepth
        assert new_mdepth=='AUTO' or new_mdepth in self.possible_memory_depth_values
        self.write(":ACQuire:MDEPth {0}".format(new_mdepth))
#assert self.query(":ACQuire:MDEPth?")==new_mdepth
    @property
    def display_data(self):
"""The bitmap bytes of the current screen content. This property will be updated every time you access it."""
        self.write(":DISPlay:DATA? ON,OFF,PNG")
        logger.info("Receiving screen capture...")
        buff=self.read_raw(self.DISPLAY_DATA_BYTES)
        logger.info("read {0} bytes in .display_data".format(len(buff)))
        return DS1054Z.decode_ieee_block(buff)
    @property
    def displayed_channels(self):
"""The list of channels currently displayed on the scope. This property will be updated every time you access it."""
        channel_list=[]
        for channel in self.CHANNEL_LIST:
            if self.query(":{0}:DISPlay?".format(channel))=='1':
                channel_list.append(channel)
        return channel_list
    def display_channel(self,channel,enable=True):
"""Display (enable) or hide (disable) a channel for aquisition and display"""
        channel=self._interpret_channel(channel)
        self.write(':{0}:DISPlay {1}'.format(channel,int(enable)))
    def display_only_channel(self,channel):
"""Convenience function to display (enable) a single channel and hide (disable) all others."""
        channel=self._interpret_channel(channel)
        for ch in self.CHANNEL_LIST:
            self.write(':{0}:DISPlay {1}'.format(ch,int(ch==channel)))
    def get_probe_ratio(self,channel):
"""Returns the probe ratio for a specific channel"""
        channel=self._interpret_channel(channel)
        return float(self.query(':{0}:PROBe?'.format(channel)))
    def set_probe_ratio(self,channel,ratio):
"""Set the probe ratio of a specific channel.
The possible ratio values are: 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1, 2, 5, 10, 20, 50, 100, 200, 500, and 1000.
:param channel: The channel name (like CHAN1,...). Alternatively specify the channel by its number (as integer).
:type channel: int or str
:param float ratio: Ratio of the probe connected to the channel"""
        ratio=float(ratio)
        ratio=min(self.possible_probe_ratio_values,key=lambda x:abs(x-ratio))
        channel=self._interpret_channel(channel)
        self.write(":{0}:PROBe {1}".format(channel,ratio))
    def get_channel_offset(self,channel):
"""Returns the channel offset in volts."""
        channel=self._interpret_channel(channel)
        return float(self.query(':{0}:OFFSet?'.format(channel)))
    def set_channel_offset(self,channel, volts):
"""Set the (vertical) offset of a specific channel in Volt.
The range of possible offset values depends on the current vertical scale and on
the probe ratio. With the probe ratio set to 1x the offset can be set between:
* -100V and +100V (if vertical scale ? 500mV/div), or * -2V and +2V (if vertical scale < 500mV/div).
The range scales with the probe ratio. Thus, when the probe ratio is set to 10x, for example, the offset could be set between:
* -1000V and +1000V (if vertical scale ? 5V/div), or * -20V and +20V (if vertical scale < 5V/div).
:param channel: The channel name (like CHAN1, ...). Alternatively specify the channel by its number (as integer).
:type channel: int or str
:param float volts: the new vertical scale offset in volts"""
channel=self._interpret_channel(channel)
        self.write(":{0}:OFFSet {1}".format(channel,volts))
    def get_channel_scale(self,channel):"""
        Returns the channel scale in volts.
        :return: channel scale
        :rtype: float"""
        channel=self._interpret_channel(channel)
        return float(self.query(':{0}:SCALe?'.format(channel)))
    def set_channel_scale(self,channel,volts,use_closest_match=False):
"""The default steps according to the programming guide:
* 1mV, 2mV, 5mV, 10mV...10V (for a 1x probe), * 10mV, 20mV, 50mV, 100mV...100V (for a 10x probe).
You can also set the scale to values in between those steps (as with using the fine adjustment mode on the scope).
:param channel: The channel name (like CHAN1,...). Alternatively specify the channel by its number (as integer).
:type channel: int or str
:param float volts: the new value for the vertical channel scaling
:param bool use_closest_match: round new scale value to closest match from the default steps"""
        channel=self._interpret_channel(channel)
        if use_closest_match:
            probe_ratio=self.get_probe_ratio(channel)
            possible_channel_scale_values=[val * probe_ratio for val in self.possible_channel_scale_values]
            volts=min(possible_channel_scale_values,key=lambda x:abs(x-volts))
        self.write(":{0}:SCALe {1}".format(channel,volts))
    def get_channel_measurement(self,channel,item,type="CURRent"):
"""Measures value on a channel
param channel: The channel name (like CHAN1, ...). Alternatively specify the channel by its number (as integer).
:type channel: int or str
:param str item: Item to measure, can be vmax,vmin,vpp,vtop,vbase,vamp,vavg,vrms,overshoot,preshoot,marea,mparea,period,frequency,rtime,ftime,pwidth,nwidth,pduty,nduty,rdelay,fdelay,rphase,fphase,tvmax,tvmin,pslewrate,nslewrate,vupper,vmid,vlower,variance,pvrms
:param str type: Type of measurement, can be CURRent, MAXimum, MINimum, AVERages, DEViation"""
channel=self._interpret_channel(channel)
        ret=float(self.query(":MEASure:STATistic:item? {0},{1},{2}".format(type,item,channel)))
        if ret==9.9e37: 
#This is a value which means that the measurement cannot be taken for some reason (channel disconnected/no edge in the trace etc.)
            return None
        return ret
def format_hex(byte_str):
    if sys.version_info >= (3,0):
        return ' '.join( [ "{:02X}".format(x)  for x in byte_str ] )
    else:
        return ' '.join( [ "{:02X}".format(ord(x))  for x in byte_str ] )
